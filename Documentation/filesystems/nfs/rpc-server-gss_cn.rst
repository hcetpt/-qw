=============================
RPCsec_GSS 对于内核 RPC 服务器的支持
=============================

本文档提供了用于在内核 RPC 服务器（如 NFS 服务器和 NFS 客户端的 NFSv4.0 回调服务器）中实现 RPCGSS 认证的标准和协议参考。（但请注意，NFSv4.1 及更高版本不要求客户端为了认证目的而充当服务器。）

RPCGSS 在几个 IETF 文档中有所规定：

- RFC2203 v1: https://tools.ietf.org/rfc/rfc2203.txt
- RFC5403 v2: https://tools.ietf.org/rfc/rfc5403.txt

还有第三个版本我们目前尚未实现：

- RFC7861 v3: https://tools.ietf.org/rfc/rfc7861.txt

背景
=====

RPCGSS 认证方法描述了一种为 NFS 进行 GSSAPI 认证的方法。虽然 GSSAPI 本身是完全机制无关的，但在许多情况下，NFS 实现只支持 KRB5 机制。
目前，Linux 内核仅支持 KRB5 机制，并且依赖于特定于 KRB5 的 GSSAPI 扩展。
GSSAPI 是一个复杂的库，在内核中完全实现它是不合适的。然而，GSSAPI 操作基本上可以分为两部分：

- 初始上下文建立
- 完整性/隐私保护（对单个数据包进行签名和加密）

前者更为复杂且与策略无关，但对性能要求不高。后者较为简单，需要非常快的速度。
因此，我们在内核中执行每数据包的完整性和隐私保护，但将初始上下文建立留给用户空间处理。我们需要上层调用来请求用户空间执行上下文建立。

NFS 服务器遗留的上层调用机制
===============================

经典的上层调用机制使用自定义的文本上层调用机制与 nfs-utils 包提供的名为 rpc.svcgssd 的自定义守护进程通信。
这种上层调用机制有两个限制：

A) 它只能处理不大于 2KiB 的令牌

在某些 Kerberos 部署中，GSSAPI 令牌可能相当大，甚至超过 64KiB 的大小，这是由于附加到 Kerberos 票据的各种授权扩展所致，这些扩展需要通过 GSS 层来完成上下文建立。
B) 它不能正确处理用户属于多个千组的情况（内核当前的硬性限制是 65K 组），这是由于可以发送回内核的缓冲区大小有限制（4KiB）。

NFS 服务器新的 RPC 上层调用机制
==================================

较新的上层调用机制使用通过 Unix 套接字的 RPC 与由名为 Gssproxy 的用户空间程序实现的一个名为 gss-proxy 的守护进程通信。
gss_proxy RPC 协议目前在 `这里 <https://fedorahosted.org/gss-proxy/wiki/ProtocolDocumentation>`_ 有文档说明。
这种上层调用机制使用内核 RPC 客户端并通过常规 Unix 套接字连接到 gssproxy 用户空间程序。gssproxy 协议不会受到遗留协议的大小限制的影响。
协商上层调用机制
=============================

为了提供向后兼容性，内核默认使用旧的机制。要切换到新的机制，gss-proxy 必须绑定到 /var/run/gssproxy.sock 并且然后向 /proc/net/rpc/use-gss-proxy 写入 "1"。如果 gss-proxy 崩溃，必须重复这两个步骤。一旦选择了上层调用机制，就不能再更改。为了避免锁定在旧的机制中，上述步骤必须在启动 nfsd 之前完成。无论谁启动 nfsd，都可以通过从 /proc/net/rpc/use-gss-proxy 读取并检查其内容是否为 "1" 来保证这一点——该读取操作会阻塞直到 gss-proxy 完成对该文件的写入。
