SPDX 许可证标识符: GPL-2.0

==================
XFS 日志设计
==================

前言
========

本文档描述了XFS日志子系统所基于的设计和算法。通过本文档，读者可以熟悉XFS中事务处理的一般概念。首先，我们将概述XFS中的事务，然后描述事务预留的结构与计算方式，并进一步介绍如何为初始预留有限的长时间运行事务保证向前进展。在这一点上，我们需要解释重写日志（relogging）的工作原理。在覆盖了基本概念之后，将记录延迟日志机制的设计。

简介
============

XFS 使用写入提前日志（Write Ahead Logging）来确保文件系统元数据的更改是原子性和可恢复的。为了空间和时间效率的原因，日志机制多种多样且复杂，结合了意图、逻辑和物理日志机制以提供文件系统所需的恢复保证。
一些对象，如inode和dquot，是以逻辑格式进行日志记录的，其中记录的细节由内核结构的变化而不是磁盘上的结构变化组成。其他对象——通常是缓冲区——则记录其物理变化。长时间运行的原子修改通过意图链接单个更改，以确保当系统停止工作时，日志恢复可以从头开始并完成部分完成的操作。
这些差异的原因是为了尽量减少修改对象所需的日志空间和CPU时间，从而尽量减少日志开销。有些项目被频繁修改，而某些对象的部分比其他部分更常被修改，因此保持元数据日志开销低至关重要。
用于记录一个项目或将修改链接在一起的方法在本文档范围内并不是特别重要。重要的是要知道，对于特定对象或修改的记录方法是不同的，并且取决于正在执行的对象和/或修改。日志子系统只关心遵循某些特定规则以保证向前进展并防止死锁。

XFS中的事务
===================

XFS有两种类型的高级事务，根据它们占用的日志空间预留类型定义。这些被称为“一次性”和“永久性”事务。永久性事务预留可以跨越提交边界，而“一次性”事务则是用于单一原子修改。
预留的类型和大小必须与正在进行的修改相匹配。这意味着永久性事务可以用于一次性修改，但一次性预留不能用于永久性事务。
在代码中，“一次性”事务模式大致如下：

```c
tp = xfs_trans_alloc(<reservation>);
<锁定项>;
<将项加入事务>;
<执行修改>;
xfs_trans_commit(tp);
```

在事务中修改项目时，通过事务句柄跟踪这些项目中的脏区域。一旦事务提交，所有与其关联的资源都会被释放，以及在事务分配时剩余未使用的预留空间也会被释放。
相比之下，永久性事务由多个链接的独立事务组成，其模式如下：

```c
tp = xfs_trans_alloc(<reservation>);
xfs_ilock(ip, XFS_ILOCK_EXCL);

loop {
    xfs_trans_ijoin(tp, 0);
    <执行修改>;
    xfs_trans_log_inode(tp, ip);
    xfs_trans_roll(&tp);
}

xfs_trans_commit(tp);
xfs_iunlock(ip, XFS_ILOCK_EXCL);
```

虽然这看起来与一次性事务相似，但有一个重要的区别：`xfs_trans_roll()` 执行一个特定操作，将两个事务链接起来：

```c
ntp = xfs_trans_dup(tp);
xfs_trans_commit(tp);
xfs_trans_reserve(ntp);
```

这导致一系列“滚动事务”，其中inode在整个事务链中被锁定。因此，在这一系列滚动事务运行期间，其他任何东西都无法读取或写入该inode，这为复杂的更改从外部观察者的角度来看呈现原子性提供了机制。
需要注意的是，在永久事务中的一系列滚动操作并不会在日志中形成一个原子性变更。虽然每个单独的修改是原子性的，但整个链不是原子性的。如果我们中途崩溃，恢复只会重播到循环中上一次提交到日志的事务性修改。

这对长时间运行的永久事务的影响在于，无法预测长时间操作中有多少部分能够真正恢复，因为无法保证操作中的哪些部分已经写入了持久存储。因此，如果一个长时间运行的操作需要多次事务才能完成，则高层操作必须使用意图和延迟操作来确保一旦第一次事务被持久化到磁盘日志中，恢复可以完成该操作。

事务是异步的
=============================

在XFS中，默认所有高层事务都是异步的。这意味着当xfs_trans_commit()返回时，并不能保证修改已经被提交到稳定存储。因此，当系统崩溃时，并非所有的已完成事务都会在恢复期间重播。
然而，日志子系统确实提供了全局顺序保证，即如果某个更改在恢复后可见，那么在此之前提交的所有元数据修改也都会可见。

对于需要立即写入稳定存储的单次操作，或者确保长时间运行的永久事务一旦完成就被完全提交，我们可以显式地将事务标记为同步。这将触发“日志强制”操作，将待提交的事务刷新到日志中的稳定存储，并等待其完成。
同步事务很少使用，因为它们将日志吞吐量限制在底层存储的I/O延迟限制内。相反，我们通常仅在用户操作需要同步点（例如fsync）时才使用日志强制操作来确保修改已写入稳定存储。

事务预留
========================

已经多次提到，日志子系统需要提供前进进度保证，以确保任何修改都不会由于日志空间不足而停滞不前。这是通过在首次分配事务时所做的事务预留实现的。对于永久事务，这些预留作为事务滚动机制的一部分进行维护。

事务预留保证在开始对对象和项目进行修改之前，有足够的物理日志空间来写入修改内容。因此，预留需要足够大，以考虑到最坏情况下可能需要记录的元数据量。这意味着如果我们正在事务中修改B树，则必须预留足够的空间来记录从叶节点到根节点的完整拆分。因此，预留非常复杂，因为我们必须考虑到所有可能发生的隐藏修改。

例如，用户数据区分配涉及从空闲空间中分配一个区，这会修改空闲空间树。这是两个B树。将区插入inode的扩展映射可能需要拆分扩展映射B树，这又需要另一个分配，可能会再次修改空闲空间树。然后我们可能还需要更新逆向映射，这会修改另一个B树，可能需要更多空间。如此等等。因此，“简单”操作所能修改的元数据量可能相当大。

这种“最坏情况”的计算为我们提供了事务的静态“单元预留”，在挂载时计算得出。我们必须保证日志有足够空间供事务继续进行，这样当我们写入脏元数据时不会在写入过程中耗尽日志空间。
对于一次性交易，只需要一个单位的空间预留即可使交易进行。然而，对于永久性交易，我们还有一个“日志计数”，这会影响需要预留的空间大小。虽然永久性交易也可以通过单个单位的空间预留来进行，但这有些低效，因为它要求在每次交易滚动时重新预留空间。根据永久性交易的实现，我们知道对于常见的修改操作，可能需要进行多少次交易滚动。

例如，inode分配通常涉及两个交易——一个用于在磁盘上物理分配一个空闲的inode块，另一个用于从包含空闲inode的inode块中分配一个inode。因此，对于inode分配交易，我们可以将预留日志计数设置为2，以表示常见/快速路径交易将在链中提交两次相关联的交易。每次永久性交易滚动时，都会消耗一个整个单位的预留空间。

因此，在永久性交易首次分配时，日志空间预留会从单个单位增加到多个单位。这个倍数由预留日志计数定义，这意味着我们可以在多次交易滚动之前不需要重新预留日志空间。这样确保了我们进行的常见修改只需预留一次日志空间。

如果永久性交易的日志计数达到零，则需要重新预留物理空间。这有些复杂，并且需要理解日志如何计算已预留的空间。

### 日志空间计算

日志中的位置通常称为日志序列号（LSN）。由于日志是循环的，因此日志中的位置由周期编号（日志被覆盖的次数）和偏移量定义。LSN的高32位表示周期，低32位表示偏移量。偏移量以“基本块”（512字节）为单位。因此，我们可以使用相对简单的LSN数学来跟踪日志中的可用空间。

日志空间计算通过一对称为“预留头”的结构来完成。预留头的位置是一个绝对值，因此日志中的可用空间由预留头位置与当前日志尾部之间的距离定义。也就是说，在预留头完全绕过日志并超过尾部位置之前，可以预留/消耗多少空间。

第一个预留头是“预留”头。它跟踪当前活动交易持有的预留字节数。这是纯粹内存中的预留空间计算，因此实际上跟踪的是日志中的字节偏移量而不是基本块。因此，它技术上不是用LSN表示日志位置，但在跟踪预留空间时仍然被视为一个拆分的{周期，偏移}元组。

预留头用于准确计算确切的交易预留金额以及实际修改所需写入日志的确切字节数。当预留头到达当前尾部时，它会阻止新的交易获取新的预留，并将它们放入FIFO队列中。随着日志尾部向前移动，一旦有足够的空间可用，就会按顺序唤醒这些预留。这种FIFO机制确保在日志空间不足时，任何交易都不会因资源短缺而饿死。
另一个授予头是“写”头。与预留头不同，这个授予头包含一个日志序列号（LSN），并且跟踪日志中的物理空间使用情况。虽然这听起来像是在记录与预留授予头相同的状况——而且它确实大部分时候跟踪的是与预留授予头相同的位置——但它们之间存在关键的行为差异，这些差异提供了滚动永久事务所需的向前进展保证。这些差异体现在当一个永久事务进行滚动，并且内部的“日志计数”归零，初始的单元预留已用尽时。此时，我们仍然需要一个日志空间预留以继续下一笔事务，但我们已经没有剩余的空间了。我们不能在事务提交过程中休眠等待新的日志空间变得可用，因为那样我们可能会排到FIFO队列的末尾，并且我们在休眠期间锁定的项目可能会在日志尾部形成固定点，在有足够的自由空间满足所有待处理的预留之前无法唤醒正在进行的事务提交。

为了在不休眠的情况下进行新的预留，我们需要能够在当前没有预留空间的情况下也能进行预留。也就是说，我们需要能够*超额预留*日志预留空间。正如前面所述，我们不能超额预留物理日志空间。然而，预留授予头并不跟踪物理空间——它只记录当前我们有多少个预留未被释放。因此，如果预留头超过了日志的尾部，这意味着新的预留将立即被限制，并一直保持限制状态，直到日志尾部前移足够远以消除超额预留并开始接受新的预留。换句话说，我们可以超额预留预留头而不违反物理日志头和尾部的规则。

因此，永久事务仅在调用`xfs_trans_commit()`时重新授予预留空间，而物理日志空间预留——由写头跟踪——则在提交完成后通过调用`xfs_log_reserve()`单独预留。一旦提交完成，我们可以在等待从写授予头预留物理日志空间时休眠，但前提是必须遵守一个关键规则：

> 使用永久预留的代码必须始终记录其持有的锁项，以便在链条中滚动的每个事务都能记录。

每次事务滚动时“重新记录”锁项确保了与事务链条相关的项目总是被重定位到日志的物理头部，从而不会固定日志的尾部。如果我们休眠等待写预留时有锁项固定了日志尾部，那么我们将导致日志死锁，因为我们无法获取所需的锁来回写该项目并前移日志尾部以释放写预留空间。重新记录锁项避免了这种死锁，并保证了我们所做的日志预留不会自我死锁。

如果所有滚动事务都遵守这一规则，那么它们可以独立地向前进展，因为没有任何东西会阻碍日志尾部向前移动，从而确保无论滚动多少次，永久事务总能最终获得写预留空间。

### 重新记录详解

XFS允许对单个对象的多个独立修改同时存在于日志中。这样，日志就不必在记录新修改之前将每个更改刷新到磁盘。XFS通过一种称为“重新记录”的方法实现这一点。从概念上讲，这很简单——只需要任何对对象的新修改都与该对象在新事务中写入日志时的所有现有修改的*新副本*一起记录。

也就是说，如果我们有一个从A到F的更改序列，并且对象在更改D之后被写入磁盘，那么在日志中我们会看到以下一系列事务、内容及其日志序列号（LSN）：

```
事务         内容            LSN
A             A              X
B            A+B             X+n
C           A+B+C            X+n+m
D          A+B+C+D          X+n+m+o
<对象写入磁盘>
E             E              Y (> X+n+m+o)
F            E+F             Y+p
```

换句话说，每当对象被重新记录时，新事务包含当前仅存在于日志中的所有先前更改的汇总。

这种重新记录技术使对象能够在日志中向前移动，从而使重新记录的对象不会阻止日志尾部向前移动。从上面表格中可以看出，每次后续事务的LSN都在递增，这是实现长时间运行、多提交永久事务的技术基础。

一个典型的滚动事务示例是从inode中删除extent，由于预留大小限制，每次事务只能删除两个extent。因此，滚动extent删除事务会在每次删除操作中不断重新记录inode和btree缓冲区。这使得它们随着操作的进行而在日志中向前移动，确保当前操作永远不会因日志循环而被自己阻塞。

因此，可以看到重新记录操作对于XFS日志子系统的正确工作至关重要。从上述描述中，大多数人应该能够理解为什么XFS元数据操作会向日志写入大量数据——对同一对象的重复操作会反复将相同的更改写入日志。更糟糕的是，对象在重新记录时往往会变得更脏，因此每个后续事务都会向日志中写入更多元数据。
现在也应该很明显，重新记录（relogging）和异步事务是如何相辅相成的。也就是说，事务不会被立即写入物理日志，而是在日志缓冲区填满（一个日志缓冲区可以保存多个事务）或者同步操作将持有这些事务的日志缓冲区强制写入磁盘时才会写入。这意味着XFS在内存中对事务进行聚合——如果你愿意的话，可以说是批量处理——以尽量减少日志I/O对事务吞吐量的影响。
异步事务吞吐量的限制因素是日志管理器提供的日志缓冲区的数量和大小。默认情况下有8个日志缓冲区可用，每个缓冲区的大小为32kB——通过挂载选项，这个大小可以增加到256kB。
实际上，这给了我们任何时刻文件系统中未完成元数据更改的最大上限——如果所有日志缓冲区都已满并处于I/O状态，那么就无法再提交更多的事务，直到当前批次完成。现在，单个CPU核心能够发出足够的事务来永久地保持日志缓冲区满载和处于I/O状态。因此，XFS的日志子系统可以被认为是I/O受限的。

延迟日志：概念
=========================

关于XFS使用的异步日志结合重新记录技术的关键在于，我们可以多次重新记录更改的对象，直到它们被提交到日志缓冲区中的磁盘上。如果我们回到之前的重新记录示例，完全有可能事务A到D在同一日志缓冲区中被提交到磁盘。
也就是说，一个日志缓冲区可能包含同一对象的多个副本，但只需要其中一个副本——最后一个“D”，因为它包含了之前所有更改的内容。换句话说，我们在日志缓冲区中有一个必要的副本，以及三个过时的副本，这些副本只是在浪费空间。当我们对同一组对象进行重复操作时，这些“过时对象”可能会占用日志缓冲区超过90%的空间。显然，减少写入日志的过时对象数量将大大减少我们写入日志的元数据量，这就是延迟日志的基本目标。
从概念上讲，XFS已经在内存中（这里内存等同于日志缓冲区）进行了重新记录，只不过效率极低。它使用逻辑到物理格式化来进行重新记录，因为没有基础设施来跟踪在事务将更改物理格式化到日志缓冲区之前发生的逻辑更改。因此我们无法避免在日志缓冲区中累积过时对象。
延迟日志是我们给在日志缓冲区之外的内存中保留和跟踪对象的事务性更改命名的方式。由于重新记录的概念是XFS日志子系统的核心，这实际上是相对容易实现的——所有对已记录项目的更改已经在当前基础设施中被跟踪。最大的问题是如何一致且可恢复地累积这些更改并将它们写入日志。
描述这些问题及其解决方案是本文的重点。
延迟日志对日志子系统的操作带来的关键变化之一是它将未完成元数据更改的数量与日志缓冲区的大小和数量解耦。换句话说，不再只有最多2MB的事务更改未写入日志，而是可能在内存中有更多数量的更改被累积。因此，在崩溃时丢失元数据的可能性比现有的日志机制要大得多。
需要注意的是，这并不会改变日志恢复将导致一致文件系统的保证。这意味着对于恢复后的文件系统来说，可能会有数千个交易由于崩溃而根本没有发生。这使得那些关心数据完整性的应用程序更需要在需要确保应用级别数据完整性时使用fsync()。
应该注意的是，延迟日志记录并不是一个需要严格证明其正确性的创新概念。在一段时间内将更改累积在内存中然后再写入日志的方法已经在许多文件系统（包括ext3和ext4）中得到了有效应用。因此，在本文档中并没有花费时间试图说服读者这一概念是合理的。相反，它被视为一个“已解决的问题”，因此在XFS中实现它纯粹是一个软件工程练习。

延迟日志记录在XFS中的基本要求很简单：

1. 至少减少一个数量级的日志元数据写入量。
2. 提供足够的统计数据来验证要求#1。
3. 提供足够的新追踪基础设施，以便能够调试新代码中的问题。
4. 不改变磁盘格式（元数据或日志格式）。
5. 通过挂载选项启用或禁用。
6. 对同步事务工作负载没有性能倒退。

延迟日志记录：设计
==================

存储更改
---------

在逻辑级别上累积更改（即仅使用现有的日志项脏区域跟踪）的问题在于，在将更改写入日志缓冲区时，我们需要确保正在格式化的对象在此过程中不会发生更改。这需要锁定该对象以防止并发修改。因此，将逻辑更改刷新到日志需要我们锁定每个对象，格式化它们，然后再次解锁。

这会引入大量与已经运行的事务产生死锁的可能性。例如，一个事务已经锁定了对象A并对其进行了修改，但需要延迟日志跟踪锁才能提交事务。然而，刷新线程已经持有了延迟日志跟踪锁，并尝试获取对象A的锁以便将其刷新到日志缓冲区。这似乎是一个无法解决的死锁条件，正是解决这个问题成为了长期以来实施延迟日志记录的障碍。

解决方案相对简单——只是花了很长时间才认识到这一点。
简单来说，当前的日志记录代码将对每个项目所做的更改格式化为指向项目中已更改区域的向量数组。在事务提交期间，日志写入代码会将这些向量所指内存复制到日志缓冲区中，同时锁定该项目。我们不必使用日志缓冲区作为格式化代码的目标，而是可以使用足够大的分配内存缓冲区来容纳格式化的向量。如果我们将向量复制到内存缓冲区，并重写向量以指向内存缓冲区而不是对象本身，我们现在就得到了一个与日志缓冲区写入代码兼容的更改副本，而无需锁定项目即可访问。这个格式化和重写过程可以在事务提交期间锁定对象时完成，从而生成一个事务一致的向量，并且无需锁定拥有项目即可访问。

因此，当我们需要将未决的异步事务刷新到日志时，就不必锁定项目。现有格式化方法与延迟日志记录格式之间的差异如以下图表所示：

当前格式的日志向量如下：

```
对象    +---------------------------------------------+
向量1      +----+
向量2                    +----+
向量3                                   +----------+
```

格式化后：

```
日志缓冲区    +-V1-+-V2-+----V3----+
```

延迟日志记录向量如下：

```
对象    +---------------------------------------------+
向量1      +----+
向量2                    +----+
向量3                                   +----------+
```

格式化后：

```
内存缓冲区 +-V1-+-V2-+----V3----+
向量1      +----+
向量2           +----+
向量3                +----------+
```

内存缓冲区及其相关向量需要作为一个单一对象传递，但仍需与父对象关联，以便在对象重新记录时可以用包含最新更改的新内存缓冲区替换当前内存缓冲区。

保留向量的原因是在格式化内存缓冲区之后支持正确地跨越日志缓冲区边界分割向量。如果我们不保留向量，我们就无法知道项目中的区域边界在哪里，因此我们需要一种新的日志缓冲区写入区域的封装方法（即双重封装）。这会导致磁盘格式的变化，这是不可取的。这也意味着我们必须在格式化阶段写入日志区域头，这在日志写入过程中有问题，因为每个区域的状态需要在日志写入时放入头部信息中。

因此，我们需要保留向量，但通过将内存缓冲区附加到向量上并重写向量地址以指向内存缓冲区，最终得到一个自描述的对象，可以将其传递给日志缓冲区写入代码，并以与现有日志向量相同的方式处理它。这样我们就可以避免为了处理内存中重新记录的项目而引入新的磁盘格式。

跟踪更改
----------

现在我们可以以一种允许它们不受限制地使用的形式在内存中记录事务性更改，我们需要能够跟踪和累积这些更改，以便在某个时间点将它们写入日志。日志项是存储该向量和缓冲区的自然位置，并且也是用于跟踪已提交对象的合理对象，因为它一旦被包含在事务中就会始终存在。
日志项已用于跟踪那些已写入日志但尚未写入磁盘的日志项。这样的日志项被认为是“活跃”的，因此它们被存储在按LSN（日志序列号）排序的双链表中，称为活跃项列表（AIL）。这些项在日志缓冲区I/O完成时插入到该列表中，在此之后它们将被取消固定并可以写入磁盘。一个在AIL中的对象可能会被重新记录（relogged），这会导致该对象再次被固定，并在该事务的日志缓冲区I/O完成后向前移动到AIL中。

基本上，这意味着一个在AIL中的项仍然可以被修改和重新记录，因此任何跟踪必须与AIL基础设施分开进行。因此，我们不能重用AIL列表指针来跟踪已提交的项，也不能在受AIL锁保护的任何字段中存储状态。因此，已提交项的跟踪需要自己的锁、列表和日志项中的状态字段。

类似于AIL，已提交项的跟踪通过一个新的列表进行，称为已提交项列表（CIL）。该列表跟踪已提交并且有格式化内存缓冲区附加的日志项。它按照事务提交顺序跟踪对象，因此当一个对象被重新记录时，它会从列表中的位置移除，并重新插入到列表尾部。这是完全随意的，这样做是为了方便调试——列表中的最后几项是最近修改过的。CIL的排序对于事务完整性不是必要的（如下一节所述），因此这种排序是为了开发者的便利/理智。

### 延迟日志：检查点

当我们有一个日志同步事件，通常称为“日志强制”时，CIL中的所有项都必须通过日志缓冲区写入日志。我们需要按照它们在CIL中的顺序写入这些项，并且需要作为一个原子事务来写入。所有对象作为一个原子事务写入的要求来自于重新记录和日志重放的需求——给定事务中的所有更改要么在日志恢复期间完全重放，要么根本不重放。如果一个事务由于不完整而没有被重放，则后续的事务也不应被重放。

为了满足这一要求，我们需要在一个单独的日志事务中写入整个CIL。幸运的是，XFS日志代码对事务大小没有固定的限制，日志重放代码也没有。唯一的基本限制是事务的大小不能超过日志大小的一半。之所以有这个限制是因为要找到日志的头和尾，任何时候都至少需要一个完整的事务存在于日志中。如果一个事务大于日志的一半，那么在写入这样一个事务期间发生崩溃可能会部分覆盖唯一的完整前一个事务，这将导致恢复失败和文件系统的不一致。因此，我们必须将检查点的最大大小设置为略小于日志大小的一半。

除了这个大小要求外，检查点事务与其他事务看起来并无不同——它包含一个事务头、一系列格式化的日志项以及尾部的一个提交记录。从恢复的角度来看，检查点事务也并无不同——只是更大一些，包含更多的项。最坏的情况影响是我们可能需要调整恢复事务对象哈希表的大小。

因为检查点只是一个事务，并且所有对日志项的更改都存储为日志向量，我们可以使用现有的日志缓冲区写入代码将更改写入日志。为了高效地做到这一点，我们需要尽量减少在写入检查点事务期间锁定CIL的时间。当前的日志写入代码使我们能够轻松地做到这一点，因为它将事务内容（日志向量）的写入与事务提交记录分离，但这需要我们在日志写入过程中直到检查点完成都有一个每检查点的上下文。

因此，检查点有一个上下文来跟踪当前检查点从启动到完成的状态。一个新的上下文会在启动检查点事务时同时启动。也就是说，在检查点操作期间，当我们从CIL中移除所有当前项时，我们将所有这些更改移到当前检查点上下文中。然后我们初始化一个新的上下文并将其附加到CIL上以聚合新的事务。

这使我们能够在转移所有已提交项后立即解锁CIL，有效地允许在我们格式化检查点到日志的同时发出新事务。这也允许并发检查点被写入日志缓冲区，特别是在日志强制工作负载较重的情况下，就像现有事务提交代码一样。然而，这要求我们在日志中严格排序提交记录，以便在日志重放期间保持检查点序列的顺序。
为了确保我们能够在某个事务写入检查点事务的同时，另一个事务修改该条目并将其日志项插入新的CIL（Current In-Log List），检查点事务提交代码不能使用日志项来存储需要写入事务的日志向量列表。因此，日志向量需要能够链接在一起，以便从日志项中分离出来。也就是说，当CIL被刷新时，每个日志项所附带的内存缓冲区和日志向量需要附加到检查点上下文中，以便释放日志项。用图表表示，在刷新之前，CIL看起来像这样：

```
CIL Head
   |
   V
Log Item <-> 日志向量 1 -> 内存缓冲区
           |         -> 向量数组
           V
Log Item <-> 日志向量 2 -> 内存缓冲区
           |         -> 向量数组
           V
......
|
   V
Log Item <-> 日志向量 N-1 -> 内存缓冲区
           |             -> 向量数组
           V
Log Item <-> 日志向量 N   -> 内存缓冲区
                     -> 向量数组
```

而在刷新之后，CIL头部为空，而检查点上下文中的日志向量列表看起来像这样：

```
Checkpoint Context
   |
   V
日志向量 1 -> 内存缓冲区
   |       -> 向量数组
   |       -> Log Item
   V
日志向量 2 -> 内存缓冲区
   |       -> 向量数组
   |       -> Log Item
   V
......
|
   V
日志向量 N-1 -> 内存缓冲区
   |           -> 向量数组
   |           -> Log Item
   V
日志向量 N   -> 内存缓冲区
              -> 向量数组
              -> Log Item
```

一旦完成这个转移，CIL就可以解锁，并且可以开始新的事务，而检查点刷新代码则可以在日志向量链上进行工作以提交检查点。一旦检查点被写入日志缓冲区，检查点上下文就会附着到包含提交记录的日志缓冲区上，并附带一个完成回调。日志IO完成时会调用这个回调，然后可以运行日志项的事务提交处理（即插入AIL并取消固定），接着释放日志向量链和检查点上下文。

讨论点：我不确定日志项是否是跟踪向量的最有效方式，尽管这似乎是自然的做法。我们在CIL中遍历日志项只是为了链接日志向量并断开日志项与日志向量之间的联系，这意味着我们对日志项列表进行了缓存行命中，然后再对日志向量链接进行缓存行命中。如果我们通过日志向量来跟踪，则只需要断开日志项与日志向量之间的链接，这意味着我们只脏化日志项的缓存行。通常我不会在意一两个缓存行的区别，但考虑到在一个检查点事务中看到过高达80,000个日志向量，我认为这是一个“测量和比较”的情况，可以在开发树中有经过审查的实现后再进行。

延迟日志：检查点排序
----------------------

XFS事务子系统的一个关键方面是它将已提交事务标记为事务提交的日志序列号。这使得事务可以异步发布，即使可能存在未来操作在该事务完全提交到日志之前无法完成的情况。在少数情况下，如果发生依赖操作（例如重新使用已释放的元数据范围作为数据范围），可以发出特殊的优化日志强制，立即将依赖事务写入磁盘。

为此，事务需要记录其提交记录的LSN（Log Sequence Number）。这个LSN直接来自于事务写入的日志缓冲区。虽然这对现有的事务机制来说工作得很好，但对于延迟日志却不适用，因为事务不是直接写入日志缓冲区的。因此，需要另一种方法来对事务进行排序。
如检查点部分所述，延迟日志记录使用每个检查点上下文，因此为每个检查点分配一个序列号非常简单。由于切换检查点上下文必须是原子操作，因此可以确保每个新的上下文有一个单调递增的序列号而无需外部原子计数器——我们只需取当前上下文的序列号并为新上下文加一即可。然后，在提交时，我们可以将当前检查点序列号分配给事务提交LSN。这使得跟踪尚未完成的事务的操作能够知道需要提交哪个检查点序列才能继续。因此，强制日志到特定LSN的代码现在需要确保日志被强制到特定的检查点。

为了实现这一点，我们需要跟踪所有当前正在提交到日志的检查点上下文。当我们刷新一个检查点时，该上下文会被添加到一个“正在提交”的列表中，可以进行搜索。当一个检查点提交完成时，它会从正在提交的列表中移除。因为检查点上下文记录了检查点提交记录的LSN，我们还可以等待包含提交记录的日志缓冲区，从而利用现有的日志强制机制执行同步强制。

需要注意的是，同步强制可能需要扩展类似当前日志缓冲代码中的缓解算法，以便在已经有同步事务正在刷新的情况下聚合多个同步事务。在此做出任何决定之前，需要对当前设计的性能进行调查。

关于日志强制的主要关注点是确保我们在等待的检查点之前的其他所有检查点也已提交到磁盘。因此，在等待我们需要完成的那个检查点之前，我们需要检查正在提交列表中的所有先前上下文是否也已完成。我们在日志强制代码中进行这种同步，这样我们就不需要在其他地方等待这样的序列化——只有在执行日志强制时才重要。

唯一剩下的复杂性在于，日志强制现在还必须处理强制序列号与当前上下文相同的特殊情况。也就是说，我们需要刷新CIL并可能等待其完成。这是对现有日志强制代码的一个简单补充，以检查序列号并在必要时进行推送。事实上，将当前序列检查点刷新放入日志强制代码中，使发出同步事务的当前机制保持不变（即提交一个异步事务，然后在该事务的LSN处强制日志），因此无论是否使用延迟日志，高级代码的行为都相同。

### 延迟日志：检查点日志空间会计

对于检查点事务来说，主要问题是事务的日志空间预留。我们事先不知道检查点事务会有多大，也不知道写入所需的日志缓冲区数量以及使用的分割日志向量区域数量。我们可以在向提交项列表中添加项目时跟踪所需的日志空间量，但仍然需要在日志中为检查点预留空间。

典型的事务会在日志中预留足够空间以应对最坏情况下的空间使用。预留考虑了日志记录头、事务和区域头、分割区域头、缓冲尾部填充等，以及事务中所有更改元数据的实际空间。虽然其中一些是固定开销，但很多取决于事务大小和记录的日志区域数量（事务中的日志向量数量）。

一个例子是记录目录更改与记录inode更改之间的差异。如果我们修改大量inode核心（例如`chmod -R g+w *`），那么会有大量只包含inode核心和inode日志格式结构的事务。也就是说，两个向量总共约150字节。如果我们修改10,000个inode，我们将有大约1.5MB的元数据以20,000个向量的形式写入。每个向量为12字节，因此总共要记录的大约为1.75MB。相比之下，如果我们记录完整的目录缓冲区，它们通常是每个4KB，因此在1.5MB的目录缓冲区中，我们将有大约400个缓冲区及其各自的缓冲格式结构——大约800个向量或总共1.51MB的空间。由此可以看出，静态日志空间预留并不特别灵活，并且很难为所有工作负载选择“最优值”。

此外，如果我们使用静态预留，整个预留覆盖了哪一部分？我们通过跟踪CIL中对象当前使用的空间，并计算对象重新记录时空间的增加或减少来计算事务预留所用的空间。这使得检查点预留只需要考虑日志缓冲区元数据的使用，例如日志头记录。
然而，即使只为日志元数据使用静态预留也是有问题的。通常情况下，每消耗1MB的日志空间，日志记录头至少会占用16KB的日志空间（每32KB占用512字节），并且预留的空间需要足够大以处理任意大小的检查点事务。这个预留必须在检查点开始之前进行，并且我们需要能够在不休眠的情况下预留空间。对于一个8MB的检查点，我们需要大约150KB的预留空间，这是一个非同小可的空间量。

静态预留需要操作日志授予计数器——我们可以对这部分空间进行永久预留，但仍需确保在每次检查点事务完成后刷新写预留（即实际可用于事务的空间）。不幸的是，如果在需要时没有足够的空间，重新授予代码将会休眠等待。

这可能会导致死锁，因为我们需要完成检查点才能释放日志空间（请参阅滚动事务的描述以了解示例）。因此，如果我们使用静态预留，则必须始终在日志中保留足够的空间，而这非常难以安排。虽然这是可行的，但有一种更简单的方法。

更简单的方法是跟踪CIL中所有项所使用的全部日志空间，并据此动态计算所需的日志元数据空间。如果由于事务提交将新的内存缓冲区插入到CIL而导致日志元数据空间发生变化，则所需空间的变化量将从引起变化的事务中扣除。在这个级别的事务始终会在其预留空间中有足够的空间来满足这一需求，因为他们已经预留了所需的最大日志元数据空间，而这样的增量预留总是小于或等于预留的最大值。

因此，我们可以在CIL中添加项目时动态增加检查点事务的预留空间，从而避免预先预留和重新授予日志空间的需求。这避免了死锁，并从检查点刷新代码中移除了一个阻塞点。

如前所述，事务不能增长到超过日志大小的一半。因此，在预留空间增长的过程中，我们还需要检查预留大小是否超过了允许的最大事务大小。如果我们达到了最大阈值，就需要将CIL推送到日志中。这实际上是一种“后台刷新”，并且按需执行。这与由日志强制触发的CIL推送相同，只是不需要等待检查点提交完成。此后台推送由事务提交代码检查并执行。

如果事务子系统处于空闲状态，而CIL中仍有项目，则这些项目将通过xfssyncd定期发出的日志强制进行刷新。此日志强制会将CIL推送到磁盘，如果事务子系统继续保持空闲，则允许空闲日志被覆盖（实际上是标记为干净），就像现有的日志方法一样。讨论的一个问题是这种日志强制是否需要比当前的频率更高，目前的频率是每30秒一次。

延迟日志：日志项固定
----------------------

目前，在事务提交期间，日志项在其仍被锁定时被固定。这发生在项格式化之后，尽管也可以在项解锁之前的任何时间进行。该机制的结果是，每个提交到日志缓冲区的事务都会对项进行一次固定。因此，重新记录在日志缓冲区中的项将在每次被弄脏的未完成事务中有一个固定计数。当这些事务中的每一个完成时，它们会对项解除一次固定。结果，只有在所有事务完成且没有待处理事务时，项才会完全解除固定。因此，日志项的固定和解除固定是对称的，因为它们与事务提交和日志项完成之间存在一对一的关系。

然而，在延迟日志中，事务提交与完成之间的关系是非对称的。每当对象在CIL中重新记录时，它会经历提交过程，但不会相应地注册完成。也就是说，我们现在有了一个事务提交与日志项完成之间的多对一关系。这导致如果保留“在事务提交时固定，在事务完成时解除固定”的模型，日志项的固定和解除固定会变得不平衡。
为了保持“加锁”和“解锁”的对称性，算法需要改为“在插入CIL时加锁，在检查点完成时解锁”。换句话说，加锁和解锁围绕检查点上下文变得对称。我们必须在对象首次插入到CIL时将其加锁——如果它已经在事务提交期间存在于CIL中，则不再重复加锁。由于可能存在多个未完成的检查点上下文，我们仍然会看到较高的加锁计数，但随着每个检查点的完成，加锁计数将根据其上下文保留正确的值。

为了让情况稍微复杂一点，这种基于检查点级别的加锁计数意味着必须在CIL提交/刷新锁下进行加锁操作。如果我们在锁之外加锁对象，无法保证加锁计数与哪个上下文相关联。这是因为加锁对象取决于该对象是否存在于当前的CIL中。如果我们不在检查和加锁对象之前先锁定CIL，那么在检查和加锁（或不加锁）之间可能会出现竞争条件。因此，必须持有CIL刷新/提交锁以确保正确地加锁项目。

延迟日志记录：并发可扩展性
---------------------------------------

CIL的一个基本要求是通过事务提交的访问能够扩展到许多并发提交。即使有2048个处理器同时进行事务提交，当前的事务提交代码也不会崩溃。虽然当前的事务代码不会比只有一个CPU使用时更快，但它也不会变慢。

因此，延迟日志记录的事务提交代码需要从一开始就设计为支持并发。显而易见，设计中存在一些序列化点——三个重要的序列化点如下：

1. 在刷新CIL时锁定新的事务提交。
2. 将项目添加到CIL并更新项目空间统计信息。
3. 检查点提交顺序。

观察事务提交与CIL刷新之间的交互，很明显这里存在多对一的交互关系。也就是说，唯一限制并发提交数量的因素是日志中为它们预留的空间。对于128MB的日志，实际限制大约是几百个并发事务，这意味着通常每台机器中的每个CPU有一个事务。

事务提交需要锁定刷新的时间相对较长——在锁定CIL刷新期间需要完成日志项目的加锁，这意味着在对象被格式化到内存缓冲区时（即memcpy操作过程中）需要保持锁定。最终可以采用两阶段算法，将格式化与对象加锁分开处理，以减少事务提交侧的锁定时间。

由于潜在的事务提交者数量较多，这个锁实际上需要是一个睡眠锁——如果CIL刷新获取了锁，我们不希望机器中的其他所有CPU都在CIL锁上自旋。鉴于CIL刷新可能涉及遍历成千上万个日志项，因此它会被锁定一段时间，自旋竞争是一个显著的问题。防止大量CPU空转是选择睡眠锁的主要原因，尽管事务提交和CIL刷新双方都没有在持有锁的情况下睡眠。

还应该注意的是，相比异步事务工作负载中的事务提交，CIL刷新是一个相对较少的操作——只有时间才能证明使用读写信号量来排除是否会因为锁的缓存线弹跳而限制事务提交的并发性。

第二个序列化点是在事务提交侧，当项目被插入到CIL中时。由于事务可以并发进入此代码，CIL需要独立于上述提交/刷新排除机制进行保护。这也需要一个独占锁，但由于每次事务持续时间很短，因此使用自旋锁在这里是合适的。有可能这个锁会成为竞争点，但考虑到每次事务持续时间较短，我认为竞争的可能性不大。

最后一个序列化点是作为检查点提交和日志强制排序的一部分运行的检查点提交记录排序代码。触发CIL刷新（即触发日志强制）的代码路径将在将所有日志向量写入日志缓冲区之后但在写入提交记录之前进入一个排序循环。这个循环遍历正在提交的检查点列表，并需要等待检查点完成提交记录写入。因此，它需要一个锁和一个等待变量。日志强制排序也需要相同的锁、列表遍历和阻塞机制来确保检查点的完成。

这两个排序操作可以使用相同的机制，尽管它们等待的事件不同。检查点提交记录排序需要等待检查点上下文包含一个提交LSN（通过完成提交记录写入获得），而日志强制排序则需要等待之前的检查点上下文从提交列表中移除（即已完成）。一个简单的等待变量和广播唤醒（雷群效应）被用来实现这两个序列化队列。它们也使用与CIL相同的锁。如果我们发现CIL锁的竞争过多，或者由于广播唤醒导致的上下文切换太多，这些操作可以放在一个新的自旋锁下，并分配单独的等待列表，以减少锁竞争和因错误事件唤醒的进程数量。
生命周期变更
-----------------

现有日志项生命周期如下：

1. 事务分配
2. 事务预留
3. 锁定项
4. 将项加入事务
    如果尚未附加，
        分配日志项
        将日志项附加到所有者项
    将日志项附加到事务
5. 修改项
    在日志项中记录修改
6. 事务提交
    如果不在CIL中，则将项固定在内存中
    将项格式化到日志向量+缓冲区
    将日志向量和缓冲区附加到日志项
    将日志项插入CIL
    将CIL上下文序列写入事务
    解锁项

    <下一个日志强制操作>

7. CIL推送
    锁定CIL刷新
    链接日志向量和缓冲区
    从CIL移除项
    解锁CIL刷新
    将日志向量写入日志
    序列提交记录
    将检查点上下文附加到日志缓冲区

    <日志缓冲区IO调度>
    <日志缓冲区IO完成>

8. 检查点完成
    标记日志项为已提交
    将项插入AIL
        将提交LSN写入日志项
    解除固定日志项
9. AIL遍历
    锁定项
    标记日志项为干净
    将项刷新到磁盘

    <项IO完成>

10. 日志项从AIL移除
    移动日志尾部
    项解锁

基本上，步骤1-6独立于步骤7运行，而步骤7也独立于步骤8-9。项可以在步骤1-6或步骤8-9中被锁定，同时步骤7正在发生，但只有步骤1-6或8-9可以同时发生。如果日志项在AIL中或处于步骤6和7之间，并且重新进入步骤1-6，则项会被重新记录。只有当步骤8-9被执行并完成后，对象才被认为是干净的。
引入延迟日志后，生命周期中插入了新的步骤：

1. 事务分配
2. 事务预留
3. 锁定项
4. 将项加入事务
    如果尚未附加，
        分配日志项
        将日志项附加到所有者项
    将日志项附加到事务
5. 修改项
    在日志项中记录修改
6. 事务提交
    如果不在CIL中，则将项固定在内存中
    将项格式化到日志向量+缓冲区
    将日志向量和缓冲区附加到日志项
    将日志项插入CIL
    将CIL上下文序列写入事务
    解锁项

    <下一个日志强制操作>

7. CIL推送
    锁定CIL刷新
    链接日志向量和缓冲区
    从CIL移除项
    解锁CIL刷新
    将日志向量写入日志
    序列提交记录
    将检查点上下文附加到日志缓冲区

    <日志缓冲区IO调度>
    <日志缓冲区IO完成>

8. 检查点完成
    标记日志项为已提交
    将项插入AIL
        将提交LSN写入日志项
    解除固定日志项
9. AIL遍历
    锁定项
    标记日志项为干净
    将项刷新到磁盘

    <项IO完成>

10. 日志项从AIL移除
    移动日志尾部
    项解锁

可以看出，两种日志方法之间的生命周期差异仅在于生命周期的中间部分——它们仍然具有相同的开始和结束以及执行约束。唯一不同的是日志项提交到日志本身和完成处理。因此，延迟日志不应引入任何对日志项行为、分配或释放的约束，这些约束已经存在。

由于这种零影响的“插入”延迟日志基础设施以及内部结构的设计避免了磁盘格式的变化，我们可以通过挂载选项基本切换延迟日志和现有机制。从根本上讲，没有理由认为日志管理器不能根据负载特性自动透明地切换方法，但如果延迟日志按设计工作，则没有必要这样做。
