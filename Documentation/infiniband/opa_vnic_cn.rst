Intel Omni-Path (OPA) 虚拟网络接口控制器 (VNIC)

Intel Omni-Path (OPA) 虚拟网络接口控制器 (VNIC) 功能通过在HFI节点间封装以太网数据包，支持在Omni-Path结构上实现以太网功能。
架构
=====
Omni-Path封装的以太网数据包交换模式涉及一个或多个虚拟以太网交换机叠加在Omni-Path结构拓扑之上。Omni-Path结构上的部分HFI节点被允许通过特定的虚拟以太网交换机跨节点交换封装的以太网数据包。这些虚拟以太网交换机是逻辑抽象，通过配置结构上的HFI节点进行报头生成和处理来实现。最简单的配置下，结构上的所有HFI节点通过单一的虚拟以太网交换机交换封装的以太网数据包。一个虚拟以太网交换机实际上是一个独立的以太网网络。配置由以太网管理器（EM）执行，它是可信的Fabric Manager（FM）应用的一部分。HFI节点可以有多个VNIC，每个VNIC连接到不同的虚拟以太网交换机。下图展示了一个包含两个虚拟以太网交换机与两个HFI节点的情况：

此处省略了图形描述。

Omni-Path封装的以太网数据包格式如下所示：
==================== ================================
位数                 字段
==================== ================================
四字0：
0-19                 SLID（低20位）
20-30                长度（四字为单位）
31                   BECN位
32-51                DLID（低20位）
52-56                SC（服务类别）
57-59                RC（路由控制）
60                   FECN位
61-62                L2（=10, 16B格式）
63                   LT（=1, 链路传输头部片段）

四字1：
0-7                  L4类型（=0x78 以太网）
8-11                 SLID[23:20]
12-15                DLID[23:20]
16-31                PKEY
32-47                熵
48-63                预留

四字2：
0-15                 预留
16-31                L4报头
32-63                以太网数据包

四字3至N-1：
0-63                 以太网数据包（填充扩展）

四字N（最后）：
0-23                 以太网数据包（填充扩展）
24-55                ICRC
56-61                尾部
62-63                LT（=01, 链路传输尾部片段）
==================== ================================

在发送端，以太网数据包会进行填充以确保VNIC OPA数据包的四字对齐。“尾部”字段包含填充的字节数量。在接收端，“尾部”字段被读取，并且在将数据包传递给网络堆栈之前，移除填充（以及ICRC、尾部和OPA报头）。L4报头字段包含VNIC端口所属的虚拟以太网交换机ID。在接收端，此字段用于将接收到的VNIC数据包解复用到不同的VNIC端口。
驱动设计
==========
Intel OPA VNIC软件设计如下面的图表所示。OPA VNIC功能具有依赖于硬件的组件和不依赖于硬件的组件。
已添加IB设备的支持以分配和释放RDMA netdev设备。RDMA netdev支持与网络堆栈接口，从而创建标准网络接口。OPA_VNIC是一种RDMA netdev设备类型。
硬件相关的VNIC功能是HFI1驱动程序的一部分。它实现了用于分配和释放OPA_VNIC RDMA netdev的动词。它涉及VNIC功能的硬件资源分配/管理。它与网络堆栈接口并实现了所需的net_device_ops函数。它期望在传输路径中接收Omni-Path封装的以太网数据包，并提供了硬件访问权限。在将数据包传递给网络堆栈之前，它从接收的数据包中剥离了Omni-Path报头。它还实现了RDMA netdev控制操作。
OPA VNIC 模块实现了与硬件无关的 VNIC 功能。它由两部分组成：VNIC 以太网管理代理（VEMA）和 VNIC netdev 部分。

VEMA 自注册为 InfiniBand (IB) 核心的一个客户端，并与 IB MAD 堆栈进行交互。它与以太网管理器（EM）及 VNIC netdev 交换管理信息。VNIC netdev 部分负责分配和释放 OPA_VNIC RDMA netdev 设备。在需要时，它会覆盖由硬件相关 VNIC 驱动程序设置的 `net_device_ops` 函数，以适应任何控制操作。此外，它还处理在传输路径中将以太网数据包封装 Omni-Path 头的操作。对于每个 VNIC 接口，封装所需的配置信息由 EM 通过 VEMA 的 MAD 接口进行配置。它还通过调用 RDMA netdev 控制操作将任何控制信息传递给硬件相关的驱动程序：

```
+-------------------+ +----------------------+
|                   | |       Linux          |
|     IB MAD        | |      Network         |
|                   | |       Stack          |
+-------------------+ +----------------------+
                 |               |          |
                 |               |          |
        +----------------------------+      |
        |                            |      |
        |      OPA VNIC Module       |      |
        |  (OPA VNIC RDMA Netdev     |      |
        |     & EMA functions)       |      |
        |                            |      |
        +----------------------------+      |
                    |                       |
                    |                       |
           +------------------+             |
           |     IB core      |             |
           +------------------+             |
                    |                       |
                    |                       |
        +--------------------------------------------+
        |                                            |
        |      HFI1 Driver with VNIC support         |
        |                                            |
        +--------------------------------------------+
```

- **IB MAD**：InfiniBand 管理设备，用于与 VEMA 进行通信。
- **Linux Network Stack**：Linux 内核中的网络堆栈。
- **OPA VNIC Module**：实现 VNIC 功能的模块，包括 OPA VNIC RDMA Netdev 和 EMA 功能。
- **IB core**：InfiniBand 核心组件，用于管理 IB 设备。
- **HFI1 Driver with VNIC support**：支持 VNIC 的 HFI1 驱动程序。
