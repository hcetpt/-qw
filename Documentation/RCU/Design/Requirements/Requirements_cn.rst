RCU需求概览
=============

版权所有 © IBM 公司，2015年

作者：Paul E. McKenney

本文档的初始版本发表在LWN的文章中：
[第一部分](https://lwn.net/Articles/652156/)、
[第二部分](https://lwn.net/Articles/652677/) 和
[第三部分](https://lwn.net/Articles/653326/)

简介
----

读-复制-更新（RCU）是一种同步机制，通常作为读者-写者锁的替代方案。RCU 的独特之处在于更新者不会阻塞读者，这意味着 RCU 的读端原语可以非常快速且具有可扩展性。此外，更新者可以在与读者并发的情况下进行有用的前进步骤。然而，所有这些 RCU 读者和更新者之间的并发性引发了关于 RCU 读者究竟在做什么的问题，进而引发关于 RCU 究竟有哪些要求的问题。

因此，本文档总结了 RCU 的要求，并可视为 RCU 的非正式高层次规范。重要的是要理解 RCU 的规范主要是经验性的；事实上，我是通过艰难的方式了解到许多这些要求的。这种情况可能会引起一些困扰，但是这一学习过程不仅非常有趣，而且能够与这么多愿意将技术应用于新方式的人合作也是一种极大的荣幸。

除此之外，以下是目前已知的 RCU 要求类别：

1. [基本要求]_
2. [基本非要求]_
3. [并发事实]_
4. [实现质量要求]_
5. [Linux 内核复杂性]_
6. [软件工程要求]_
7. [其他 RCU 变体]_
8. [可能的未来变化]_

之后是总结，不过每个快速测验的答案紧随其后。使用鼠标选择大块空白区域即可查看答案。

基本要求
----------

RCU 的基本要求是 RCU 接近于硬数学要求的部分。这些要求包括：

1. [优雅期保证]_
2. [发布/订阅保证]_
3. [内存屏障保证]_
4. [RCU 原语无条件执行保证]_
5. [读到写的升级保证]_

优雅期保证
~~~~~~~~~~~~~

RCU 的优雅期保证是预先计划好的：Jack Slingwine 和我在 1990 年代初期开始研究 RCU（当时称为“rclock”）时就牢牢地记住了这个保证。不过，过去二十年的 RCU 使用经验产生了对这个保证更为详细的了解。

RCU 的优雅期保证允许更新者等待所有现有 RCU 读端临界区的完成。一个 RCU 读端临界区以标记 rcu_read_lock() 开始，并以标记 rcu_read_unlock() 结束。这些标记可以嵌套，而 RCU 将一个嵌套集视为一个大的 RCU 读端临界区。

生产级的 rcu_read_lock() 和 rcu_read_unlock() 实现极其轻量级，在为生产环境构建的 Linux 内核中（带有 `CONFIG_PREEMPTION=n`）实际上没有任何开销。

此保证允许以极低的读者开销强制顺序执行，例如：

```c
1 int x, y;
2
3 void thread0(void)
4 {
5   rcu_read_lock();
6   r1 = READ_ONCE(x);
7   r2 = READ_ONCE(y);
8   rcu_read_unlock();
9 }
10
11 void thread1(void)
12 {
13   WRITE_ONCE(x, 1);
14   synchronize_rcu();
15   WRITE_ONCE(y, 1);
16 }
```

由于第 14 行上的 synchronize_rcu() 等待所有现有读者，任何从 `x` 加载值为零的 thread0() 实例必须在 thread1() 存储到 `y` 之前完成，因此该实例还必须从 `y` 加载值为零。同样，任何从 `y` 加载值为一的 thread0() 实例必须在 synchronize_rcu() 启动之后启动，因此也必须从 `x` 加载值为一。因此，结果：

```c
(r1 == 0 && r2 == 1)
```

无法发生。

+-----------------------------------------------------------------------+
| **快速测验**：                                                        |
+-----------------------------------------------------------------------+
| 等一下！你说更新者可以在与读者并发的情况下取得有用的进展，但现有读者会阻塞 synchronize_rcu()！！！|
| 你到底想骗谁？？？                                                   |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 首先，如果更新者不希望被读者阻塞，他们可以使用 call_rcu() 或 kfree_rcu()，这将在后面讨论。       |
| 其次，即使使用 synchronize_rcu()，其他更新端代码也会与读者并发运行，无论这些读者是否已经存在。     |
+-----------------------------------------------------------------------+

这种场景类似于 DYNIX/ptx 中 RCU 的最早用途之一，它管理分布式锁管理器过渡到适合处理节点故障恢复的状态，大致如下：

```c
1 #define STATE_NORMAL        0
2 #define STATE_WANT_RECOVERY 1
3 #define STATE_RECOVERING    2
4 #define STATE_WANT_NORMAL   3
5
6 int state = STATE_NORMAL;
7
8 void do_something_dlm(void)
9 {
10   int state_snap;
11
12   rcu_read_lock();
13   state_snap = READ_ONCE(state);
14   if (state_snap == STATE_NORMAL)
15     do_something();
16   else
17     do_something_carefully();
18   rcu_read_unlock();
19 }
20
21 void start_recovery(void)
22 {
23   WRITE_ONCE(state, STATE_WANT_RECOVERY);
24   synchronize_rcu();
25   WRITE_ONCE(state, STATE_RECOVERING);
26   recovery();
27   WRITE_ONCE(state, STATE_WANT_NORMAL);
28   synchronize_rcu();
29   WRITE_ONCE(state, STATE_NORMAL);
30 }
```

do_something_dlm() 中的 RCU 读端临界区与 start_recovery() 中的 synchronize_rcu() 配合工作，以保证 do_something() 从未与 recovery() 并发运行，但在 do_something_dlm() 中几乎没有或完全没有同步开销。

+-----------------------------------------------------------------------+
| **快速测验**：                                                        |
+-----------------------------------------------------------------------+
| 第 28 行上的 synchronize_rcu() 为什么需要？                          |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 如果没有这个额外的优雅期，内存重新排序可能导致 do_something_dlm() 在 recovery() 的最后阶段并发执行 do_something()。|
+-----------------------------------------------------------------------+

为了避免诸如死锁等致命问题，RCU 读端临界区内不得包含 synchronize_rcu() 调用。
同样地，RCU读端临界区中不得包含任何直接或间接等待`synchronize_rcu()`调用完成的内容。
尽管RCU的宽限期保证本身非常有用，并且有`许多使用场景 <https://lwn.net/Articles/573497/>`__，但最好能够使用RCU来协调对链表数据结构的读端访问。对于这一点，宽限期保证是不够的，如下面的`add_gp_buggy()`函数所示。我们稍后会查看读端代码，但在此期间，可以将读端视为无锁获取`gp`指针，并且如果加载的值非`NULL`，则无锁访问`->a`和`->b`字段：

```c
1 bool add_gp_buggy(int a, int b)
2 {
3   p = kmalloc(sizeof(*p), GFP_KERNEL);
4   if (!p)
5     return -ENOMEM;
6   spin_lock(&gp_lock);
7   if (rcu_access_pointer(gp)) {
8     spin_unlock(&gp_lock);
9     return false;
10   }
11   p->a = a;
12   p->b = a;
13   gp = p; /* 顺序错误 */
14   spin_unlock(&gp_lock);
15   return true;
16 }
```

问题在于编译器和弱序CPU有权重新排序这段代码如下：

```c
1 bool add_gp_buggy_optimized(int a, int b)
2 {
3   p = kmalloc(sizeof(*p), GFP_KERNEL);
4   if (!p)
5     return -ENOMEM;
6   spin_lock(&gp_lock);
7   if (rcu_access_pointer(gp)) {
8     spin_unlock(&gp_lock);
9     return false;
10   }
11   gp = p; /* 顺序错误 */
12   p->a = a;
13   p->b = a;
14   spin_unlock(&gp_lock);
15   return true;
16 }
```

如果RCU读端在`add_gp_buggy_optimized`执行第11行之后获取`gp`，那么它将在`->a`和`->b`字段中看到垃圾数据。这只是编译器和硬件优化可能引起麻烦的众多方式之一。因此，显然我们需要某种方法来阻止编译器和CPU以这种方式重新排序，这引出了下节讨论的发布-订阅保证。

### 发布/订阅保证
RCU的发布-订阅保证允许在不干扰RCU读端的情况下向链表数据结构插入数据。更新者使用`rcu_assign_pointer()`插入新数据，而读端使用`rcu_dereference()`访问数据，无论是新的还是旧的。以下是一个插入示例：

```c
1 bool add_gp(int a, int b)
2 {
3   p = kmalloc(sizeof(*p), GFP_KERNEL);
4   if (!p)
5     return -ENOMEM;
6   spin_lock(&gp_lock);
7   if (rcu_access_pointer(gp)) {
8     spin_unlock(&gp_lock);
9     return false;
10   }
11   p->a = a;
12   p->b = a;
13   rcu_assign_pointer(gp, p);
14   spin_unlock(&gp_lock);
15   return true;
16 }
```

第13行的`rcu_assign_pointer()`概念上等同于简单的赋值语句，但也保证其赋值会在第11行和第12行的两个赋值之后发生，类似于C11的`memory_order_release`存储操作。它还防止了许多“有趣”的编译器优化，例如，在赋值之前立即使用`gp`作为临时位置。

| **快速测验**：
| 但是`rcu_assign_pointer()`并没有阻止对`p->a`和`p->b`的两次赋值被重新排序。这会不会也引起问题？
| **答案**：
| 不会。读者直到`gp`赋值时才可以看到这两个字段，此时这两个字段已完全初始化。因此，重新排序对`p->a`和`p->b`的赋值不可能引起任何问题。

人们很容易认为读端无需做任何特殊的事情来控制其对RCU保护数据的访问，如下面的`do_something_gp_buggy()`所示：

```c
1 bool do_something_gp_buggy(void)
2 {
3   rcu_read_lock();
4   p = gp;  /* 各种优化！ */
5   if (p) {
6     do_something(p->a, p->b);
7     rcu_read_unlock();
8     return true;
9   }
10   rcu_read_unlock();
11   return false;
12 }
```

然而，这种诱惑必须抵制，因为编译器（或弱序CPU，如DEC Alpha）有多种方法会使这段代码出错。例如，如果编译器缺少寄存器，它可能会选择从`gp`重新获取而不是在`p`中保留一个单独的副本，如下所示：

```c
1 bool do_something_gp_buggy_optimized(void)
2 {
3   rcu_read_lock();
4   if (gp) { /* 各种优化！ */
5     do_something(gp->a, gp->b);
6     rcu_read_unlock();
7     return true;
8   }
9   rcu_read_unlock();
10   return false;
11 }
```

如果此函数与一系列替换当前结构的新结构并发运行，则`gp->a`和`gp->b`的获取可能来自两个不同的结构，这可能导致严重的混乱。为了防止这种情况（以及其他情况），`do_something_gp()`使用`rcu_dereference()`从`gp`获取：

```c
1 bool do_something_gp(void)
2 {
3   rcu_read_lock();
4   p = rcu_dereference(gp);
5   if (p) {
6     do_something(p->a, p->b);
7     rcu_read_unlock();
8     return true;
9   }
10   rcu_read_unlock();
11   return false;
12 }
```

`rcu_dereference()`在Linux内核中使用volatile转换（对于DEC Alpha使用内存屏障）。一旦出现高质量的C11 `memory_order_consume` 实现，`rcu_dereference()`可以实现为`memory_order_consume`加载。无论具体实现如何，由`rcu_dereference()`获取的指针不得在包含该`rcu_dereference()`的最外层RCU读端临界区之外使用，除非相应数据元素的保护已从RCU转移到其他同步机制，通常是锁定或引用计数（参见 ../../rcuref.rst）。

简而言之，更新者使用`rcu_assign_pointer()`，而读端使用`rcu_dereference()`，这两者一起工作以确保读端对新添加的数据元素具有一致视图。当然，还需要从RCU保护的数据结构中移除元素，例如，可以使用以下过程：

1. 从包含的结构中移除数据元素。
2. 等待所有现有的RCU读端临界区完成（因为只有现有的读端才可能有一个指向新移除数据元素的引用）。
3. 此时，只有更新者有一个指向新移除数据元素的引用，因此可以安全地回收数据元素，例如通过将其传递给`kfree()`。
此过程由`remove_gp_synchronous()`实现：

   ::

       1 bool remove_gp_synchronous(void)
       2 {
       3   struct foo *p;
       4
       5   spin_lock(&gp_lock);
       6   p = rcu_access_pointer(gp);
       7   if (!p) {
       8     spin_unlock(&gp_lock);
       9     return false;
      10   }
      11   rcu_assign_pointer(gp, NULL);
      12   spin_unlock(&gp_lock);
      13   synchronize_rcu();
      14   kfree(p);
      15   return true;
      16 }

此函数非常简单，其中第13行在第14行释放旧数据元素之前等待一个宽限期。这种等待确保了读取者会在引用`p`的数据元素被释放之前到达`do_something_gp()`的第7行。第6行的`rcu_access_pointer()`与`rcu_dereference()`类似，但有以下几点不同：

1. `rcu_access_pointer()`返回的值不能被解引用。如果你想访问该指针所指向的内容以及指针本身，请使用`rcu_dereference()`而不是`rcu_access_pointer()`。
2. 对`rcu_access_pointer()`的调用不需要保护。相反，`rcu_dereference()`必须在一个RCU读侧临界区或指针不会改变的代码段中调用，例如，在由相应更新侧锁保护的代码中。

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 如果没有`rcu_dereference()`或`rcu_access_pointer()`，编译器可能会进行哪些破坏性优化？ |
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 首先看如果没有使用`rcu_dereference()`时`do_something_gp()`会发生什么。它可能会重用从前从同一指针获取的值。它也可能以字节为单位从`gp`获取指针，导致*加载撕裂*，进而导致两个不同指针值的字节混合。甚至可能使用值推测优化，在这里它做出了错误的猜测，但当它检查值时，更新已经改变了指针以匹配错误的猜测。太糟糕了，任何在此期间返回初始化前垃圾的解引用！
| 对于`remove_gp_synchronous()`，只要所有对`gp`的修改都在持有`gp_lock`的情况下进行，上述优化是无害的。然而，如果定义`gp`时使用了`__rcu`，但在不使用`rcu_access_pointer()`或`rcu_dereference()`的情况下访问它，`sparse`会发出警告。
+-----------------------------------------------------------------------+

简而言之，RCU的发布订阅保证是由`rcu_assign_pointer()`和`rcu_dereference()`的组合提供的。这一保证允许数据元素安全地添加到RCU保护的链式数据结构中，而不会中断RCU读取者。这一保证可以与宽限期保证结合使用，也允许从RCU保护的链式数据结构中移除数据元素，同样不会中断RCU读取者。
这一保证只是部分预设的。DYNIX/ptx使用了一个显式的内存屏障用于发布，但它没有类似于`rcu_dereference()`的订阅机制，也没有类似于后来包含在`rcu_dereference()`中的依赖顺序屏障。这些操作的需求在1990年代末与DEC Alpha架构师的一次会议上突然显现出来，当时DEC还是一家独立公司。Alpha架构师花了大约一个小时才说服我需要某种形式的屏障，然后我又花了两个小时来说服他们他们的文档没有明确这一点。近年来与C和C++标准委员会的合作提供了很多关于编译器技巧和陷阱的教育。简而言之，1990年代初的编译器要简单得多，但在2015年，不要想省略`rcu_dereference()`！

内存屏障保证
~~~~~~~~~~~~~~

前一节的简单链式数据结构场景清楚地展示了多CPU系统上RCU严格的内存排序保证的必要性：

1. 每个在`synchronize_rcu()`开始之前进入RCU读侧临界区的CPU都会在RCU读侧临界区结束和`synchronize_rcu()`返回之间执行一个完整的内存屏障。如果没有这个保证，现有的RCU读侧临界区可能会在`remove_gp_synchronous()`第14行的`kfree()`之后仍然保留对新删除的`struct foo`的引用。
2. 每个在`synchronize_rcu()`返回之后结束RCU读侧临界区的CPU都会在`synchronize_rcu()`开始和RCU读侧临界区开始之间执行一个完整的内存屏障。如果没有这个保证，`remove_gp_synchronous()`第14行的`kfree()`之后运行的RCU读侧临界区可能会稍后运行`do_something_gp()`并发现新删除的`struct foo`。
3. 如果调用`synchronize_rcu()`的任务保留在给定CPU上，则该CPU在`synchronize_rcu()`执行期间会执行一个完整的内存屏障。这个保证确保`remove_gp_synchronous()`第14行的`kfree()`确实是在第11行的移除之后执行的。
4. 如果调用`synchronize_rcu()`的任务在一组CPU之间迁移，则该组中的每个CPU在`synchronize_rcu()`执行期间都会执行一个完整的内存屏障。这个保证不仅确保`remove_gp_synchronous()`第14行的`kfree()`确实是在第11行的移除之后执行的，而且还考虑到了执行`synchronize_rcu()`的线程在此期间迁移的情况。

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 鉴于多个CPU可以在任何时候无序地开始RCU读侧临界区，RCU怎么可能知道某个RCU读侧临界区是否在某个`synchronize_rcu()`实例之前开始呢？
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 如果RCU无法判断某个RCU读侧临界区是否在某个`synchronize_rcu()`实例之前开始，那么它必须假设RCU读侧临界区先开始。换句话说，只有当RCU能够证明`synchronize_rcu()`先开始时，它才能避免等待某个RCU读侧临界区。
| 相关的问题是“当`rcu_read_lock()`不生成任何代码时，为什么它与宽限期的关系重要？” 答案是重要的不是`rcu_read_lock()`本身的关系，而是封闭的RCU读侧临界区内代码与宽限期前后代码的关系。如果我们采取这种观点，那么某个RCU读侧临界区在某个宽限期之前开始，当一些在宽限期之前的访问观察到了临界区内某些访问的效果，在这种情况下，临界区内任何访问都不会观察到宽限期之后任何访问的效果。
| 截至2016年末，RCU的数学模型采用了这种观点，例如，见`2016 LinuxCon EU <http://www2.rdrop.com/users/paulmck/scalability/paper/LinuxMM.2016.10.04c.LCE.pdf>`__ 的第62和63页幻灯片。
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 第一个和第二个保证要求难以置信的严格排序！所有这些内存屏障真的需要吗？
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 是的，它们确实是必需的。要理解第一个保证为何需要，考虑以下事件序列：
| #. CPU 1: `rcu_read_lock()`
| #. CPU 1: `q = rcu_dereference(gp); /* 很有可能返回p */`
| #. CPU 0: `list_del_rcu(p);`
| #. CPU 0: `synchronize_rcu()` 开始。
| #. CPU 1: `do_something_with(q->a); /* 没有smp_mb()，所以可能发生在kfree()之后 */`
| #. CPU 1: `rcu_read_unlock()`
| #. CPU 0: `synchronize_rcu()` 返回。
| #. CPU 0: `kfree(p);`
| 因此，RCU读侧临界区结束和宽限期结束之间绝对必须有一个完整的内存屏障。
| 表明第二个规则必要的事件序列大致相似：
| #. CPU 0: `list_del_rcu(p);`
| #. CPU 0: `synchronize_rcu()` 开始。
| #. CPU 1: `rcu_read_lock()`
| #. CPU 1: `q = rcu_dereference(gp); /* 如果没有内存屏障，可能会返回p */`
| #. CPU 0: `synchronize_rcu()` 返回。
| #. CPU 0: `kfree(p);`
| #. CPU 1: `do_something_with(q->a); /* 崩溃 */`
| #. CPU 1: `rcu_read_unlock()`
| 同样，如果没有宽限期开始和RCU读侧临界区开始之间的内存屏障，CPU 1 可能最终会访问自由列表。
| “如同”规则当然适用，因此任何表现得好像适当内存屏障存在的情况都是正确的实现。话虽如此，欺骗自己相信你遵守了如同规则比真正遵守它要容易得多！
+-----------------------------------------------------------------------+

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 你声称`rcu_read_lock()`和`rcu_read_unlock()`在某些内核构建中绝对不生成任何代码。这意味着编译器可能会任意重新排列连续的RCU读侧临界区。鉴于这样的重新排列，如果某个RCU读侧临界区已完成，你怎么能确定所有先前的RCU读侧临界区都完成了？编译器的重新排列会不会使得这变得不可能确定？
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 在`rcu_read_lock()`和`rcu_read_unlock()`绝对不生成任何代码的情况下，RCU仅在特殊位置推断静默状态，例如，在调度程序内部。因为对`schedule()`的调用最好阻止调用代码对共享变量的访问跨过对`schedule()`的调用，如果RCU检测到某个RCU读侧临界区的结束，它必然也会检测到所有先前RCU读侧临界区的结束，无论编译器多么激进地重新排列代码。再次强调，这都假设编译器不能跨过调度程序调用、中断处理程序、空闲循环、用户模式代码等进行重新排列。但如果你的内核构建允许这种重新排列，你破坏的不仅仅是RCU！
+-----------------------------------------------------------------------+

请注意，这些内存屏障要求并不会取代RCU的基本要求，即宽限期等待所有预先存在的读取者。相反，本节中提到的内存屏障必须以强制执行这一基本要求的方式运作。当然，不同的实现以不同的方式强制执行这一要求，但必须强制执行。

RCU原语无条件执行保证
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

常见的RCU原语是无条件的。它们被调用，完成任务，并返回，没有任何错误的可能性，也不需要重试。这是RCU设计哲学的关键。
然而，这种哲学是务实的而非顽固的。如果有人提出了某个特定条件RCU原语的良好理由，它很可能会被实现并添加进来。毕竟，这一保证是逆向工程的结果，而不是预先设定的。RCU原语的无条件性质最初是实现的一个偶然结果，后来的经验表明带有条件原语的同步原语使我将这一偶然提升为保证。因此，将条件原语添加到RCU中的理由需要基于详细且有说服力的用例。
### 保证读到写升级

就RCU而言，总是在RCU读侧临界区中执行更新是可行的。例如，该RCU读侧临界区可能会搜索给定的数据元素，然后可能会获取更新侧自旋锁来更新该元素，所有这些操作都在同一个RCU读侧临界区内完成。当然，在调用`synchronize_rcu()`之前需要退出RCU读侧临界区，但是通过使用本文档稍后描述的`call_rcu()`和`kfree_rcu()`API成员可以避免这种不便。

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 但升级到写入操作是如何排除其他读者的？                                 |
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 它并没有这样做，就像正常的RCU更新一样，它们也不排除RCU读者。           |
+-----------------------------------------------------------------------+

这一保证使得查找代码可以在读侧和更新侧代码之间共享，并且是有预谋的，在最早的DYNIX/ptx RCU文档中就已出现。
### 根本的非需求

RCU提供了极其轻量级的读取器，并且其读侧保证虽然非常有用，但也相应地轻量级。因此，很容易假设RCU提供的保证比它实际提供的更多。当然，RCU不保证的内容清单是无限长的，然而以下部分列出了一些引起混淆的非保证。除非另有说明，这些非保证也是有预谋的：
1. `读取器施加最小顺序`
2. `读取器不排斥更新者`
3. `更新者只等待旧读取器`
4. `优雅期不划分读侧临界区`
5. `读侧临界区不划分优雅期`

### 读取器施加最小顺序

读侧标记如`rcu_read_lock()`和`rcu_read_unlock()`除了通过与优雅期API（如`synchronize_rcu()`）的交互之外，根本不提供任何顺序保证。为了理解这一点，请考虑以下两个线程：

```plaintext
 1 void thread0(void)
 2 {
 3   rcu_read_lock();
 4   WRITE_ONCE(x, 1);
 5   rcu_read_unlock();
 6   rcu_read_lock();
 7   WRITE_ONCE(y, 1);
 8   rcu_read_unlock();
 9 }
10
11 void thread1(void)
12 {
13   rcu_read_lock();
14   r1 = READ_ONCE(y);
15   rcu_read_unlock();
16   rcu_read_lock();
17   r2 = READ_ONCE(x);
18   rcu_read_unlock();
19 }
```

在`thread0()`和`thread1()`并发执行之后，完全有可能得到：

```plaintext
(r1 == 1 && r2 == 0)
```

（即`y`似乎在`x`之前被赋值），这在`rcu_read_lock()`和`rcu_read_unlock()`具有显著顺序属性的情况下是不可能的。但它们没有这样的属性，所以CPU有权进行大量重排序。这是设计使然：任何显著的顺序约束都会减慢这些快路径API的速度。

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 编译器不能也重新排序这段代码吗？                                       |
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 不，`READ_ONCE()`和`WRITE_ONCE()`中的易失性转换防止编译器在这种特定情况下重新排序。 |
+-----------------------------------------------------------------------+

### 读取器不排斥更新者

`rcu_read_lock()`和`rcu_read_unlock()`都不排斥更新。它们所做的一切只是阻止优雅期结束。以下示例说明了这一点：

```plaintext
 1 void thread0(void)
 2 {
 3   rcu_read_lock();
 4   r1 = READ_ONCE(y);
 5   if (r1) {
 6     do_something_with_nonzero_x();
 7     r2 = READ_ONCE(x);
 8     WARN_ON(!r2); /* BUG!!! */
 9   }
10   rcu_read_unlock();
11 }
12
13 void thread1(void)
14 {
15   spin_lock(&my_lock);
16   WRITE_ONCE(x, 1);
17   WRITE_ONCE(y, 1);
18   spin_unlock(&my_lock);
19 }
```

如果`thread0()`函数的`rcu_read_lock()`排斥`thread1()`函数的更新，则`WARN_ON()`永远不会触发。但实际上`rcu_read_lock()`除了随后的优雅期外，几乎不排斥任何东西，而`thread1()`没有任何优雅期，所以`WARN_ON()`确实会触发。

### 更新者只等待旧读取器

可能有人会误以为在`synchronize_rcu()`完成后，不再有任何读取器在执行。必须避免这种诱惑，因为新的读取器可以在`synchronize_rcu()`启动后立即开始，而`synchronize_rcu()`没有义务等待这些新读取器。

+-----------------------------------------------------------------------+
| **快速问答**：                                                       |
+-----------------------------------------------------------------------+
| 假设`synchronize_rcu()`确实等待所有读取器完成而不是只等待现有读取器。更新者能依赖多久没有读取器？ |
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 一点时间都不能。即使`synchronize_rcu()`等到所有读取器完成，一个新的读取器也可能在`synchronize_rcu()`完成后立即开始。因此，`synchronize_rcu()`后的代码永远不能依赖于没有读取器。 |
+-----------------------------------------------------------------------+

### 优雅期不划分读侧临界区

可能有人会误以为如果一个RCU读侧临界区的一部分发生在某个优雅期之前，而另一个RCU读侧临界区的一部分发生在同一个优雅期之后，那么第一个RCU读侧临界区的所有部分必须在第二个之前。然而，事实并非如此：一个优雅期不会划分RCU读侧临界区集。可以通过以下情况举例说明，其中`x`、`y`和`z`最初都为零：

```plaintext
 1 void thread0(void)
 2 {
 3   rcu_read_lock();
 4   WRITE_ONCE(a, 1);
 5   WRITE_ONCE(b, 1);
 6   rcu_read_unlock();
 7 }
 8
 9 void thread1(void)
10 {
11   r1 = READ_ONCE(a);
12   synchronize_rcu();
13   WRITE_ONCE(c, 1);
14 }
15
16 void thread2(void)
17 {
18   rcu_read_lock();
19   r2 = READ_ONCE(b);
20   r3 = READ_ONCE(c);
21   rcu_read_unlock();
22 }
```

结果：

```plaintext
(r1 == 1 && r2 == 0 && r3 == 1)
```

完全是可能的。下图展示了这种情况，每个圈起来的“QS”表示RCU记录每个线程的一个*静止状态*，即RCU知道线程不可能处于当前优雅期之前的RCU读侧临界区中：

.. kernel-figure:: GPpartitionReaders1.svg

如果需要以这种方式划分RCU读侧临界区，则需要使用两个优雅期，其中一个优雅期已知在另一个优雅期开始之前结束：

```plaintext
 1 void thread0(void)
 2 {
 3   rcu_read_lock();
 4   WRITE_ONCE(a, 1);
 5   WRITE_ONCE(b, 1);
 6   rcu_read_unlock();
 7 }
 8
 9 void thread1(void)
10 {
11   r1 = READ_ONCE(a);
12   synchronize_rcu();
13   WRITE_ONCE(c, 1);
14 }
15
16 void thread2(void)
17 {
18   r2 = READ_ONCE(c);
19   synchronize_rcu();
20   WRITE_ONCE(d, 1);
21 }
22
23 void thread3(void)
24 {
25   rcu_read_lock();
26   r3 = READ_ONCE(b);
27   r4 = READ_ONCE(d);
28   rcu_read_unlock();
29 }
```

这里，如果`(r1 == 1)`，则`thread0()`对`b`的写入必须在`thread1()`的优雅期结束之前发生。如果同时`(r4 == 1)`，则`thread3()`对`b`的读取必须在`thread2()`的优雅期开始之后发生。如果同时`(r2 == 1)`，则`thread1()`的优雅期结束必须在`thread2()`的优雅期开始之前。这意味着两个RCU读侧临界区不能重叠，从而保证`(r3 == 1)`。因此，结果：

```plaintext
(r1 == 1 && r2 == 1 && r3 == 0 && r4 == 1)
```

不可能发生。

这一非需求也是非预谋的，但在研究RCU与内存顺序之间的交互时变得明显。
读取侧临界区不会分割宽限期
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

假设如果一个RCU读取侧临界区发生在一对宽限期之间，那么这些宽限期不能重叠。然而，这种假设是不可取的，以下示例可以说明这一点，所有变量最初都为零：

   ::

       1 void thread0(void)
       2 {
       3   rcu_read_lock();
       4   WRITE_ONCE(a, 1);
       5   WRITE_ONCE(b, 1);
       6   rcu_read_unlock();
       7 }
       8
       9 void thread1(void)
      10 {
      11   r1 = READ_ONCE(a);
      12   synchronize_rcu();
      13   WRITE_ONCE(c, 1);
      14 }
      15
      16 void thread2(void)
      17 {
      18   rcu_read_lock();
      19   WRITE_ONCE(d, 1);
      20   r2 = READ_ONCE(c);
      21   rcu_read_unlock();
      22 }
      23
      24 void thread3(void)
      25 {
      26   r3 = READ_ONCE(d);
      27   synchronize_rcu();
      28   WRITE_ONCE(e, 1);
      29 }
      30
      31 void thread4(void)
      32 {
      33   rcu_read_lock();
      34   r4 = READ_ONCE(b);
      35   r5 = READ_ONCE(e);
      36   rcu_read_unlock();
      37 }

在这种情况下，以下结果是完全可能的：

   ::

      (r1 == 1 && r2 == 1 && r3 == 1 && r4 == 0 && r5 == 1)

如图所示：

.. kernel-figure:: ReadersPartitionGP1.svg

再次强调，RCU读取侧临界区可以与给定宽限期的大部分时间重叠，只要不与整个宽限期重叠即可。因此，RCU读取侧临界区无法将一对RCU宽限期分开。
+-----------------------------------------------------------------------+
| **快速测验**：                                                        |
+-----------------------------------------------------------------------+
| 需要多少个由RCU读取侧临界区分隔的宽限期序列才能在链的开始和结束处分隔RCU读取侧临界区？|
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 理论上，需要无限多个。实际上，所需数量取决于实现细节和时间因素。因此，即使在实践中，RCU用户也必须遵循理论而非实际答案。|
+-----------------------------------------------------------------------+

并发生活的事实
-------------------------

这些并发生活的事实不仅限于RCU，但RCU实现必须遵守它们。因此，有必要重复这些事实：

1. 任何CPU或任务随时都可能被延迟，并且任何试图通过禁用抢占、中断或其他方式来避免这些延迟的尝试都是徒劳的。这在可抢占的用户级环境中以及虚拟化环境中（其中给定的来宾OS的VCPUs可以随时被底层hypervisor抢占）最为明显，但在裸机环境中也会由于ECC错误、NMIs和其他硬件事件而发生。尽管超过约20秒的延迟可能会导致系统崩溃，但RCU实现有义务使用能够容忍极长延迟的算法，但“极长”的时间不足以使64位计数器溢出。
2. 编译器和CPU都可以重新排序内存访问。在关键位置，RCU必须使用编译器指令和内存屏障指令来保持顺序。
3. 对给定缓存行中内存位置的冲突写入会导致昂贵的缓存缺失。更多的并发写入和更频繁的并发写入会导致更严重的性能下降。因此，RCU有义务使用具有足够局部性的算法以避免显著的性能和扩展性问题。
4. 大致来说，在任何给定的独占锁保护下，只能进行一个CPU的工作量。因此，RCU必须使用可扩展的锁定设计。
5. 计数器是有限的，尤其是在32位系统上。因此，RCU对计数器的使用必须能够容忍计数器溢出，或者设计得使得计数器溢出需要的时间远远超过单个系统运行的时间。例如，RCU的dyntick-idle嵌套计数器允许64位中的54位用于中断嵌套级别（此计数器即使在32位系统上也是64位）。溢出此计数器需要在一个CPU上发生2^54次半中断而不让该CPU进入空闲状态。如果每微秒发生一次半中断，则需要570年才能溢出此计数器，这目前被认为是可以接受的时间长度。
6. Linux系统可以在单个共享内存环境中运行数千个CPU。因此，RCU必须特别关注高扩展性。

最后一个并发生活的事实意味着RCU必须特别注意前面的事实。在1990年代，Linux可能会扩展到数千个CPU系统的观点会受到一些怀疑，但这些要求即使在1990年代初期也不会令人惊讶。
实现质量要求
--------------------------------------

这些部分列出了实现质量要求。虽然忽略这些要求的RCU实现仍然可以使用，但它可能会受到限制，使其不适合工业级生产使用。实现质量要求的类别如下：

1. `专业化`_
2. `性能和可扩展性`_
3. `前进步骤`_
4. `组合性`_
5. `边缘情况`_

这些类别将在下面的部分中详细讨论。
专业化
~~~~~~~~~~~~~~

RCU一直主要用于读取为主的场景，这意味着RCU的读取侧原语经过了优化，通常是以更新侧原语为代价的。根据目前的经验，以下是几种情况：

1. 读取为主的非关键数据，陈旧和不一致的数据不是问题：RCU表现很好！
2. 读取为主的非关键数据，数据必须一致：RCU表现良好
#. 读写数据，其中数据必须保持一致：RCU *可能*可以正常工作
或者不行

#. 主要是写的数据，其中数据必须保持一致：RCU 很不可能是合适的工具，但有以下例外情况，RCU 可以提供：

   a. 为更新友好的机制提供存在保证
   b. 用于实时用途的无等待读取侧原语

这种对主要读取情况的关注意味着 RCU 必须与其他同步原语协同工作。例如，前面讨论的 `add_gp()` 和 `remove_gp_synchronous()` 示例使用 RCU 来保护读者，并使用锁来协调更新者。然而，这种需求远远不止于此，要求在 RCU 的读取侧临界区中可以合法使用各种同步原语，包括自旋锁、序列锁、原子操作、引用计数和内存屏障。

+-----------------------------------------------------------------------+
| **快速问答**：                                                      |
+-----------------------------------------------------------------------+
| 睡眠锁呢？                                                            |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 在 Linux 内核的 RCU 读取侧临界区内禁止使用睡眠锁，因为在此类临界区内放置静止状态（在这种情况下为自愿上下文切换）是不合法的。然而，在用户空间的 RCU 读取侧临界区内以及 Linux 内核的可睡眠 RCU (`SRCU`) 读取侧临界区内可以使用睡眠锁。此外，-rt 补丁集将自旋锁转换为睡眠锁，以便相应的临界区可以被抢占，这也意味着这些经过睡眠化处理的自旋锁（但不是其他睡眠锁！）可以在 -rt-Linux 内核的 RCU 读取侧临界区内获取。请注意，在普通的 RCU 读取侧临界区内有条件地获取睡眠锁（如 `mutex_trylock()`）是合法的，但前提是不能无限循环尝试条件性地获取该睡眠锁。关键在于像 `mutex_trylock()` 这样的函数要么带着锁返回，要么如果锁不可立即获得则返回错误指示。无论如何，`mutex_trylock()` 都会立即返回而不进行睡眠。|
+-----------------------------------------------------------------------+

令人惊讶的是，许多算法并不需要一致的数据视图，但它们仍然可以在这种模式下运行，网络路由就是一个典型案例。互联网路由算法需要相当长的时间来传播更新，因此当更新到达某个系统时，该系统已经错误地发送网络流量有一段时间了。让少数线程继续错误地发送流量几毫秒显然不是问题：最坏的情况下，TCP 重传最终会将数据送到正确的地方。一般来说，当追踪计算机外部的状态时，由于光速延迟等因素，必须容忍一定程度的不一致性。

此外，对外部状态的不确定性在许多情况下是固有的。例如，两名兽医可能会通过心跳检测来判断一只猫是否还活着。但在最后一次心跳后应该等待多久才能决定这只猫确实死了？等待不到 400 毫秒是没有意义的，因为这意味着一只放松的猫每分钟会被认为死亡和复活超过 100 次。而且，正如人类一样，猫的心脏也可能停止跳动一段时间，因此确切的等待时间是一个判断问题。两名兽医中的一名可能等待 30 秒后宣布猫死亡，而另一名可能坚持等待整整一分钟。两名兽医在最后一次心跳后的最后 30 秒内会对猫的状态产生分歧。

有趣的是，这种情况同样适用于硬件。当需要确定某个外部服务器是否已失败时，我们如何判断？我们定期向它发送消息，并在没有收到响应时宣布其失败。政策决策通常可以容忍短时间内的不一致性。政策是在一段时间前决定的，现在才开始实施，所以几毫秒的延迟通常是无关紧要的。

然而，有些算法绝对需要看到一致的数据。
例如，用户级的System V信号量ID与其内核中对应数据结构之间的转换由RCU（Read-Copy-Update）保护，但绝对禁止更新刚刚被移除的信号量。在Linux内核中，这种一致性需求通过在RCU读端临界区内部获取位于内核数据结构中的自旋锁来实现，这在上图中用绿色框表示。许多其他技术也可以使用，并且实际上在Linux内核中也在使用。

简而言之，RCU并不是维持一致性的唯一机制，当需要一致性时，可以与其他机制结合使用。RCU的专业化使其能够非常出色地完成任务，其与其他同步机制的互操作性使得可以根据具体需求选择合适的同步工具。

性能和可扩展性
~~~~~~~~~~~~~~~~~~~~~~~~~~~

能效是当今性能的关键组成部分，因此Linux内核中的RCU实现必须避免不必要的唤醒空闲CPU。我不能声称这一要求是预先计划好的。事实上，我是通过一次电话交谈了解到这一点的，在那次交谈中，我得到了关于电池供电系统中能效的重要性以及Linux内核RCU实现中特定能效不足的“坦诚而直接”的反馈。

根据我的经验，电池供电的嵌入式社区会认为任何不必要的唤醒都是极其不友好的行为。以至于仅凭Linux内核邮件列表的帖子不足以表达他们的不满。

内存消耗在大多数情况下并不特别重要，并且随着内存容量的增加和成本的下降，其重要性也在降低。然而，正如我从Matt Mackall的`bloatwatch <http://elinux.org/Linux_Tiny-FAQ>`__工作中所学到的，内存占用在单CPU系统且内核不可抢占（`CONFIG_PREEMPTION=n`）的情况下至关重要，因此诞生了`tiny RCU <https://lore.kernel.org/r/20090113221724.GA15307@linux.vnet.ibm.com>`__。此后，Josh Triplett接手了小内存项目，并通过他的`Linux内核小型化 <https://tiny.wiki.kernel.org/>`__项目使`SRCU <Sleepable RCU_>`__成为可选组件，对于那些不需要它的内核来说。

其余的性能需求大多在意料之中。例如，符合RCU的读端专业化的理念，`rcu_dereference()`应具有几乎为零的开销（例如，抑制几个次要的编译器优化）。同样，在不可抢占环境中，`rcu_read_lock()`和`rcu_read_unlock()`应该完全无开销。

在可抢占环境中，如果RCU读端临界区没有被抢占（如最高优先级的实时进程），`rcu_read_lock()`和`rcu_read_unlock()`应该有最小的开销。特别是，它们不应包含原子读-修改-写操作、内存屏障指令、抢占禁用、中断禁用或向后分支。然而，在RCU读端临界区被抢占的情况下，`rcu_read_unlock()`可能会获取自旋锁并禁用中断。这就是为什么最好将RCU读端临界区嵌套在禁用抢占区域内，而不是反过来，至少在该临界区足够短以避免过度降低实时延迟的情况下是如此。

`synchronize_rcu()`的优雅等待期原语针对吞吐量进行了优化。因此，除了最长的RCU读端临界区持续时间外，它可能会带来几毫秒的延迟。
另一方面，需要多次并发调用 `synchronize_rcu()` 才能利用批处理优化，从而通过单一的基础等待优雅期操作来满足这些调用。例如，在 Linux 内核中，一个单一的优雅期等待操作服务于超过 1,000 次 `synchronize_rcu()` 的单独调用是很常见的 <https://www.usenix.org/conference/2004-usenix-annual-technical-conference/making-rcu-safe-deep-sub-millisecond-response> ，这使得每次调用的开销摊薄到几乎为零。然而，优雅期优化也是必需的，以避免实时调度和中断延迟的可测量退化。
在某些情况下，多毫秒级的 `synchronize_rcu()` 延迟是不可接受的。在这种情况下，可以使用 `synchronize_rcu_expedited()` 来减少优雅期延迟至几十微秒（在小型系统上），至少在 RCU 读侧临界区较短的情况下是这样。目前对大型系统没有特殊的延迟要求，但与 RCU 规范的经验性质一致，这一点可能会改变。但是，确实存在扩展性要求：在 4096 个 CPU 上的一系列 `synchronize_rcu_expedited()` 调用应该至少能够合理地向前推进。作为对其更短延迟的交换条件，`synchronize_rcu_expedited()` 允许在非空闲在线 CPU 上适度降低实时延迟。这里的“适度”意味着大约相当于调度时钟中断的延迟。
在某些情况下，即使 `synchronize_rcu_expedited()` 减少后的优雅期延迟也是不可接受的。在这种情况下，可以在 `synchronize_rcu()` 的位置使用异步 `call_rcu()`，如下所示：

```c
1 struct foo {
2   int a;
3   int b;
4   struct rcu_head rh;
5 };
7 static void remove_gp_cb(struct rcu_head *rhp)
8 {
9   struct foo *p = container_of(rhp, struct foo, rh);
11   kfree(p);
12 }
14 bool remove_gp_asynchronous(void)
15 {
16   struct foo *p;
18   spin_lock(&gp_lock);
19   p = rcu_access_pointer(gp);
20   if (!p) {
21     spin_unlock(&gp_lock);
22     return false;
23   }
24   rcu_assign_pointer(gp, NULL);
25   call_rcu(&p->rh, remove_gp_cb);
26   spin_unlock(&gp_lock);
27   return true;
28 }
```

最终需要定义 `struct foo`，它出现在第 1 到 5 行。函数 `remove_gp_cb()` 在第 25 行传递给 `call_rcu()`，并在后续优雅期结束之后被调用。这得到了与 `remove_gp_synchronous()` 相同的效果，但不需要更新者等待优雅期结束。`call_rcu()` 可以在许多情况下使用，而 `synchronize_rcu()` 和 `synchronize_rcu_expedited()` 是不合法的，包括在禁用抢占代码、禁用本地软中断代码、禁用中断代码以及中断处理程序中。然而，即使 `call_rcu()` 在 NMI 处理程序和空闲和离线 CPU 上也是非法的。回调函数（本例中的 `remove_gp_cb()`）将在 Linux 内核中的软中断环境中执行，要么在真实的软中断处理程序中，要么在 `local_bh_disable()` 的保护下。在 Linux 内核和用户空间中，编写运行时间过长的 RCU 回调函数是一种不良做法。长时间运行的操作应委托给单独的线程或（在 Linux 内核中）工作队列。

+-----------------------------------------------------------------------+
| **快速测验**：                                                        |
+-----------------------------------------------------------------------+
| 为什么第 19 行使用 `rcu_access_pointer()`？毕竟，第 25 行的 `call_rcu()` 将数据存储到结构体中，这会与并发插入相互影响。这是否意味着需要 `rcu_dereference()`？ |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 据推测，第 18 行获取的 `->gp_lock` 排除了任何更改，包括 `rcu_dereference()` 会保护的任何插入。因此，任何插入都将延迟到第 25 行释放 `->gp_lock` 之后，这意味着 `rcu_access_pointer()` 就足够了。 |
+-----------------------------------------------------------------------+

然而，`remove_gp_cb()` 所做的只是对数据元素调用 `kfree()`。这是一种常见的模式，并且由 `kfree_rcu()` 支持，允许“发射并忘记”的操作，如下所示：

```c
1 struct foo {
2   int a;
3   int b;
4   struct rcu_head rh;
5 };
7 bool remove_gp_faf(void)
8 {
9   struct foo *p;
11   spin_lock(&gp_lock);
12   p = rcu_dereference(gp);
13   if (!p) {
14     spin_unlock(&gp_lock);
15     return false;
16   }
17   rcu_assign_pointer(gp, NULL);
18   kfree_rcu(p, rh);
19   spin_unlock(&gp_lock);
20   return true;
21 }
```

注意，`remove_gp_faf()` 仅调用 `kfree_rcu()` 并继续进行，无需进一步关注随后的优雅期和 `kfree()`。允许从与 `call_rcu()` 相同环境调用 `kfree_rcu()`。
有趣的是，DYNIX/ptx 拥有类似于 `call_rcu()` 和 `kfree_rcu()` 的功能，但没有 `synchronize_rcu()`。这是由于 RCU 在 DYNIX/ptx 中使用不多，所以少数需要类似 `synchronize_rcu()` 功能的地方直接编码实现。
+-----------------------------------------------------------------------+
| **快速测验**：                                                        |
+-----------------------------------------------------------------------+
| 早先声称 `call_rcu()` 和 `kfree_rcu()` 允许更新者避免被读者阻塞。但这怎么可能正确，因为回调的调用和内存释放（分别）仍然必须等待优雅期结束？ |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 我们可以这样定义，但请记住，这种定义会说垃圾回收语言中的更新无法在下次垃圾收集运行之前完成，这似乎不太合理。关键点在于，在大多数情况下，使用 `call_rcu()` 或 `kfree_rcu()` 的更新者在调用 `call_rcu()` 或 `kfree_rcu()` 后可以立即进行下一次更新，而无需等待随后的优雅期。 |
+-----------------------------------------------------------------------+

但如果更新者必须等待优雅期结束后执行的代码完成，但在等待期间还有其他任务可以完成怎么办？可以使用轮询风格的 `get_state_synchronize_rcu()` 和 `cond_synchronize_rcu()` 函数来达到这个目的，如下所示：

```c
1 bool remove_gp_poll(void)
2 {
3   struct foo *p;
4   unsigned long s;
6   spin_lock(&gp_lock);
7   p = rcu_access_pointer(gp);
8   if (!p) {
9     spin_unlock(&gp_lock);
10     return false;
11   }
12   rcu_assign_pointer(gp, NULL);
13   spin_unlock(&gp_lock);
14   s = get_state_synchronize_rcu();
15   do_something_while_waiting();
16   cond_synchronize_rcu(s);
17   kfree(p);
18   return true;
19 }
```

在第 14 行，`get_state_synchronize_rcu()` 从 RCU 获取一个“标记”，然后第 15 行执行其他任务，最后，如果在此期间优雅期已结束，则第 16 行立即返回，否则按需等待。对 `get_state_synchronize_rcu` 和 `cond_synchronize_rcu()` 的需求最近才出现，因此现在还无法判断它们是否会经受住时间的考验。
RCU 提供了一系列工具，使更新者能够在延迟、灵活性和 CPU 开销之间找到所需的权衡。
向前进展
~~~~~~~~~~~

理论上，延迟优雅期完成和回调调用是无害的。实际上，不仅内存大小有限，而且回调有时会唤醒进程，足够延迟的唤醒很难与系统挂起区分开。因此，RCU 必须提供多种机制来促进向前进展。
这些机制不是万无一失的，也不能做到。举一个简单的例子，在 RCU 读侧临界区中的无限循环必然会阻止后续优雅期的完成。对于一个更复杂的例子，考虑一个使用 `CONFIG_RCU_NOCB_CPU=y` 构建并带有 `rcu_nocbs=1-63` 启动参数的 64-CPU 系统，其中 CPU 1 到 63 在紧密循环中调用 `call_rcu()`。即使这些紧密循环也包含 `cond_resched()` 调用（从而允许优雅期完成），CPU 0 也无法像其他 63 个 CPU 那样快地调用回调，至少在系统耗尽内存之前是这样。在这两个例子中，蜘蛛侠原则适用：能力越大，责任越大。然而，只要不是这种程度的滥用，RCU 必须确保优雅期及时完成和回调及时调用。
RCU 采取以下步骤鼓励优雅期及时完成：

1. 如果一个优雅期未能在 100 毫秒内完成，RCU 会导致未来在持留 CPU 上调用 `cond_resched()` 提供 RCU 安静状态。RCU 还会导致这些 CPU 的 `need_resched()` 调用返回 `true`，但在相应 CPU 的下一个调度时钟之后。
#. 在内核引导参数 ``nohz_full`` 中提到的 CPU 可以无限期地在内核中运行而无需调度时钟中断，这使得上述的 `need_resched()` 策略失效。因此，RCU 将会在任何在 109 毫秒后仍然持有不释放的 ``nohz_full`` CPU 上调用 `resched_cpu()`。
#. 在使用 ``CONFIG_RCU_BOOST=y`` 构建的内核中，如果某个在 RCU 读侧临界区中被抢占的任务持续超过 500 毫秒未释放，RCU 将会采用优先级提升策略。
#. 如果一个 CPU 在恩典期开始后的 10 秒内仍未释放，无论其是否处于 ``nohz_full`` 状态，RCU 都将调用 `resched_cpu()`。

以上值是对于运行在 ``HZ=1000`` 的系统中的默认值。随着 ``HZ`` 值的变化，这些值也会变化，并且可以使用相关的 Kconfig 选项和内核引导参数进行调整。目前，RCU 对这些参数没有做太多合理性检查，因此在修改它们时请谨慎。请注意，这些前进步骤措施仅适用于 RCU，而不适用于 `SRCU (Sleepable RCU)` 或 `Tasks RCU`。

RCU 在 `call_rcu()` 中采取以下步骤来鼓励及时调用回调函数，当任意一个非-``rcu_nocbs`` CPU 拥有 10,000 个回调函数，或者比上次提供鼓励时多出 10,000 个回调函数时：

#. 如果还没有开始恩典期，则启动一个恩典期。
#. 强制立即检查静默状态，而不是等待恩典期开始后的三毫秒。
#. 立即标记 CPU 的回调函数的恩典期完成编号，而不是等待 `RCU_SOFTIRQ` 处理程序来处理。
#. 提高回调执行批次限制，这会加快回调调用的速度，但代价是实时响应性能下降。

再次强调，这些是在 ``HZ=1000`` 下运行的默认值，并且可以被覆盖。同样，这些前进步骤措施仅适用于 RCU，而不适用于 `SRCU (Sleepable RCU)` 或 `Tasks RCU`。即使是对于 RCU，``rcu_nocbs`` CPU 的回调调用前进步骤也远不如其他 CPU 发展得完善，部分原因是受益于 ``rcu_nocbs`` CPU 的工作负载往往不会频繁调用 `call_rcu()`。如果出现需要同时使用 ``rcu_nocbs`` CPU 和高 `call_rcu()` 调用率的工作负载，则需要进行额外的前进步骤开发。

### 组合性

近年来，组合性受到了广泛关注，这可能部分是因为多核硬件与为单线程环境设计的面向对象技术之间的碰撞。理论上，RCU 读侧临界区是可以组合的，并且实际上可以任意深度嵌套。然而，在实践中，就像所有现实世界中的组合构造一样，存在一些限制。
RCU 的实现中，如果 `rcu_read_lock()` 和 `rcu_read_unlock()` 不生成任何代码（例如，在 `CONFIG_PREEMPTION=n` 配置下的 Linux 内核 RCU），可以无限嵌套。毕竟，没有额外的开销。然而，如果所有这些 `rcu_read_lock()` 和 `rcu_read_unlock()` 实例对编译器可见，则最终会因耗尽内存、存储空间或用户耐心而编译失败，以先发生的为准。如果嵌套对编译器不可见，例如在不同编译单元中的相互递归函数，则会导致栈溢出。如果嵌套形式为循环，可能以尾递归的形式出现，要么控制变量会溢出，要么在 Linux 内核中会收到 RCU CPU 停顿警告。尽管如此，这类 RCU 实现是现有最可组合的构造之一。

显式跟踪嵌套深度的 RCU 实现受限于嵌套深度计数器。例如，Linux 内核的抢占式 RCU 将嵌套限制为 `INT_MAX`。这应该能满足几乎所有实际需求。但是，两个 RCU 读端临界区之间如果有等待优雅期的操作，则不能被另一个 RCU 读端临界区包围。因为在 RCU 读端临界区内等待优雅期是不合法的：这样做会导致死锁或 RCU 隐式分割外层 RCU 读端临界区，这两种情况都不利于内核长期稳定运行。

值得注意的是，RCU 并不是唯一限制可组合性的同步机制。例如，许多事务内存实现禁止将一对事务用不可撤销操作（如网络接收操作）分隔开。再比如，基于锁的临界区可以自由组合，但前提是避免死锁。

简而言之，虽然 RCU 读端临界区具有高度可组合性，但在某些情况下仍需谨慎，就像其他任何可组合的同步机制一样。

### 特殊情况

某个 RCU 工作负载可能会有无休止且密集的 RCU 读端临界区流，甚至可能密集到任何时候至少有一个 RCU 读端临界区正在进行。RCU 不能允许这种情况阻塞优雅期：只要所有的 RCU 读端临界区都是有限的，优雅期也必须是有限的。

然而，抢占式 RCU 实现在某些情况下可能导致 RCU 读端临界区长时间被抢占，从而形成一个长时间的 RCU 读端临界区。这种情况仅在高负载系统中出现，但使用实时优先级的系统更容易受到影响。因此，提供了 RCU 优先级提升来应对这种情况。不过，随着经验积累，对 RCU 优先级提升的确切要求可能会有所演变。

其他工作负载可能具有非常高的更新率。虽然可以说这样的工作负载应该使用不同于 RCU 的方法，但事实是 RCU 必须优雅地处理此类工作负载。这一要求也是推动优雅期批处理的因素之一，同时也是促使 `call_rcu()` 路径检查大量排队 RCU 回调的原因。最后，高更新率不应延迟 RCU 读端临界区，尽管在使用 `synchronize_rcu_expedited()` 时可能会发生一些小的读端延迟，这是由于该函数使用了 `smp_call_function_single()`。

尽管早在 1990 年代初就理解了这三个特殊情况，但在 2000 年代初的一个简单的用户级测试（由 `close(open(path))` 在紧密循环中组成）突然让人们更深入地理解了高更新率的情况。这个测试还促使添加了一些 RCU 代码来应对高更新率，例如，如果某个 CPU 发现自己有超过 10,000 个排队的 RCU 回调，它会使 RCU 更积极地启动优雅期并更积极地完成优雅期处理。这种规避措施使优雅期更快完成，但代价是限制了 RCU 的批处理优化，从而增加了该优雅期的 CPU 开销。
软件工程需求

在墨菲定律和“人非圣贤，孰能无过”之间，有必要防范意外和误用：

1. 很容易忘记在所有需要的地方使用 `rcu_read_lock()`，因此使用 `CONFIG_PROVE_RCU=y` 构建的内核会在 `rcu_dereference()` 被用于 RCU 读临界区之外时崩溃。更新代码可以使用 `rcu_dereference_protected()`，它接受一个锁依赖表达式来指示提供保护的方式。如果未提供所指示的保护，则会发出锁依赖崩溃信息。读者和更新者共享的代码可以使用 `rcu_dereference_check()`，这也接受一个锁依赖表达式，并在既没有 `rcu_read_lock()` 也没有所指示的保护时发出锁依赖崩溃信息。此外，在那些（希望是很少见的）无法轻松描述所需保护的情况下，可以使用 `rcu_dereference_raw()`。最后，`rcu_read_lock_held()` 提供了一个函数，以验证其是否在一个 RCU 读临界区内被调用。我在托马斯·格莱克森审核了大量 RCU 使用情况后不久就了解到这一系列需求。

2. 给定的函数可能希望在其入口处检查与 RCU 相关的前提条件，然后再使用任何其他 RCU API。`rcu_lockdep_assert()` 就完成了这项工作，在启用了锁依赖的内核中断言表达式，否则则不做任何事情。

3. 很容易忘记使用 `rcu_assign_pointer()` 和 `rcu_dereference()`，也许（错误地）用简单的赋值来替代。为了捕捉这种错误，一个受 RCU 保护的指针可以用 `__rcu` 标记，之后 sparse 将对简单赋值访问该指针进行抱怨。阿恩德·伯格曼让我注意到了这个需求，并且还提供了所需的补丁系列。

4. 使用 `CONFIG_DEBUG_OBJECTS_RCU_HEAD=y` 构建的内核将在数据元素连续两次传递给 `call_rcu()` 且其间没有优雅期时崩溃。（此错误类似于双释放错误。）动态分配的相应 `rcu_head` 结构会自动跟踪，但栈上分配的 `rcu_head` 结构必须通过 `init_rcu_head_on_stack()` 初始化，并通过 `destroy_rcu_head_on_stack()` 清理。同样，静态分配的非栈 `rcu_head` 结构必须通过 `init_rcu_head()` 初始化，并通过 `destroy_rcu_head()` 清理。马蒂厄·德斯诺耶尔让我注意到了这个需求，并且还提供了所需的补丁。

5. 在 RCU 读临界区中的无限循环最终将触发 RCU CPU 停滞警告崩溃，其“最终”的持续时间由 `RCU_CPU_STALL_TIMEOUT` 的 `Kconfig` 选项控制，或者，可选地，通过 `rcupdate.rcu_cpu_stall_timeout` 启动参数或 `sysfs` 参数。但是，除非有优雅期等待在那个特定的 RCU 读临界区上，否则 RCU 没有义务产生这个崩溃信息。某些极端的工作负载可能会有意延迟 RCU 优雅期，运行这些工作负载的系统可以通过 `rcupdate.rcu_cpu_stall_suppress` 启动参数来抑制崩溃信息。此内核参数也可以通过 `sysfs` 设置。此外，在 sysrq 卸载期间和发生恐慌时，RCU CPU 停滞警告是适得其反的。因此，RCU 提供了 `rcu_sysrq_start()` 和 `rcu_sysrq_end()` API 成员，在长时间的 sysrq 卸载之前和之后调用。RCU 还提供了 `rcu_panic()` 通知器，该通知器在恐慌开始时自动调用以抑制进一步的 RCU CPU 停滞警告。这个需求在 1990 年代初首次出现，几乎是第一次需要调试 CPU 停滞的时候。尽管如此，DYNIX/ptx 中的初始实现比 Linux 的实现更为通用。

6. 虽然检测从 RCU 读临界区泄漏的指针非常重要，但目前还没有好的方法来实现这一点。一个复杂之处在于需要区分泄漏的指针和已经从 RCU 转交给其他同步机制（例如引用计数）的指针。
#. 在使用 ``CONFIG_RCU_TRACE=y`` 构建的内核中，通过事件跟踪提供与 RCU 相关的信息。
#. 使用 rcu_assign_pointer() 和 rcu_dereference() 显式创建典型的链式数据结构可能会出乎意料地容易出错。因此，提供了 RCU 保护的 `链表 <https://lwn.net/Articles/609973/#RCU%20List%20APIs>`__ 和最近的 RCU 保护的 `哈希表 <https://lwn.net/Articles/612100/>`__。Linux 内核和用户空间 RCU 库中还包含许多其他专门用途的 RCU 保护数据结构。
#. 有些链式结构在编译时创建，但仍需要 ``__rcu`` 检查。RCU_POINTER_INITIALIZER() 宏为此目的服务。
#. 对于通过单一外部指针发布的链式结构，不需要使用 rcu_assign_pointer()。为完成此任务提供了 RCU_INIT_POINTER() 宏。

这不是一个严格的列表：RCU 的诊断能力将继续根据实际应用中发现的使用错误的数量和类型进行指导。

Linux 内核复杂性
--------------------

Linux 内核为各种软件（包括 RCU）提供了一个有趣的环境。一些相关的关键点如下：

#. `配置`_
#. `固件接口`_
#. `早期引导`_
#. `中断和 NMI`_
#. `可加载模块`_
#. `热插拔 CPU`_
#. `调度器和 RCU`_
#. `跟踪和 RCU`_
#. `对用户内存的访问和 RCU`_
#. `能效`_
#. `调度时钟中断和 RCU`_
#. `内存效率`_
#. `性能、可扩展性、响应时间和可靠性`_

这个列表可能并不完整，但它确实体现了最显著的 Linux 内核复杂性。以下各节分别涵盖了上述主题之一。

配置
~~~~~~~~~~~~~

RCU 的目标是自动配置，以便几乎没有人需要担心 RCU 的 ``Kconfig`` 选项。对于几乎所有用户，RCU 实际上都可以“开箱即用”。

然而，存在一些特殊使用情况，这些情况由内核启动参数和 ``Kconfig`` 选项处理。不幸的是，``Kconfig`` 系统会明确询问用户关于新的 ``Kconfig`` 选项的问题，这要求几乎所有这些选项都隐藏在 ``CONFIG_RCU_EXPERT`` ``Kconfig`` 选项之后。

这看起来应该很明显，但事实上，Linus Torvalds 最近不得不提醒我这一要求。

固件接口
~~~~~~~~~~~~~~~~~~

在许多情况下，内核从固件获取有关系统的某些信息，有时信息在转换过程中丢失。或者虽然转换准确，但原始消息本身就有问题。

例如，某些系统的固件会高估 CPU 的数量，有时甚至高估很多。如果 RCU 像以前那样天真地相信固件报告的数量，它将创建过多的每 CPU 线程。尽管结果系统仍能正确运行，但额外的线程会无谓地消耗内存，并且当它们出现在 `ps` 列表中时会造成混乱。
RCU 因此必须等待给定的 CPU 实际上线后，才能允许自己相信该 CPU 确实存在。由此产生的“幽灵 CPU”（永远不会上线）导致了一系列有趣的复杂情况。<https://paulmck.livejournal.com/37494.html>

早期启动
~~~~~~~~~~

Linux 内核的启动序列是一个有趣的过程，并且 RCU 在启动过程中很早就被使用了，甚至在调用 rcu_init() 之前。实际上，在初始任务的 `task_struct` 可用并且启动 CPU 的每个 CPU 变量设置好之后，RCU 的一些原语就可以开始使用了。读取侧原语（rcu_read_lock()、rcu_read_unlock()、rcu_dereference() 和 rcu_access_pointer()）会非常早地正常工作，rcu_assign_pointer() 也是如此。

尽管 call_rcu() 可以在启动过程中的任何时候被调用，但回调函数保证不会在所有 RCU 的 kthread 被创建之前被调用，这发生在 early_initcall() 时间点。回调函数调用的延迟是由于 RCU 直到完全初始化后才会调用回调函数，而这种完全初始化直到调度器初始化到可以运行 RCU 的 kthread 时才能发生。理论上可以在更早的时候调用回调函数，但这并不是万能的解决方案，因为会有严格的限制规定这些回调函数能够调用的操作。

令人惊讶的是，synchronize_rcu() 和 synchronize_rcu_expedited() 在非常早期的启动阶段也能正常工作，原因是只有一个 CPU 并且抢占被禁用。这意味着调用 synchronize_rcu()（或其变体）本身就是一种静默状态，从而也是一个宽限期，因此早期启动实现可以是一个空操作。

然而，一旦调度器创建了第一个 kthread，对于 synchronize_rcu()（以及 synchronize_rcu_expedited()）来说，这个早期启动技巧在 CONFIG_PREEMPTION=y 的内核中就失效了。原因是 RCU 读取侧临界区可能会被抢占，这意味着后续的 synchronize_rcu() 真正需要等待某些东西，而不是简单地立即返回。

不幸的是，synchronize_rcu() 必须等到所有 kthread 创建完毕后才能做到这一点，而这要等到 early_initcalls() 时间点。但这并不是借口：RCU 在此期间仍然需要正确处理同步宽限期。一旦所有的 kthread 都运行起来，RCU 就开始正常运行。

+-----------------------------------------------------------------------+
| **快速问答**：                                                      |
+-----------------------------------------------------------------------+
| RCU 如何在所有 kthread 创建完成之前处理宽限期？                        |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 非常小心地！                                                          |
| 在调度器创建第一个任务和所有 RCU 的 kthread 创建完成之间的“死区”，所有 |
| 同步宽限期都由加速宽限期机制处理。在运行时，这种加速机制依赖于工作队列，|
| 但在死区期间，请求的任务本身驱动所需的加速宽限期。因为死区执行发生在任务 |
| 上下文中，所以一切都能正常工作。一旦死区结束，加速宽限期又回到使用工 |
| 作队列的方式，这是为了避免当用户任务在驱动加速宽限期时收到 POSIX 信 |
| 号时可能发生的其他问题。                                               |
|                                                                        |
| 是的，这意味着在调度器创建第一个 kthread 到 RCU 的 kthread 全部创 |
| 建完成之间发送 POSIX 信号是没有帮助的。如果将来有理由在此期间发送 POSIX |
| 信号，将做出适当的调整。（如果发现在此期间无理由发送 POSIX 信号，也将做 |
| 出其他适当的调整。）                                                   |
+-----------------------------------------------------------------------+

我是在一系列系统挂起事件中了解到这些启动时间要求的。
中断和 NMI
~~~~~~~~~~~~~~~~~~~

Linux 内核中有中断，RCU 读取侧临界区在中断处理程序和禁用中断的代码区域中是合法的，调用 call_rcu() 也是如此。

某些 Linux 内核架构可以从非空闲进程上下文进入中断处理程序，然后永远不离开它，而是偷偷地转换回进程上下文。有时这种技巧用于从内核内部调用系统调用。这些“半中断”意味着 RCU 必须非常小心地计算中断嵌套级别。我在重写 RCU 的 dyntick-idle 代码时，以艰难的方式了解到了这一需求。
Linux 内核具有不可屏蔽中断（NMIs），并且 RCU 读端临界区在 NMI 处理程序中是合法的。值得庆幸的是，RCU 更新端原语（包括 call_rcu()）在 NMI 处理程序中是被禁止的。
尽管名称如此，某些 Linux 内核架构可以有嵌套的 NMIs，RCU 必须正确处理这种情况。Andy Lutomirski 在这方面提出了一个要求，并且他还友好地提供了一个满足该要求的算法。
此外，NMI 处理程序可能会被中断，这些中断对 RCU 来说看起来像普通的中断。这可以通过直接调用 ct_irq_enter() 和 ct_irq_exit() 的代码从 NMI 处理程序中调用来实现。这一令人惊讶的事实促使了当前的代码结构，其中 ct_irq_enter() 调用了 ct_nmi_enter() 并且 ct_irq_exit() 调用了 ct_nmi_exit()。
是的，我也通过艰难的方式学到了这一要求。

### 可加载模块

Linux 内核具有可加载模块，这些模块也可以被卸载。在一个给定的模块被卸载之后，任何试图调用其函数的操作都会导致段错误。因此，模块卸载函数必须取消所有延迟调用的模块函数，例如任何未处理的 mod_timer() 都必须通过 timer_shutdown_sync() 或类似方式处理。
不幸的是，没有办法取消一个 RCU 回调；一旦你调用 call_rcu()，回调函数最终会被调用，除非系统先崩溃。因为通常认为在模块卸载请求时崩溃系统是不负责的行为，我们需要其他方法来处理飞行中的 RCU 回调。
因此，RCU 提供了 rcu_barrier()，它会等待所有飞行中的 RCU 回调被调用。如果一个模块使用了 call_rcu()，其退出函数应阻止任何未来的 call_rcu() 调用，然后调用 rcu_barrier()。理论上，底层模块卸载代码可以无条件地调用 rcu_barrier()，但实际上这会导致无法接受的延迟。
Nikita Danilov 注意到了一个类似的文件系统卸载情况的需求，Dipankar Sarma 将 rcu_barrier() 纳入 RCU 中。对于模块卸载需要 rcu_barrier() 的需求后来才变得明显。

#### 重要提示：

rcu_barrier() 函数没有义务等待一个宽限期。它只需等待已发布的 RCU 回调。因此，如果系统中没有任何 RCU 回调发布，rcu_barrier() 有权立即返回。即使有回调发布，rcu_barrier() 也不一定需要等待一个完整的宽限期。

#### 快速测验：

等等！每个 RCU 回调都必须等待一个宽限期完成，并且 rcu_barrier() 必须等待每个现有的回调被调用。那么如果系统中有任何一个回调发布，rcu_barrier() 是否需要等待一个完整的宽限期？

#### 答案：

绝对不需要！！！

是的，每个 RCU 回调都必须等待一个宽限期完成，但在 rcu_barrier() 被调用时，这个宽限期可能已经部分（甚至完全）完成了。在这种情况下，rcu_barrier() 只需等待剩余的宽限期。因此，即使有很多回调发布，rcu_barrier() 也可能很快返回。
所以如果你需要等待一个宽限期以及所有的现有回调，你需要分别调用 synchronize_rcu() 和 rcu_barrier()。如果延迟是一个问题，你可以始终使用工作队列并行调用它们。

### 热插拔 CPU

Linux 内核支持 CPU 热插拔，这意味着 CPU 可以加入和离开。当然，在离线 CPU 上使用任何 RCU API 成员是非法的，除了 SRCU（可睡眠 RCU）读端临界区。这一要求自 DYNIX/ptx 开始就存在，但另一方面，Linux 内核的 CPU 热插拔实现是“有趣的”。
Linux 内核的 CPU 热插拔实现使用了通知器，允许各个内核子系统（包括 RCU）响应特定的 CPU 热插拔操作。大多数 RCU 操作可以从 CPU 热插拔通知器中调用，甚至同步宽限期操作（如 synchronize_rcu() 和 synchronize_rcu_expedited()）。然而，这些同步操作确实会阻塞，因此不能从通过 stop_machine() 执行的通知器中调用，特别是那些在 ``CPUHP_AP_OFFLINE`` 和 ``CPUHP_AP_ONLINE`` 状态之间的通知器。
此外，所有回调等待操作（如 rcu_barrier()）不得从任何 CPU 热插拔通知器中调用。这一限制是由于在 CPU 热插拔操作的某些阶段，即将下线的 CPU 的回调不会在热插拔操作结束前被调用，这可能会导致死锁。此外，rcu_barrier() 在执行过程中会阻塞 CPU 热插拔操作，当从 CPU 热插拔通知器中调用时，会导致另一种类型的死锁。

最后，RCU 必须避免由于热插拔、定时器和优雅期处理之间的交互而引起的死锁。它通过维护自己的“账本”来实现这一点，这些“账本”复制了集中维护的“cpu_online_mask”，并且在 CPU 下线时显式报告静默状态。这种静默状态的显式报告避免了强制静默状态循环（FQS）为离线 CPU 报告静默状态的需求。然而，作为一种调试措施，如果离线 CPU 阻塞 RCU 优雅期过长时间，FQS 循环将报错。

离线 CPU 的静默状态将在以下情况之一报告：

1. 当 CPU 使用 RCU 的热插拔通知器下线时（使用 rcutree_report_cpu_dead()）
2. 当优雅期初始化（rcu_gp_init()）检测到与 CPU 下线或任务解除对某个叶子节点结构的阻塞之间的竞态条件时，该结构的所有 CPU 均已离线

CPU 上线路径（rcutree_report_cpu_starting()）不应需要报告离线 CPU 的静默状态。然而，作为一种调试措施，如果没有提前报告该 CPU 的静默状态，它会发出警告。

在检查/修改 RCU 的热插拔账本时，相应的 CPU 的叶子节点锁会被持有。这避免了 RCU 的热插拔通知器钩子、优雅期初始化代码以及 FQS 循环之间的竞态条件，这些都引用或修改了这个账本。

调度器和 RCU
~~~~~~~~~~~~~~

RCU 使用内核线程（kthreads），必须避免这些线程积累过多的 CPU 时间。这个需求并不令人意外，但当构建时使用了“CONFIG_NO_HZ_FULL=y”配置，并且运行上下文切换密集型工作负载时，RCU 违反了这一要求，这是出乎意料的 [PDF] <http://www.rdrop.com/users/paulmck/scalability/paper/BareMetal.2015.01.15b.pdf>。RCU 已经在这方面取得了良好的进展，即使对于上下文切换密集型的 “CONFIG_NO_HZ_FULL=y” 工作负载，但仍有一定的改进空间。

现在不再禁止在 rcu_read_unlock() 调用期间持有调度器的任何一个运行队列或优先级继承自旋锁，即使在相应的 RCU 读侧临界区内部启用了中断和抢占。

因此，现在完全可以合法地在启用抢占的情况下执行 rcu_read_lock()，获取一个调度器锁，并在匹配的 rcu_read_unlock() 调用期间持有该锁。
同样地，RCU口味整合移除了对负向嵌套的需求。代码中禁止中断的区域作为RCU读端临界区隐式避免了早期因中断处理程序使用RCU而导致的破坏性递归问题。

RCU追踪
~~~~~~~~~~~~~~~

可以在RCU代码上使用追踪功能，但追踪本身也使用RCU。出于这个原因，提供了`rcu_dereference_raw_check()`供追踪使用，以避免可能由此导致的破坏性递归。此API也在某些架构中的虚拟化环境中被使用，因为RCU读者在这些环境中无法使用追踪。追踪团队不仅发现了这一需求，还提供了所需的修复方案，因此这一意外需求相对容易解决。

访问用户内存与RCU
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

内核需要访问用户空间的内存，例如，访问系统调用参数引用的数据。`get_user()`宏完成了这项工作。然而，用户空间的内存可能已经被换出，这意味着`get_user()`可能会产生分页错误，并因此阻塞等待I/O完成。如果编译器将`get_user()`调用重排到RCU读端临界区内，那将是非常糟糕的事情。例如，假设源代码如下所示：

  ::

       1 rcu_read_lock();
       2 p = rcu_dereference(gp);
       3 v = p->value;
       4 rcu_read_unlock();
       5 get_user(user_v, user_p);
       6 do_something_with(v, user_v);

编译器不得允许将这段源代码转换为以下形式：

  ::

       1 rcu_read_lock();
       2 p = rcu_dereference(gp);
       3 get_user(user_v, user_p); // BUG: POSSIBLE PAGE FAULT!!!
       4 v = p->value;
       5 rcu_read_unlock();
       6 do_something_with(v, user_v);

如果编译器在一个`CONFIG_PREEMPTION=n`的内核构建中进行了这种转换，并且`get_user()`产生了分页错误，结果将是RCU读端临界区中间的一个静止状态。这种错位的静止状态可能导致第4行是一个释放后的访问，这对内核的统计数字来说可能是灾难性的。类似的情况也可以通过在`rcu_read_lock()`之前的`get_user()`调用来构造。

不幸的是，`get_user()`没有任何特定的排序属性，在某些架构中，底层的`asm`甚至没有标记为`volatile`。即使标记为`volatile`，上述对`p->value`的访问也不是`volatile`的，因此编译器没有理由保持这两个访问的顺序。

因此，Linux内核中`rcu_read_lock()`和`rcu_read_unlock()`的定义必须作为编译屏障，至少对于嵌套RCU读端临界区内的最外层实例而言是如此。

能源效率
~~~~~~~~~~~~~~~~~

中断空闲的CPU被认为是不道德的行为，特别是对于那些使用电池供电的嵌入式系统的用户。因此，RCU通过检测哪些CPU处于空闲状态来节省能源，包括跟踪从空闲状态被中断的CPU。这是能源效率要求的重要部分，所以我接到了一个愤怒的电话。

由于RCU避免中断空闲的CPU，因此在空闲CPU上执行RCU读端临界区是非法的。（使用`CONFIG_PROVE_RCU=y`构建的内核会在你尝试这样做时崩溃。）

同样，中断正在用户空间运行的`nohz_full` CPU也被认为是不道德的。因此，RCU必须跟踪`nohz_full`用户空间的执行。RCU因此必须能够在两个时间点采样状态，并确定是否有其他CPU花费了任何时间处于空闲或用户空间执行状态。
这些能效要求被证明是相当难以理解和满足的。例如，RCU（即“Read-Copy-Update”）的能效代码已经进行了五次以上的彻底重写，最后一次终于能够展示在真实硬件上运行时实现了“真实的能耗节省”。[PDF] <http://www.rdrop.com/users/paulmck/realtime/paper/AMPenergy.2013.04.19a.pdf> 正如前面所提到的，我通过许多愤怒的电话了解到这些要求：显然，在Linux内核邮件列表中对我进行批评还不够充分，他们还需要通过电话来完全发泄对RCU能效问题的不满！

调度时钟中断与RCU
~~~~~~~~~~~~~~~~~~~~~~~~

内核在内核非空闲执行、用户空间执行和空闲循环之间切换。根据内核配置，RCU以不同的方式处理这些状态：

+--------------+------------------+------------------+-----------------+
| HZ Kconfig   | 内核             | 用户模式         | 空闲            |
+==============+==================+==================+=================+
| HZ_PERIODIC  | 可依赖于          | 可依赖于          | 可依赖于         |
|              | 调度时钟中断。   | 调度时钟中断及其  | RCU的dyntick-    |
|              |                  | 检测从用户模式的  | idle检测。       |
|              |                  | 中断检测。       |                 |
+--------------+------------------+------------------+-----------------+
| NO_HZ_IDLE   | 可依赖于          | 可依赖于          | 可依赖于         |
|              | 调度时钟中断。   | 调度时钟中断及其  | RCU的dyntick-    |
|              |                  | 检测从用户模式的  | idle检测。       |
|              |                  | 中断检测。       |                 |
+--------------+------------------+------------------+-----------------+
| NO_HZ_FULL   | 有时可以依赖于    | 可依赖于          | 可依赖于         |
|              | 调度时钟中断。   | RCU的dyntick-    | RCU的dyntick-    |
|              | 在其他情况下，需  | idle检测。       | idle检测。       |
|              | 要限制内核执行时  |                  |                 |
|              | 间和/或使用IPI。 |                  |                 |
+--------------+------------------+------------------+-----------------+

+-----------------------------------------------------------------------+
| **快速问答**：                                                         |
+-----------------------------------------------------------------------+
| 为什么``NO_HZ_FULL``内核执行不能像``HZ_PERIODIC``和``NO_HZ_IDLE``那样依赖调度时钟中断？ |
+-----------------------------------------------------------------------+
| **答案**：                                                             |
+-----------------------------------------------------------------------+
| 因为作为一种性能优化手段，``NO_HZ_FULL``不一定会在每次进入系统调用时重新启用调度时钟中断。 |
+-----------------------------------------------------------------------+

然而，RCU必须可靠地知道任何给定的CPU当前是否处于空闲循环中，并且对于``NO_HZ_FULL``，还需知道该CPU是否处于用户模式，如前文所述。此外，当RCU需要时钟中断时，必须确保其已启用：

1. 如果一个CPU当前处于空闲状态或在用户模式下执行，而RCU认为它处于非空闲状态，则调度时钟中断最好正在运行。否则，你会收到RCU CPU停顿警告，或者最坏的情况是长达11秒的宽限期，并且无意义地通过IPI偶尔唤醒CPU。
2. 如果一个CPU处于内核中执行RCU读端临界区的部分，而RCU认为这个CPU处于空闲状态，那么你将遇到随机内存损坏。**千万不要这样做！** 这也是测试时应使用lockdep的原因之一，它会抱怨这类问题。
3. 如果一个CPU处于绝对肯定永远不会执行任何RCU读端临界区的部分，而RCU认为这个CPU处于空闲状态，则没有问题。这种情况被某些架构用于轻量级异常处理程序，从而避免在异常进入和退出时的ct_irq_enter()和ct_irq_exit()开销。有些架构甚至进一步避免了irq_enter()和irq_exit()的整个过程。确保你在测试时开启``CONFIG_PROVE_RCU=y``，以防你的代码路径实际上在开玩笑，没有执行RCU读端临界区。
4. 如果一个CPU在内核中执行时调度时钟中断被禁用，而RCU认为这个CPU处于非空闲状态，并且如果该CPU每隔几毫秒就变得空闲（从RCU的角度来看），则没有问题。通常允许空闲周期之间的间隔偶尔达到一秒钟左右。
5. 如果一个CPU处于空闲状态或在用户模式下执行，而RCU认为它处于空闲状态，则当然没有问题。
6. 如果一个CPU在内核中执行，内核代码路径以合理的频率（最好每几毫秒一次，但偶尔延长到一秒左右通常是可接受的）通过静默状态，并且调度时钟中断已启用，则当然没有问题。
如果连续两个静止状态之间的间隔过长，你将会收到RCU CPU停顿警告。

+-----------------------------------------------------------------------+
| **快速问答**：                                                         |
+-----------------------------------------------------------------------+
| 但是如果我的驱动程序有一个可以运行很多秒的硬件中断处理程序怎么办？我毕竟不能在硬件中断处理程序中调用schedule()！ |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 一种方法是每隔一段时间执行一次 ``ct_irq_exit(); ct_irq_enter();``。但是考虑到长时间运行的中断处理程序可能会引起其他问题，尤其是对响应时间的影响，你不应该努力将你的中断处理程序的运行时间保持在合理的范围内吗？ |
+-----------------------------------------------------------------------+

但是只要RCU被正确地通知内核状态转换（包括内核执行、用户模式执行和空闲），并且在RCU需要时启用调度时钟中断，你可以放心，遇到的任何错误都将在RCU的其他部分或内核的其他部分中。

内存效率
~~~~~~~~~~~~~~

虽然小型非实时系统可以直接使用Tiny RCU，但代码大小只是内存效率的一个方面。另一个方面是 ``rcu_head`` 结构的大小，该结构由call_rcu()和kfree_rcu()使用。尽管这个结构只包含一对指针，但它确实出现在许多RCU保护的数据结构中，包括一些对大小要求严格的数据结构。例如，``page`` 结构就是一个很好的例子，这一点可以从该结构中多次出现的 ``union`` 关键字看出。
这种对内存效率的需求是RCU使用手工制作的单链表来跟踪等待恩典期结束的 ``rcu_head`` 结构的原因之一。这也是为什么 ``rcu_head`` 结构不包含调试信息，如跟踪调用call_rcu()或kfree_rcu()的文件和行号的字段。尽管这种信息可能会在未来某个时候出现在仅用于调试的内核构建中，但在那之前， ``->func`` 字段通常会提供所需的调试信息。
然而，在某些情况下，对内存效率的需求会导致更极端的措施。回到 ``page`` 结构， ``rcu_head`` 字段与其他许多在整个页面生命周期的不同阶段使用的结构共享存储空间。为了正确解决某些 `竞争条件 <https://lore.kernel.org/r/1439976106-137226-1-git-send-email-kirill.shutemov@linux.intel.com>`__，Linux内核的内存管理子系统需要特定位在所有恩典期处理阶段保持为零，而这一位恰好映射到 ``rcu_head`` 结构的 ``->next`` 字段的最低位。RCU只要使用call_rcu()而不是kfree_rcu()或其他可能出于能效目的创建的未来“懒惰”变体来发布回调，就保证了这一点。
话虽如此，还是有限制的。RCU要求 ``rcu_head`` 结构必须对齐到两字节边界，并且将未对齐的 ``rcu_head`` 结构传递给call_rcu()系列函数会导致崩溃。因此，在打包包含 ``rcu_head`` 类型字段的结构时需要谨慎。为什么不采用四字节甚至八字节对齐呢？因为m68k架构只支持两字节对齐，因此成为对齐的最小公倍数。
保留指向 ``rcu_head`` 结构的指针的最低位是为了留出“懒惰”回调的大门，其调用可以安全地延迟。延迟调用可能具有潜在的能效优势，但前提是对于某些重要工作负载，非懒惰回调的数量显著减少。
与此同时，保留最低位保留了这一选项，以防有一天它变得有用。

性能、可扩展性、响应时间和可靠性
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

继续之前的 `讨论 <Performance and Scalability_>`__，RCU在Linux内核的网络、安全、虚拟化和调度代码路径中的热点代码路径中被广泛使用。因此，RCU必须使用高效的实现，特别是在其读端原语中。为此，最好使抢占式RCU的rcu_read_lock()实现能够内联，但这需要解决与 ``task_struct`` 结构相关的 ``#include`` 问题。
Linux内核支持最多4096个CPU的硬件配置，这意味着RCU必须极其可扩展。涉及频繁获取全局锁或频繁对全局变量进行原子操作的算法根本无法容忍在RCU实现中。因此，RCU大量使用基于 ``rcu_node`` 结构的组合树。RCU必须能够容忍所有CPU连续调用RCU运行时原语的任意组合，并且每个操作的开销最小。实际上，在许多情况下，增加负载必须 *减少* 每个操作的开销，参见synchronize_rcu()、call_rcu()、synchronize_rcu_expedited() 和 rcu_barrier() 的批处理优化。作为一般规则，RCU必须愉快地接受Linux内核决定投掷的任何内容。
Linux内核用于实时工作负载，特别是结合 `-rt补丁集 <https://wiki.linuxfoundation.org/realtime/>`__ 使用。实时延迟响应要求使得传统的在RCU读端临界区禁用抢占的方法不合适。因此，使用 ``CONFIG_PREEMPTION=y`` 构建的内核使用允许RCU读端临界区被抢占的RCU实现。这一需求是在用户明确表示早期 `实时补丁 <https://lwn.net/Articles/107930/>`__ 不满足他们的需求，并结合非常早期版本的-rt补丁集中遇到的一些 `RCU问题 <https://lore.kernel.org/r/20050318002026.GA2693@us.ibm.com>`__ 后显现出来的。
此外，RCU 必须在不超过 100 微秒的实时延迟预算内工作。实际上，在带有 -rt 补丁集的小型系统上，Linux 内核为整个内核（包括 RCU）提供了小于 20 微秒的实时延迟。因此，RCU 的可扩展性和延迟必须足够满足这些类型的配置。令我惊讶的是，即使在最大的系统上，100 微秒的实时延迟预算也适用，包括多达 4096 个 CPU 的系统 [PDF] <http://www.rdrop.com/users/paulmck/realtime/paper/bigrt.2013.01.31a.LCA.pdf>。这一实时要求促使了 grace-period kthread 的引入，同时也简化了许多竞态条件的处理。

RCU 必须避免降低 CPU 密集型线程的实时响应，无论它们是在用户模式下执行（这是 ``CONFIG_NO_HZ_FULL=y`` 的一个使用场景），还是在内核中执行。话虽如此，内核中的 CPU 密集型循环必须至少每几十毫秒执行一次 cond_resched()，以避免收到 RCU 发送的 IPI。

作为同步原语的地位意味着任何 RCU 失败都可能导致任意内存损坏，这将极其难以调试。这意味着 RCU 必须极其可靠，实际上也意味着 RCU 必须具备一套积极的压力测试套件。这个压力测试套件被称为 ``rcutorture``。

虽然需要 ``rcutorture`` 并不令人意外，但当前 Linux 内核的极大普及带来了有趣的——也许是前所未有的——验证挑战。考虑到如今有超过十亿个实例在运行 Linux 内核，从 Android 智能手机到 Linux 驱动的电视和服务器，这个数字随着物联网的兴起将会急剧增加。

假设 RCU 中存在一个平均每百万年才会出现一次的竞态条件。这个错误每天在整个安装基础上会出现大约三次。RCU 可以简单地依赖硬件错误率，因为没有人真的期望他们的智能手机能够持续一百万年。然而，任何对此感到安慰的人应该考虑这样一个事实：在大多数司法管辖区，对某个机制的成功多年测试足以获得多种类型的安全关键认证。事实上，据说 Linux 内核已经在安全关键应用中投入生产。我不知道你是否和我一样，如果 RCU 中的一个错误导致了人员伤亡，我会非常不安。这也可能是我最近专注于验证和确认的原因之一。

其他 RCU 变体
---------------

RCU 的一个更令人惊讶之处在于，现在至少有五种不同的“变体”或 API 家族。此外，迄今为止唯一关注的主要变体有两个不同的实现：非抢占式和抢占式。其他四种变体如下所示，各自的要求将在单独的部分中描述：

1. `底半部变体（历史）`_
2. `调度变体（历史）`_
3. `可睡眠 RCU`_
4. `任务 RCU`_
5. `任务跟踪 RCU`_

底半部变体（历史）
~~~~~~~~~~~~~~~~~~~~

RCU-bh 变体已经被表示为其他 RCU 变体的一部分，作为将三种变体合并为一种变体的一部分。读取端 API 仍然存在，并继续禁用软中断并被锁依赖所跟踪。因此，本节中的许多材料严格来说是历史性的。

软中断禁用（即“底半部”，因此简称“_bh”）的 RCU 变体，或称 *RCU-bh*，是由 Dipankar Sarma 开发的，目的是提供一种能够抵御 Robert Olsson 研究的基于网络的拒绝服务攻击的 RCU 变体。这些攻击在网络负载方面对系统施加了如此大的压力，以至于一些 CPU 从未退出软中断执行，从而阻止这些 CPU 执行上下文切换，进而使得当时的 RCU 实现中的优雅周期永远无法结束。结果是内存不足并导致系统挂起。

解决方案是创建 RCU-bh，它会在其读取端临界区中执行 local_bh_disable()，并且使用从一种软中断处理到另一种的转换作为静默状态，除了上下文切换、空闲、用户模式和离线之外。这意味着即使某些 CPU 无限期地执行软中断，RCU-bh 的优雅周期也可以完成，从而使基于 RCU-bh 的算法能够承受基于网络的拒绝服务攻击。

由于 rcu_read_lock_bh() 和 rcu_read_unlock_bh() 分别禁用和重新启用软中断处理器，因此在 RCU-bh 读取端临界区内尝试启动任何软中断处理器都会被推迟。在这种情况下，rcu_read_unlock_bh() 将调用软中断处理，这可能需要相当长的时间。当然可以争论这种软中断开销应该与 RCU-bh 读取端临界区后的代码相关联，而不是与 rcu_read_unlock_bh() 相关联，但事实是大多数剖析工具不能预期做出这种细微的区别。例如，假设一个三毫秒长的 RCU-bh 读取端临界区在高网络负载期间执行。在这三毫秒内很可能至少会尝试调用一个软中断处理器，但任何此类调用都将被推迟到 rcu_read_unlock_bh() 时。这当然会让 rcu_read_unlock_bh() 看起来像是在缓慢执行。
RCU-bh API 包括 rcu_read_lock_bh()、rcu_read_unlock_bh()、rcu_dereference_bh()、rcu_dereference_bh_check() 和 rcu_read_lock_bh_held()。然而，旧的 RCU-bh 更新侧 API 已经被移除，取而代之的是 synchronize_rcu()、synchronize_rcu_expedited()、call_rcu() 和 rcu_barrier()。此外，任何禁用底半部（bottom half）的操作也会标记一个 RCU-bh 读侧临界区，包括 local_bh_disable() 和 local_bh_enable()，local_irq_save() 和 local_irq_restore() 等。

### Sched Flavor（历史）

RCU-sched 味道的 RCU 已经通过其他 RCU 味道进行表达，作为将三种味道整合为一种味道的一部分。读侧 API 仍然保留，并继续禁用抢占并由锁依赖（lockdep）进行跟踪。因此，本节中的许多内容严格来说具有历史性质。

在可抢占 RCU 出现之前，等待 RCU 宽限期会顺带等待所有现有的中断和 NMI 处理程序。然而，存在合法的可抢占 RCU 实现，这些实现不具有此特性，因为代码中任何不在 RCU 读侧临界区之外的地方都可以是一个静默状态。因此，创建了 *RCU-sched*，它遵循“经典”RCU 的方式，在 RCU-sched 宽限期内等待现有中断和 NMI 处理程序。在使用 ``CONFIG_PREEMPTION=n`` 构建的内核中，RCU 和 RCU-sched API 具有相同的实现；而在使用 ``CONFIG_PREEMPTION=y`` 构建的内核中，则为每个提供了单独的实现。

请注意，在 ``CONFIG_PREEMPTION=y`` 内核中，rcu_read_lock_sched() 和 rcu_read_unlock_sched() 分别禁用和重新启用抢占。这意味着如果在 RCU-sched 读侧临界区内发生了抢占尝试，rcu_read_unlock_sched() 将进入调度器，伴随着所有的延迟和开销。与 rcu_read_unlock_bh() 类似，这可能使 rcu_read_unlock_sched() 看起来执行得非常缓慢。但是，最高优先级的任务不会被抢占，因此该任务将享受低开销的 rcu_read_unlock_sched() 调用。

RCU-sched API 包括 rcu_read_lock_sched()、rcu_read_unlock_sched()、rcu_read_lock_sched_notrace()、rcu_read_unlock_sched_notrace()、rcu_dereference_sched()、rcu_dereference_sched_check() 和 rcu_read_lock_sched_held()。然而，旧的 RCU-sched 更新侧 API 已经被移除，取而代之的是 synchronize_rcu()、synchronize_rcu_expedited()、call_rcu() 和 rcu_barrier()。此外，任何禁用抢占的操作也会标记一个 RCU-sched 读侧临界区，包括 preempt_disable() 和 preempt_enable()，local_irq_save() 和 local_irq_restore() 等。

### 可睡眠 RCU

十多年来，“我需要在 RCU 读侧临界区内阻塞”一直是表明某人不了解 RCU 的可靠标志。毕竟，如果你总是在 RCU 读侧临界区内阻塞，那么你可能可以承受更高开销的同步机制。然而，随着 Linux 内核通知器的出现，其 RCU 读侧临界区几乎从不休眠，但有时需要这样做，从而引入了 `可睡眠 RCU <https://lwn.net/Articles/202847/>`__ 或 *SRCU*。

SRCU 允许定义不同的域，每个这样的域由一个 ``srcu_struct`` 结构实例定义。必须将指向该结构的指针传递给每个 SRCU 函数，例如 ``synchronize_srcu(&ss)``，其中 ``ss`` 是 ``srcu_struct`` 结构。这些域的关键好处是，一个域中的慢 SRCU 读者不会延迟另一个域中的 SRCU 宽限期。

也就是说，这些域的一个后果是读侧代码必须从 srcu_read_lock() 到 srcu_read_unlock() 传递一个“cookie”，如下所示：

   ::

       1 int idx;
       2
       3 idx = srcu_read_lock(&ss);
       4 do_something();
       5 srcu_read_unlock(&ss, idx);

如上所述，可以在 SRCU 读侧临界区内阻塞，但权力越大责任越大。如果你在一个给定域的 SRCU 读侧临界区内永久阻塞，那么该域的宽限期也将永远被阻塞。

当然，一个很好的永久阻塞方法是死锁，这可能会发生在一个给定域的 SRCU 读侧临界区内的任何操作直接或间接等待该域的宽限期结束。例如，这会导致自死锁：

   ::

       1 int idx;
       2
       3 idx = srcu_read_lock(&ss);
       4 do_something();
       5 synchronize_srcu(&ss);
       6 srcu_read_unlock(&ss, idx);

然而，如果第 5 行获取了一个在域 ``ss`` 的 synchronize_srcu() 中持有的互斥锁，死锁仍然可能发生。此外，如果第 5 行获取了一个在另一域 ``ss1`` 的 synchronize_srcu() 中持有的互斥锁，并且 ``ss1`` 域的 SRCU 读侧临界区获取了另一个在 ``ss`` 域的 synchronize_srcu() 中持有的互斥锁，死锁同样可能发生。这种死锁循环可以延伸到任意多个不同的 SRCU 域。再次强调，权力越大责任越大。
与其它RCU变种不同，SRCU的读侧临界区可以在空闲甚至离线的CPU上运行。这种能力要求`srcu_read_lock()`和`srcu_read_unlock()`包含内存屏障，这意味着SRCU读取者将比RCU读取者运行得稍慢一些。这也促使了`smp_mb__after_srcu_read_unlock()` API的出现，结合`srcu_read_unlock()`使用时，可以保证一个完整的内存屏障。

同样不同于其他RCU变种，`synchronize_srcu()`**不能**从CPU热插拔通知器中调用，这是因为SRCU的宽限期使用了定时器，并且存在定时器暂时“滞留”在即将离线的CPU上的可能性。定时器的滞留意味着发送到即将离线CPU的定时器不会在CPU热插拔过程的早期触发。问题是如果一个通知器正在等待一个SRCU宽限期，而这个宽限期又依赖于一个滞留在即将离线CPU上的定时器，则该通知器将永远不会被唤醒，换句话说，就会发生死锁。同样的情况也禁止`srcu_barrier()`从CPU热插拔通知器中调用。

SRCU还与其他RCU变种不同之处在于其加速和非加速宽限期由相同的机制实现。这意味着在当前的SRCU实现中，加速未来的宽限期会有一个副作用，即加速所有尚未完成的先前宽限期。（但请注意，这是当前实现的特性，并不一定是未来实现的特性。）此外，如果SRCU已闲置的时间超过内核启动参数`srcutree.exp_holdoff`（默认为25微秒）所指定的间隔，并且如果`synchronize_srcu()`调用结束了这一闲置期，则该调用将自动加速。

自v4.12版本起，SRCU的回调函数按每CPU维护，消除了以前内核版本中存在的锁定瓶颈。虽然这将允许用户对`call_srcu()`施加更大的压力，但重要的是要注意，SRCU目前还没有采取任何特殊措施来应对回调洪泛。因此，如果你每秒每CPU发布（例如）10,000个SRCU回调，你可能完全没问题，但如果你打算每秒每CPU发布（例如）1,000,000个SRCU回调，请先进行一些测试。SRCU可能需要一些调整才能应对这种负载。当然，你的结果可能会根据CPU的速度和内存大小有所不同。

SRCU API包括`srcu_read_lock()`、`srcu_read_unlock()`、`srcu_dereference()`、`srcu_dereference_check()`、`synchronize_srcu()`、`synchronize_srcu_expedited()`、`call_srcu()`、`srcu_barrier()`和`srcu_read_lock_held()`。还包括用于定义和初始化`srcu_struct`结构的`DEFINE_SRCU()`、`DEFINE_STATIC_SRCU()`和`init_srcu_struct()` API。

最近，SRCU API增加了轮询接口：

1. `start_poll_synchronize_srcu()`返回一个标识符，标识未来SRCU宽限期的完成，并确保此宽限期将被启动。
2. `poll_state_synchronize_srcu()`如果指定的标识符对应于已完成的SRCU宽限期，则返回`true`。
3. `get_state_synchronize_srcu()`像`start_poll_synchronize_srcu()`一样返回一个标识符，但不同之处在于它不做任何事情来确保任何未来SRCU宽限期的启动。

这些函数用于避免某些具有多阶段老化机制的缓冲缓存算法中的不必要的SRCU宽限期。其思路是，在块完全从缓存老化之前，一个SRCU宽限期很可能已经过去。

### 任务RCU

某些形式的跟踪使用“蹦床”来处理安装不同类型探针所需的二进制重写。能够释放旧的蹦床听起来像是RCU的一项工作。然而，由于需要能够在代码的任何地方安装跟踪，因此无法使用如`rcu_read_lock()`和`rcu_read_unlock()`这样的读侧标记。此外，也不能在蹦床本身中使用这些标记，因为需要在`rcu_read_unlock()`之后有指令。尽管`syncrhonize_rcu()`可以保证执行到达`rcu_read_unlock()`，但它无法保证执行完全离开蹦床。更糟糕的是，在某些情况下，蹦床的保护必须在执行到达蹦床之前扩展几个指令。例如，这些指令可能计算出蹦床的地址，使得进入蹦床会在执行实际到达蹦床之前很长一段时间就预定好了。
解决方案是采用 `Tasks RCU <https://lwn.net/Articles/607117/>`__，该方案通过自愿上下文切换来界定隐式的读侧临界区，即对 `schedule()`、`cond_resched()` 和 `synchronize_rcu_tasks()` 的调用。此外，用户空间执行的进入和退出也会界定 Tasks RCU 的读侧临界区。空闲任务被 Tasks RCU 忽略，可以使用 Tasks Rude RCU 来与它们交互。

请注意，非自愿上下文切换并不是 Tasks RCU 的静默状态。毕竟，在抢占式内核中，正在执行跳板代码的任务可能会被抢占。在这种情况下，Tasks RCU 的宽限期显然不能在该任务恢复并离开跳板之前结束。这意味着 `cond_resched()` 不提供 Tasks RCU 的静默状态。（相反，请从软中断中使用 `rcu_softirq_qs()` 或者在其他情况下使用 `rcu_tasks_classic_qs()`。）

Tasks RCU 的 API 非常紧凑，仅包括 `call_rcu_tasks()`、`synchronize_rcu_tasks()` 和 `rcu_barrier_tasks()`。在 `CONFIG_PREEMPTION=n` 内核中，跳板代码不会被抢占，因此这些 API 分别映射到 `call_rcu()`、`synchronize_rcu()` 和 `rcu_barrier()`。在 `CONFIG_PREEMPTION=y` 内核中，跳板代码会被抢占，因此这三个 API 通过单独的函数实现，检查自愿上下文切换。

### Tasks Rude RCU

某些跟踪形式需要等待所有在线 CPU 上的所有禁用抢占区域中的代码，包括 RCU 未监控时执行的代码。这意味着 `synchronize_rcu()` 是不够的，必须使用 Tasks Rude RCU。这种 RCU 的工作方式是迫使每个在线 CPU 调度一个工作队列，因此被称为“粗鲁”（"Rude"）。实时工作负载不希望其 `nohz_full` CPU 接收 IPI，电池供电系统也不希望其空闲 CPU 被唤醒，这被认为是相当粗鲁的操作。

一旦内核入口/出口和深度休眠函数被正确标记为 `noinstr`，Tasks RCU 可以开始关注空闲任务（除了那些从 RCU 角度来看处于空闲状态的任务），然后可以从内核中移除 Tasks Rude RCU。

Tasks Rude RCU 的 API 也是无读者标记的，因此非常紧凑，包括 `call_rcu_tasks_rude()`、`synchronize_rcu_tasks_rude()` 和 `rcu_barrier_tasks_rude()`。

### Tasks Trace RCU

某些跟踪形式需要在读者中睡眠，但无法容忍 SRCU 的读侧开销，其中包括 `srcu_read_lock()` 和 `srcu_read_unlock()` 中的完整内存屏障。这种需求由使用调度器锁定和 IPI 同步读者的 Tasks Trace RCU 处理。无法容忍 IPI 的实时系统可以通过配置 `CONFIG_TASKS_TRACE_RCU_READ_MB=y` 来避免 IPI，代价是在读侧原语中添加完整的内存屏障。

Tasks Trace RCU 的 API 也相对紧凑，包括 `rcu_read_lock_trace()`、`rcu_read_unlock_trace()`、`rcu_read_lock_trace_held()`、`call_rcu_tasks_trace()`、`synchronize_rcu_tasks_trace()` 和 `rcu_barrier_tasks_trace()`。

### 可能的未来变化

RCU 用来实现更新侧可扩展性的一个技巧是随着 CPU 数量的增加而增加宽限期延迟。如果这成为一个严重问题，则有必要重构宽限期状态机以避免额外的延迟。

RCU 在一些地方禁用了 CPU 热插拔，最显著的是在 `rcu_barrier()` 操作中。如果在 CPU 热插拔通知器中有强烈理由使用 `rcu_barrier()`，则需要避免禁用 CPU 热插拔。这会引入一些复杂性，因此必须有一个 **非常好的理由**。
权衡优雅期延迟与对其他CPU的中断可能需要重新审视。当然，理想的情况是优雅期延迟为零，并且在加速优雅期操作期间不产生跨处理器中断。虽然这一理想状态不太可能实现，但很有可能还能进一步改进。

多处理器实现的 RCU 使用了一种组合树结构，将 CPU 分组以减少锁竞争并提高缓存局部性。然而，这种组合树并没有将内存分布到 NUMA 节点上，也没有将 CPU 组与硬件特性（如插槽或核心）对齐。目前认为这种分布和对齐是没有必要的，因为热点路径读取侧原语不会访问组合树，而在常见情况下 `call_rcu()` 也不会访问它。如果您认为您的架构需要这种分布和对齐，那么您的架构也应该从 `rcutree.rcu_fanout_leaf` 引导参数中受益，该参数可以设置为一个插槽、NUMA 节点或任何其他数量的 CPU 数目。如果 CPU 数目过大，可以使用 CPU 数目的一个分数。如果 CPU 数目是一个大的质数，这确实是一个“有趣”的架构选择！可以考虑更灵活的安排，但前提是 `rcutree.rcu_fanout_leaf` 已经证明不足，并且这种不足已经通过仔细运行和现实的系统级工作负载进行了验证。

请注意，需要 RCU 重新映射 CPU 编号的安排需要极其充分地证明其必要性，并全面探索替代方案。

RCU 的各种 kthreads 是相对较新的添加。很可能需要调整来更优雅地处理极端负载。可能还需要能够将 RCU 的 kthreads 和软中断处理器的 CPU 利用率追溯到引发这些 CPU 利用率的代码。例如，RCU 回调开销可能会归因于原始的 `call_rcu()` 实例，尽管在生产内核中可能不会这样做。

在重负载下，可能还需要额外的工作来提供合理的前进保证，以确保优雅期和回调调用的顺利进行。

### 总结

本文档介绍了超过二十年的 RCU 需求。鉴于需求不断变化，这不会是最后一个版本，但至少它有助于阐述一个重要子集的需求。

### 致谢

我非常感谢 Steven Rostedt、Lai Jiangshan、Ingo Molnar、Oleg Nesterov、Borislav Petkov、Peter Zijlstra、Boqun Feng 和 Andy Lutomirski 对使这篇文章易于理解的帮助，以及 Michelle Rankin 对这项工作的支持。其他贡献者在 Linux 内核的 Git 存储库中有记录。
