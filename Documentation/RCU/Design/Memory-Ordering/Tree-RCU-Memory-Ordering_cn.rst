树形 RCU 的宽限期内存排序之旅
==================================

2017年8月8日

本文由 Paul E. McKenney 贡献

简介
====

本文档大致提供了一个关于树形 RCU 如何提供宽限期内存排序保证的视觉概览。

什么是树形 RCU 的宽限期内存排序保证？
========================================

RCU 宽限期提供了非常强大的内存排序保证，适用于非空闲且未离线的代码。
任何发生在特定 RCU 宽限期结束之后的代码，都保证能看到该宽限期开始之前所有 RCU 读侧临界区内的访问效果。
同样，任何发生在特定 RCU 宽限期开始之前的代码，都保证不会看到该宽限期结束之后所有 RCU 读侧临界区内的访问效果。
请注意，RCU-sched 读侧临界区包括任何禁用抢占的代码区域。
鉴于每个单独的机器指令可以被认为是一个极小的禁用抢占的代码区域，因此可以将 ``synchronize_rcu()`` 视为增强版的 ``smp_mb()``。
RCU 更新者利用这一保证将其更新分为两个阶段：一个在宽限期之前执行，另一个在宽限期之后执行。
最常见的用例中，第一阶段从链接的 RCU 保护数据结构中移除一个元素，第二阶段释放该元素。
为了使这有效工作，任何观察到第一阶段更新前状态（常见情况下是移除）的读者，必须不能观察到第二阶段更新后状态（常见情况下是释放）。
RCU 实现使用基于锁的临界区网络、内存屏障和每 CPU 处理来提供这一保证，具体如下文所述。
RCU的恩宠期内存排序的核心组件是`rcu_node`结构中的`->lock`临界区。这些临界区使用锁获取辅助函数，包括`raw_spin_lock_rcu_node()`、`raw_spin_lock_irq_rcu_node()`和`raw_spin_lock_irqsave_rcu_node()`。它们对应的锁释放函数分别是`raw_spin_unlock_rcu_node()`、`raw_spin_unlock_irq_rcu_node()`和`raw_spin_unlock_irqrestore_rcu_node()`。为了完整性，还提供了一个`raw_spin_trylock_rcu_node()`。关键点在于，所有锁获取函数（包括`raw_spin_trylock_rcu_node()`）在成功获取锁后立即调用`smp_mb__after_unlock_lock()`。

因此，对于任何一个`rcu_node`结构，在上述任一锁释放函数之前的任何访问，都将被所有CPU视为发生在之后的锁获取函数之后的任何访问之前。此外，在任一给定CPU上，在上述任一锁释放函数之前的任何访问，将被所有CPU视为发生在同一CPU上执行的后续锁获取函数之后的任何访问之前，即使锁释放和锁获取函数作用于不同的`rcu_node`结构。

Tree RCU利用这两个排序保证来构建一个涉及恩宠期内所有CPU的排序网络，包括在此期间上线或下线的CPU。

以下是一个展示这些锁获取和锁释放函数排序效果的测试示例：

```c
1 int x, y, z;
2
3 void task0(void)
4 {
5   raw_spin_lock_rcu_node(rnp);
6   WRITE_ONCE(x, 1);
7   r1 = READ_ONCE(y);
8   raw_spin_unlock_rcu_node(rnp);
9 }
10
11 void task1(void)
12 {
13   raw_spin_lock_rcu_node(rnp);
14   WRITE_ONCE(y, 1);
15   r2 = READ_ONCE(z);
16   raw_spin_unlock_rcu_node(rnp);
17 }
18
19 void task2(void)
20 {
21   WRITE_ONCE(z, 1);
22   smp_mb();
23   r3 = READ_ONCE(x);
24 }
25
26 WARN_ON(r1 == 0 && r2 == 0 && r3 == 0);
```

`WARN_ON()` 在“时间的尽头”进行评估，即所有更改已传播到整个系统之后。如果没有锁获取函数提供的`smp_mb__after_unlock_lock()`，这个`WARN_ON()`可能会触发，例如在PowerPC上。调用`smp_mb__after_unlock_lock()`防止了`WARN_ON()`的触发。
+-----------------------------------------------------------------------+
| **快速测验**：                                                      |
+-----------------------------------------------------------------------+
| 但是，rcu_node-structure锁获取链确保新读取者能够看到更新者在宽限期内的所有访问，并且还确保更新者在宽限期后的访问能够看到所有旧读取者的访问。那么，为什么我们需要所有这些对smp_mb__after_unlock_lock()的调用呢？|
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 因为我们必须为RCU的轮询宽限期原语提供顺序，例如get_state_synchronize_rcu()和poll_state_synchronize_rcu()。考虑以下代码：|

|  CPU 0                                     CPU 1                      |
|  ----                                      ----                       |
|  WRITE_ONCE(X, 1)                          WRITE_ONCE(Y, 1)           |
|  g = get_state_synchronize_rcu()           smp_mb()                   |
|  while (!poll_state_synchronize_rcu(g))    r1 = READ_ONCE(X)          |
|          continue;                                                    |
|  r0 = READ_ONCE(Y)                                                    |

| RCU保证结果r0 == 0 && r1 == 0不会发生，即使CPU 1处于RCU扩展静默状态（空闲或离线），因此不会直接与RCU核心处理进行交互。|
+-----------------------------------------------------------------------+

这种方法必须扩展以包括空闲的CPU，这些CPU需要RCU的宽限期内存排序保证扩展到当前空闲期间之前和之后的任何RCU读侧临界区。
这种情况下通过在进入空闲时调用`rcu_dynticks_eqs_enter()`中的强序`atomic_add_return()`读修改写原子操作以及在退出空闲时调用`rcu_dynticks_eqs_exit()`来处理。
宽限期kthread首先调用`ct_dynticks_cpu_acquire()`（由完整的内存屏障前置）和`rcu_dynticks_in_eqs_since()`（两者都依赖于获取语义）来检测空闲的CPU。
+-----------------------------------------------------------------------+
| **快速测验**：                                                      |
+-----------------------------------------------------------------------+
| 但是如果整个宽限期内保持离线的CPU怎么办？                              |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 这样的CPU将在宽限期开始时离线，因此宽限期不会期望它们的静默状态。宽限期开始和CPU热插拔操作之间的竞争由该CPU的叶rcu_node结构的->lock如上所述处理。|
+-----------------------------------------------------------------------+

该方法还必须处理最后一个情况，即唤醒被阻塞在`synchronize_rcu()`中的任务。这个任务可能绑定到一个尚未意识到宽限期已结束的CPU上，因此可能还未受到宽限期内存排序的影响。因此，在`synchronize_rcu()`代码路径中`wait_for_completion()`返回后有一个`smp_mb()`。
+-----------------------------------------------------------------------+
| **快速测验**：                                                      |
+-----------------------------------------------------------------------+
| 什么？在哪里？？？我没有看到`wait_for_completion()`返回后有任何`smp_mb()`！！！ |
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 这是因为我在创建此文档时注意到了需要那个`smp_mb()`，因此它不太可能在v4.14之前进入主线。感谢Lance Roy、Will Deacon、Peter Zijlstra和Jonathan Cameron提出的问题，使我对展示需要这个内存屏障的复杂事件序列变得敏感。|
+-----------------------------------------------------------------------+

树状RCU的宽限期内存排序保证主要依赖于rcu_node结构的->lock字段，以至于有必要在下一部分的图示中缩写这种模式。例如，考虑下面所示的`rcu_prepare_for_idle()`函数，它是几个强制新到达的RCU回调与未来宽限期排序的函数之一：

```c
static void rcu_prepare_for_idle(void)
{
  bool needwake;
  struct rcu_data *rdp = this_cpu_ptr(&rcu_data);
  struct rcu_node *rnp;
  int tne;

  lockdep_assert_irqs_disabled();
  if (rcu_rdp_is_offloaded(rdp))
    return;

  /* 处理保守的nohz启用切换。 */
  tne = READ_ONCE(tick_nohz_active);
  if (tne != rdp->tick_nohz_enabled_snap) {
    if (!rcu_segcblist_empty(&rdp->cblist))
      invoke_rcu_core(); /* 强制nohz看到更新。 */
    rdp->tick_nohz_enabled_snap = tne;
    return;
  }
  if (!tne)
    return;

  /*
   * 如果我们还没有加速这个滴答时间，则加速该CPU上的所有回调。
   */
  if (rdp->last_accelerate == jiffies)
    return;
  rdp->last_accelerate = jiffies;
  if (rcu_segcblist_pend_cbs(&rdp->cblist)) {
    rnp = rdp->mynode;
    raw_spin_lock_rcu_node(rnp); /* 中断已禁用。 */
    needwake = rcu_accelerate_cbs(rnp, rdp);
    raw_spin_unlock_rcu_node(rnp); /* 中断仍禁用。 */
    if (needwake)
      rcu_gp_kthread_wake();
  }
}
```

但`rcu_prepare_for_idle()`中真正重要的部分是第32-34行。因此我们将此函数简化如下：

.. kernel-figure:: rcu_node-lock.svg

框代表rcu_node结构的->lock临界区，顶部的双线表示额外的`smp_mb__after_unlock_lock()`。

树状RCU宽限期内存排序组件
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

树状RCU的宽限期内存排序保证由多个RCU组件提供：

1. `回调注册`_
2. `宽限期初始化`_
3. `自我报告的静默状态`_
4. `动态滴答接口`_
5. `CPU热插拔接口`_
6. `强制静默状态`_
7. `宽限期清理`_
8. `回调调用`_

每个后续部分将详细查看相应的组件。

回调注册
^^^^^^^^^^^^^^^^^^

如果RCU的宽限期保证要具有任何意义，那么发生在给定`call_rcu()`调用之前的任何访问也必须发生在相应的宽限期内。RCU宽限期保证的这一部分实现如以下图所示：

.. kernel-figure:: TreeRCU-callback-registry.svg

由于`call_rcu()`通常仅作用于CPU本地状态，因此它不提供任何排序保证，无论是对自己还是对更新的第一阶段（这通常是从RCU保护的数据结构中删除元素）。它只是将`rcu_head`结构入队到每CPU列表中，直到稍后调用`rcu_accelerate_cbs()`才能与宽限期关联，如上面的图所示。

一组代码路径在左边调用`rcu_accelerate_cbs()`通过`note_gp_changes()`，要么直接从`call_rcu()`（如果当前CPU充斥着排队的`rcu_head`结构），或者更可能来自`RCU_SOFTIRQ`处理器。中间的另一条代码路径只存在于编译了`CONFIG_RCU_FAST_NO_HZ=y`的内核中，通过`rcu_prepare_for_idle()`调用`rcu_accelerate_cbs()`。右边的最后一条代码路径只存在于编译了`CONFIG_HOTPLUG_CPU=y`的内核中，通过`rcu_advance_cbs()`、`rcu_migrate_callbacks`、`rcutree_migrate_callbacks()`和`takedown_cpu()`调用`rcu_accelerate_cbs()`，而`takedown_cpu()`是在出站CPU完全离线后在存活的CPU上调用的。
在优雅期处理中有几条其他代码路径会投机性地调用 `rcu_accelerate_cbs()`。然而，无论如何，所有最近排队的 `rcu_head` 结构都与未来的优雅期编号关联，并受到 CPU 的主 `rcu_node` 结构的 `->lock` 保护。在所有情况下，对于同一个 `rcu_node` 结构的 `->lock`，存在对任何先前临界区的完全排序，同时也对当前任务或 CPU 的任何先前临界区存在完全排序，针对任何 `rcu_node` 结构的 `->lock`。

下一节将展示这种排序如何确保在 `call_rcu()` 之前的任何访问（特别是更新的第一阶段）发生在相应的优雅期开始之前。
+-----------------------------------------------------------------------+
| **快速问答**：                                                      |
+-----------------------------------------------------------------------+
| 但是 `synchronize_rcu()` 呢？                                        |
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| `synchronize_rcu()` 将 `call_rcu()` 传递给 `wait_rcu_gp()`，后者调用它。因此，无论如何，最终归结为 `call_rcu()`。|
+-----------------------------------------------------------------------+

### 优雅期初始化
^^^^^^^^^^^^^^^^^^^^^^^^^^^

优雅期初始化由优雅期内核线程执行，在 `rcu_gp_init()` 函数中多次遍历 `rcu_node` 树。这意味着要展示优雅期计算中的完整排序流，需要复制这棵树。如果你觉得困惑，请注意 `rcu_node` 的状态随时间变化，就像赫拉克利特的河流一样。然而，为了使 `rcu_node` 河流易于管理，优雅期内核线程的遍历分多个部分呈现，从本节开始介绍优雅期初始化的不同阶段。

优雅期初始化的第一个与排序相关的操作是推进 `rcu_state` 结构的 `->gp_seq` 优雅期编号计数器，如下图所示：

.. kernel-figure:: TreeRCU-gp-init-1.svg

实际的递增是通过 `smp_store_release()` 完成的，这有助于拒绝错误的 RCU CPU 停滞检测。请注意，只有根 `rcu_node` 结构被触及。

第一次遍历 `rcu_node` 树时，根据自上一个优雅期开始以来 CPU 上线或下线的情况更新位掩码。在最常见的场景中，如果这个 `rcu_node` 结构的在线 CPU 数量没有变为零或从零变为非零，这次遍历将只扫描叶 `rcu_node` 结构。然而，如果某个叶 `rcu_node` 结构的在线 CPU 数量从零变为非零，则会调用 `rcu_init_new_rnp()` 为第一个上线的 CPU 处理。类似地，如果某个叶 `rcu_node` 结构的在线 CPU 数量变为零，则会调用 `rcu_cleanup_dead_rnp()` 为最后一个下线的 CPU 处理。

下图展示了如果最左边的 `rcu_node` 结构上线了它的第一个 CPU 并且下一个 `rcu_node` 结构没有在线 CPU（或者相反情况，即最左边的 `rcu_node` 结构下线了它的最后一个 CPU 并且下一个 `rcu_node` 结构没有在线 CPU）时的排序路径：
.. kernel-figure:: TreeRCU-gp-init-2.svg

最后，`rcu_gp_init()` 对 `rcu_node` 树进行宽度优先遍历，将每个 `rcu_node` 结构的 `->gp_seq` 字段设置为从 `rcu_state` 结构新推进的值，如下图所示：
.. kernel-figure:: TreeRCU-gp-init-3.svg

这一更改还将导致每个 CPU 下一次调用 `__note_gp_changes()` 时注意到新的优雅期已经开始，如下一节所述。但由于优雅期内核线程从根（推进 `rcu_state` 结构的 `->gp_seq` 字段）开始优雅期，然后才设置每个叶 `rcu_node` 结构的 `->gp_seq` 字段，每个 CPU 观察到优雅期开始的时间实际上是在优雅期真正开始之后。
+-----------------------------------------------------------------------+
| **快速问答**：                                                      |
+-----------------------------------------------------------------------+
| 但是启动优雅期的 CPU 呢？为什么它不会在启动优雅期时立即看到优雅期开始呢？|
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 在某种哲学和过度拟人化的意义上，是的，启动优雅期的 CPU 立即意识到自己已经这样做了。然而，如果我们假设 RCU 不具备自我意识，那么即使是启动优雅期的 CPU 也不是真正意识到这个优雅期的开始，直到它第一次调用 `__note_gp_changes()`。另一方面，这个 CPU 可能会提前收到通知，因为它在最后一次 `rcu_gp_init()` 遍历其叶 `rcu_node` 结构时调用了 `__note_gp_changes()`。|
+-----------------------------------------------------------------------+

### 自报告静默状态
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

当所有可能阻塞优雅期的实体报告了静默状态（或者如后一节所述，代表它们报告了静默状态），优雅期可以结束。在线的非空闲 CPU 报告自己的静默状态，如下图所示：

.. kernel-figure:: TreeRCU-qs.svg

这是最后一个报告静默状态的 CPU，它标志着优雅期的结束。早期的静默状态将仅向上推到 `rcu_node` 树中等待更多静默状态的 `rcu_node` 结构。然而，排序仍然得到保留，因为稍后的静默状态将获取该 `rcu_node` 结构的 `->lock`。

任何事件都可能导致 CPU 调用 `note_gp_changes`（或者直接调用 `__note_gp_changes()`），此时该 CPU 在持有其叶 `rcu_node` 锁时会注意到新优雅期的开始。因此，此图中显示的所有执行都在优雅期开始之后发生。此外，该 CPU 认为任何在调用 `__note_gp_changes()` 之前开始的 RCU 读侧临界区都是在优雅期之前开始的，因此优雅期必须等待这些临界区。
```markdown
+-----------------------------------------------------------------------+
| **快速测验**：                                                      |
+-----------------------------------------------------------------------+
| 但是，一个RCU读端临界区可能在宽限期（即``->gp_seq``的推进）开始后才启动，那么为什么宽限期要等待这样一个临界区呢？|
+-----------------------------------------------------------------------+
| **答案**：                                                            |
+-----------------------------------------------------------------------+
| 宽限期确实没有必要等待这样一个临界区。然而，允许等待它是可以的，并且进一步来说，等待它是重要的，因为这种懒惰的方法比“大爆炸”式的全部一次性启动宽限期更为可扩展。|
+-----------------------------------------------------------------------+

如果CPU进行了上下文切换，则会在左侧通过``rcu_note_context_switch()``记录一个静默状态。另一方面，如果CPU在用户模式执行过程中收到调度时钟中断，则会在右侧通过``rcu_sched_clock_irq()``记录一个静默状态。无论如何，经过这个静默状态将会在一个每CPU变量中被记录下来。
下一次当该CPU上执行一个``RCU_SOFTIRQ``处理器（例如，在下一个调度时钟中断之后），``rcu_core()``将调用``rcu_check_quiescent_state()``，该函数会注意到记录下来的静默状态，并调用``rcu_report_qs_rdp()``。如果``rcu_report_qs_rdp()``验证了这个静默状态确实适用于当前的宽限期，它将调用``rcu_report_rnp()``，该函数会遍历如图所示的``rcu_node``树，清除每个``rcu_node``结构的``->qsmask``字段中的位，并在结果为零时向上传播。
需要注意的是，只有当当前CPU报告了以该``rcu_node``结构为根的子树中的最后一个静默状态时，遍历才会向上传递出给定的``rcu_node``结构。关键的一点是，如果一个CPU的遍历在某个给定的``rcu_node``结构处停止，则会有另一个CPU（或可能是同一个CPU）稍后的遍历从该点向上继续，并且该``rcu_node``结构的``->lock``保证第一个CPU的静默状态发生在第二个CPU剩余遍历之前。反复应用这一思路表明，所有CPU的静默状态都发生在最后一个CPU遍历根``rcu_node``结构之前，“最后一个CPU”是指清除了根``rcu_node``结构的``->qsmask``字段中最后一个位的CPU。
动态Tick接口
^^^^^^^^^^^^^^^^^^^^^^

由于能效方面的考虑，RCU禁止干扰空闲的CPU。因此，CPU在进入或离开空闲状态时必须通知RCU，它们通过对每个CPU变量进行完全有序的原子操作来实现这一点。顺序效果如下所示：

.. kernel-figure:: TreeRCU-dyntick.svg

RCU宽限期内核线程在持有对应CPU的叶节点``rcu_node``结构的``->lock``时采样每CPU的空闲变量。这意味着任何先于空闲期发生的RCU读端临界区（图中上方的椭圆）将在当前宽限期结束前发生。同样地，当前宽限期的开始将发生在任何后于空闲期的RCU读端临界区之前（图中下方的椭圆）。
将此集成到完整的宽限期执行中详见下面的`强制静默状态`__部分。
CPU热插拔接口
^^^^^^^^^^^^^^^^^^^^^

RCU也被禁止干扰离线的CPU，这些CPU可能会被关闭并完全从系统中移除。因此，CPU在相应的CPU热插拔操作期间必须通知RCU它们的进出情况。顺序效果如下所示：

.. kernel-figure:: TreeRCU-hotplug.svg

由于CPU热插拔操作比空闲转换少得多，因此它们更重，并且获取CPU的叶节点``rcu_node``结构的``->lock``并更新该结构的``->qsmaskinitnext``。RCU宽限期内核线程采样此掩码以检测自宽限期开始以来已离线的CPU。
将此集成到完整的宽限期执行中详见下面的`强制静默状态`__部分。
强制静默状态
^^^^^^^^^^^^^^^^^^^^^^^^

如上所述，空闲和离线的CPU不能报告自己的静默状态，因此宽限期内的内核线程必须代表它们报告。这一过程被称为“强制静默状态”，每隔几秒重复一次，其顺序效果如下所示：

.. kernel-figure:: TreeRCU-gp-fqs.svg

每次静默状态的强制都会保证遍历叶节点``rcu_node``结构，如果没有新的静默状态（由于最近空闲或离线的CPU），则只遍历叶子节点。
然而，如果有新离线的CPU（如图左侧所示）或新空闲的CPU（如图右侧所示），相应的静默状态将被驱动至根节点。与自报告的静默状态类似，向上驱动在到达具有其他CPU未完成静默状态的``rcu_node``结构时停止。
```
+-----------------------------------------------------------------------+
| **快速测验**：                                                       |
+-----------------------------------------------------------------------+
| 最左边的驱动在到达根结构之前停止了，这意味着仍然有从属于该结构的CPU正在等待当前的宽限期。那么，最右边的驱动是如何结束这个宽限期的呢？|
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 分析得很好！在RCU没有bug的情况下，这实际上是不可能的。但这个图已经足够复杂了，因此为了简化而牺牲了一点准确性。你可以认为这是艺术许可，也可以认为这是一种在`拼接图`__中得以解决的误导。
+-----------------------------------------------------------------------+

宽限期清理
^^^^^^^^^^^^^^^^^^^^

宽限期清理首先以广度优先的方式扫描``rcu_node``树，并推进所有``->gp_seq``字段，然后推进``rcu_state``结构中的``->gp_seq``字段。其顺序效应如下所示：

.. kernel-figure:: TreeRCU-gp-cleanup.svg

如图底部的椭圆所示，一旦宽限期清理完成，下一个宽限期就可以开始。
+-----------------------------------------------------------------------+
| **快速测验**：                                                       |
+-----------------------------------------------------------------------+
| 宽限期到底是在何时精确结束的？
+-----------------------------------------------------------------------+
| **答案**：                                                           |
+-----------------------------------------------------------------------+
| 并没有一个有用的单一时间点可以用来表示宽限期结束。最早的合理候选时间是在最后一个CPU报告其静止状态之后，但RCU可能需要几毫秒才能意识到这一点。最晚的合理候选时间是在``rcu_state``结构中的``->gp_seq``字段更新之后，但此时一些CPU可能已经完成了其更新的第二阶段。简而言之，如果你打算与RCU一起工作，你需要学会接受不确定性。
+-----------------------------------------------------------------------+

回调函数调用
^^^^^^^^^^^^^^^

一旦某个CPU的叶``rcu_node``结构中的``->gp_seq``字段被更新，该CPU就可以开始调用那些等待当前宽限期结束的RCU回调函数。这些回调函数由``rcu_advance_cbs()``识别，通常由``__note_gp_changes()``调用。如图所示，这种调用可以由调度时钟中断（左侧的``rcu_sched_clock_irq()``）或空闲进入（右侧的``rcu_cleanup_after_idle()``，但仅限于使用``CONFIG_RCU_FAST_NO_HZ=y``构建的内核）触发。无论如何，都会引发``RCU_SOFTIRQ``，从而导致``rcu_do_batch()``调用这些回调函数，进而使这些回调函数执行每个更新所需的第二阶段处理（直接或通过唤醒间接进行）
.. kernel-figure:: TreeRCU-callback-invocation.svg

请注意，回调函数调用也可能由许多特殊情况下的代码路径触发，例如，当某个CPU注意到它有大量的回调函数排队时。在所有情况下，CPU在调用回调函数之前会获取其叶``rcu_node``结构的``->lock``，这保持了对新完成的宽限期所需的顺序。然而，如果回调函数与其他CPU通信，例如，进行唤醒，则该函数负责维护顺序。例如，如果回调函数唤醒了一个在其他CPU上运行的任务，则回调函数和被唤醒的任务都必须具备正确的顺序。要了解为什么这一点很重要，请考虑“宽限期清理”图的上半部分。回调函数可能在一个对应于最左边叶``rcu_node``结构的CPU上运行，并唤醒一个将在对应于最右边叶``rcu_node``结构的CPU上运行的任务，而宽限期的内核线程可能尚未到达最右边的叶。在这种情况下，宽限期的内存顺序可能尚未到达那个CPU，因此再次回调函数和被唤醒的任务必须提供正确的顺序。
将一切结合起来
~~~~~~~~~~~~~~~~~~~~~~~

拼接在一起的图如下：

.. kernel-figure:: TreeRCU-gp.svg

法律声明
~~~~~~~~~~~~~~~

本作品代表作者的观点，并不一定代表IBM的观点。
Linux是Linus Torvalds的注册商标。
其他公司、产品和服务名称可能是他人的商标或服务标志。
