SPDX 许可证标识符: GPL-2.0

#########
UML 使用指南
#########

.. contents:: :local:

************
介绍
************

欢迎使用 User Mode Linux

User Mode Linux 是首个开源虚拟化平台（首次发布日期为 1991 年），也是第二个用于 x86 PC 的虚拟化平台。

UML 与使用虚拟化包 X 的虚拟机有何不同？
==============================================================

我们已经习惯认为虚拟化意味着某种程度的硬件仿真。事实上，这并不是必须的。只要虚拟化包提供的设备能够被操作系统识别并且有相应的驱动程序支持，这些设备并不需要模拟真实的硬件。如今大多数操作系统都内置了对多种仅在虚拟化环境下使用的“假”设备的支持。

User Mode Linux 将这一概念推向了极致——没有任何一个真实设备。它是 100% 人工构建的，或者用更准确的术语来说，是 100% 半虚拟化的。所有 UML 设备都是抽象的概念，它们映射到主机提供的某些东西上，如文件、套接字、管道等。

UML 与其他各种虚拟化包的另一个主要区别在于 UML 内核和 UML 程序的操作方式存在明显的差异。

UML 内核只是运行在 Linux 上的一个进程，就像任何其他程序一样。它可以由非特权用户运行，并且不需要任何特殊的 CPU 特性。

然而，UML 用户空间则有所不同。主机上的 Linux 内核会帮助 UML 拦截 UML 实例中运行的程序试图执行的所有操作，并让 UML 内核处理所有的请求。

这一点不同于其他虚拟化包，后者不会区分来宾内核和来宾程序。这种区别导致了 UML 相对于 QEMU 等其他虚拟化包的一些优势和劣势，我们将在本文档稍后部分详细讨论。

为什么我会想要使用 User Mode Linux？
=================================

* 如果 User Mode Linux 内核崩溃，你的主机内核仍然完好无损。它没有以任何方式加速（例如 vhost、KVM 等），也没有尝试直接访问任何设备。实际上，它只是一个普通的进程。
* 你可以作为非 root 用户运行用户模式内核（你可能需要为某些设备设置适当的权限）。
为什么运行UML
===============

* 您可以为特定任务运行一个非常小的虚拟机（例如32M或更少）。
* 对于任何“内核特定任务”（如转发、防火墙等），您可以获得极高的性能，同时仍然与主机内核隔离。
* 您可以在不破坏任何东西的情况下尝试内核概念。
* 您不受“模拟”硬件的限制，因此可以尝试一些在模拟真实硬件时很难支持的奇特概念，例如时间旅行和使系统时钟依赖于UML的行为（对于测试等用途非常有用）。
* 这很有趣。

为什么不运行UML
=================

* UML所使用的系统调用拦截技术使其对任何用户空间应用程序来说本质上较慢。虽然它可以像大多数其他虚拟化包一样处理内核任务，但其用户空间**慢**。根本原因是UML创建新进程和线程的成本非常高（这是大多数Unix/Linux应用程序理所当然的事情）。
* 目前UML严格单处理器。如果您想运行一个需要多个CPU才能正常工作的应用程序，显然这不是正确的选择。

构建一个UML实例
================

没有任何发行版中有UML安装程序。尽管您可以使用现成的安装介质通过虚拟化包安装到空白虚拟机中，但没有UML的等效方式。您必须使用主机上的适当工具来构建一个可行的文件系统镜像。
在Debian上这非常容易——您可以使用debootstrap来完成。在OpenWRT上也很容易——构建过程可以构建UML镜像。所有其他发行版——效果可能因人而异。

创建一个镜像
=============

创建一个稀疏的原始磁盘镜像::

   # dd if=/dev/zero of=disk_image_name bs=1 count=1 seek=16G

这将创建一个16G的磁盘镜像。操作系统最初只会分配一个块，并且会在UML写入更多数据时分配更多块。截至内核版本4.19，UML完全支持TRIM（通常用于闪存驱动器）。
在UML（User Mode Linux）镜像中使用TRIM功能，可以通过指定`discard`作为挂载选项或运行`tune2fs -o discard /dev/ubdXX`来请求UML将未使用的块返回给操作系统。

创建文件系统并挂载它：

```sh
# mkfs.ext4 ./disk_image_name && mount ./disk_image_name /mnt
```

这个示例使用了ext4文件系统，其他如ext3、btrfs、xfs、jfs等文件系统也可以。

在已挂载的文件系统上创建一个最小的操作系统安装：

```sh
# debootstrap buster /mnt http://deb.debian.org/debian
```

`debootstrap` 不会设置root密码、fstab、主机名或任何与网络相关的配置。这些需要用户自行完成。

设置root密码——最简单的方法是通过chroot进入挂载的镜像：

```sh
# chroot /mnt
# passwd
# exit
```

编辑关键系统文件
==================

UML块设备称为ubds。`debootstrap` 创建的fstab默认为空，需要为根文件系统添加一条记录：

```
/dev/ubd0   ext4    discard,errors=remount-ro  0       1
```

镜像的主机名将被设置为主机名。为了避免误操作重启错误的机器，建议更改主机名。

UML支持两种类型的网络设备：较旧的uml_net设备（计划淘汰），这些设备被称为ethX；以及较新的向量IO设备，这些设备显著更快，并支持一些标准虚拟网络封装，如Ethernet over GRE和Ethernet over L2TPv3。这些设备被称为vec0。

根据所使用的设备类型，`/etc/network/interfaces` 需要包含相应的条目：

```sh
# 传统的UML网络设备
auto eth0
iface eth0 inet dhcp

# 向量UML网络设备
auto vec0
iface vec0 inet dhcp
```

现在我们有了一个几乎可以运行的UML镜像，只需要一个UML内核及其模块即可。
大多数发行版都有UML包。即使你打算使用自己的内核，用默认内核测试镜像也是一个好的开始。这些包包含了一组模块，需要复制到目标文件系统中。具体位置取决于发行版。对于Debian，这些模块位于`/usr/lib/uml/modules`下。递归复制此目录的内容到挂载的UML文件系统中：

```sh
# cp -rax /usr/lib/uml/modules /mnt/lib/modules
```

如果你编译了自己的内核，需要按照通常的“安装模块到指定位置”的过程进行：

```sh
# make INSTALL_MOD_PATH=/mnt/lib/modules modules_install
```

这将会把模块安装到`/mnt/lib/modules/$(KERNELRELEASE)`。

为了指定完整的模块安装路径，使用：

```sh
# make MODLIB=/mnt/lib/modules modules_install
```

此时镜像已经准备好启动。

*************************
设置UML网络
*************************

UML网络设计用于模拟以太网连接。这种连接可以是点对点（类似于使用直连电缆连接的机器之间）或连接到交换机。UML支持多种方式构建这些连接，包括本地机器、远程机器、本地和远程UML以及其他虚拟机实例。

+-----------+--------+------------------------------------+------------+
| 运输方式  | 类型   | 功能                              | 吞吐量     |
+===========+========+====================================+============+
| tap       | 向量   | 校验和、tso                        | > 8Gbit    |
+-----------+--------+------------------------------------+------------+
| hybrid    | 向量   | 校验和、tso、多包接收              | > 6GBit    |
+-----------+--------+------------------------------------+------------+
| raw       | 向量   | 校验和、tso、多包接收、传输        | > 6GBit    |
+-----------+--------+------------------------------------+------------+
| EoGRE     | 向量   | 多包接收、传输                     | > 3Gbit    |
+-----------+--------+------------------------------------+------------+
| Eol2tpv3  | 向量   | 多包接收、传输                     | > 3Gbit    |
+-----------+--------+------------------------------------+------------+
| bess      | 向量   | 多包接收、传输                     | > 3Gbit    |
+-----------+--------+------------------------------------+------------+
| fd        | 向量   | 取决于fd类型                       | 变化       |
+-----------+--------+------------------------------------+------------+
| tuntap    | 传统   | 无                                 | ~ 500Mbit  |
+-----------+--------+------------------------------------+------------+
| daemon    | 传统   | 无                                 | ~ 450Mbit  |
+-----------+--------+------------------------------------+------------+
| socket    | 传统   | 无                                 | ~ 450Mbit  |
+-----------+--------+------------------------------------+------------+
| pcap      | 传统   | 仅接收                             | ~ 450Mbit  |
+-----------+--------+------------------------------------+------------+
| ethertap  | 传统   | 过时                               | ~ 500Mbit  |
+-----------+--------+------------------------------------+------------+
| vde       | 传统   | 过时                               | ~ 500Mbit  |
+-----------+--------+------------------------------------+------------+

* 所有支持tso和校验和卸载的运输方式都可以在TCP流中提供接近10G的速度。
* 所有支持多包接收和/或发送的传输方式都可以提供最高达1Mpps或更高的pps速率
* 所有传统传输方式通常限制在约600-700Mbit/s和0.05Mpps
* GRE和L2TPv3允许连接到本地机器、远程机器、远程网络设备和远程UML实例
* Socket仅允许UML实例之间的连接
* Daemon和bess需要运行一个本地交换机。这个交换机也可以连接到主机

网络配置权限
=============

大多数支持的网络模式需要`root`权限
例如，在传统的tuntap网络模式中，用户需要成为与隧道设备关联的组的一部分
对于较新的网络驱动（如vector传输），需要`root`权限来执行ioctl以设置tun接口和/或在需要时使用原始套接字
这可以通过授予用户特定的能力而不是以root身份运行UML来实现。在vector传输的情况下，用户可以向uml二进制文件添加`CAP_NET_ADMIN`或`CAP_NET_RAW`能力
此后，UML可以以普通用户权限运行，并且具有完整的网络功能
例如：

   # sudo setcap cap_net_raw,cap_net_admin+ep linux

配置向量传输
===============================

所有向量传输都支持类似的语法：

如果 X 是接口编号，如 vec0、vec1、vec2 等，选项的一般语法如下：

   vecX:transport="Transport Name",option=value,option=value,...,option=value

通用选项
--------------

这些选项适用于所有传输方式：

* ``depth=int`` - 设置向量 I/O 的队列深度。这是 UML 在单次系统调用中尝试读取或写入的数据包数量。默认值为 64，对于大多数需要 2-4 Gbit 吞吐量的应用程序来说通常是足够的。更高的速度可能需要更大的值。
* ``mac=XX:XX:XX:XX:XX`` - 设置接口的 MAC 地址值。
* ``gro=[0,1]`` - 设置 GRO 关闭或开启。启用接收/发送卸载。此选项的效果取决于所配置传输方式在主机端的支持。在大多数情况下，它会启用 TCP 分段和 RX/TX 校验和卸载。主机端和 UML 端的设置必须相同。如果不同，UML 内核会产生警告。例如，默认情况下本地机器接口（如 veth 对、桥接等）启用了 GRO，因此为了使网络正常运行，在相应的 UML 传输（raw、tap、hybrid）中也应启用 GRO。
* ``mtu=int`` - 设置接口的 MTU。
* ``headroom=int`` - 调整默认的头部空间（32 字节），如果数据包需要重新封装到 VXLAN 中，则保留该头部空间。
* ``vec=0`` - 禁用多数据包 I/O，并回退到每次一个数据包的模式。

共享选项
--------------

* ``ifname=str`` - 绑定到本地网络接口的传输方式有一个共享选项 —— 绑定到的接口名称。
* ``src, dst, src_port, dst_port`` - 所有使用套接字并具有源地址和目标地址及/或源端口和目标端口概念的传输方式都使用这些选项来指定它们。
* ``v6=[0,1]`` - 用于指定是否希望为所有通过 IP 运行的传输方式建立 v6 连接。此外，对于那些在 v4 和 v6 上操作方式有所不同的传输方式（例如 EoL2TPv3），设置正确的操作模式。如果没有此选项，则根据 src 和 dst 参数解析的结果来确定套接字类型。
### tap 运输方式

示例：

```
vecX:transport=tap,ifname=tap0,depth=128,gro=1
```

这将把 vec0 连接到主机上的 tap0。tap0 必须已经存在（例如使用 tunctl 创建）并且处于 UP 状态。
tap0 可以配置为点对点接口并分配一个 IP 地址，以便 UML 能够与主机通信。或者，可以将 UML 连接到一个连接到网桥的 tap 接口。
尽管 tap 依赖于向量基础设施，但它目前并不是一个真正的向量传输方式，因为 Linux 不支持在普通用户空间应用程序（如 UML）中的 tap 文件描述符上进行多包 IO。这是一种仅提供给能够通过专用接口（如 vhost-net）在内核级别与其连接的特权。
计划在未来某个时候为 UML 提供一个类似 vhost-net 的辅助工具。
所需权限：tap 运输方式需要以下条件之一：

* tap 接口必须存在，并且使用 tunctl 持久化创建且由 UML 用户拥有。示例：`tunctl -u uml-user -t tap0`

* 二进制文件需要具有 `CAP_NET_ADMIN` 权限。

### 混合运输方式

示例：

```
vecX:transport=hybrid,ifname=tap0,depth=128,gro=1
```

这是一种实验性/演示性的运输方式，结合了 tap 发送和原始套接字接收。原始套接字允许多包接收，从而显著提高数据包速率。
所需权限：混合运输方式需要 UML 用户具有 `CAP_NET_RAW` 权限以及 tap 运输方式的要求。

### 原始套接字运输方式

示例：

```
vecX:transport=raw,ifname=p-veth0,depth=128,gro=1
```

这种运输方式使用原始套接字上的向量 IO。虽然您可以绑定到任何接口，包括物理接口，但最常见的用途是绑定到一对 veth 中的“对端”，而另一端则配置在主机上。
Debian 主机配置示例：

**/etc/network/interfaces**：

```
auto veth0
iface veth0 inet static
    address 192.168.4.1
    netmask 255.255.255.252
    broadcast 192.168.4.3
    pre-up ip link add veth0 type veth peer name p-veth0 && \
          ifconfig p-veth0 up
```

现在 UML 可以这样绑定到 p-veth0：

```
vec0:transport=raw,ifname=p-veth0,depth=128,gro=1
```

如果 UML 客户端配置了 192.168.4.2 和子网掩码 255.255.255.0，则它可以通过 192.168.4.1 与主机通信。
原始运输方式还提供了一些卸载过滤到主机的支持。控制它的两个选项是：

* `bpffile=str`：要加载为套接字过滤器的原始 BPF 代码的文件名

* `bpfflash=int`：0/1 允许从 User Mode Linux 内部加载 BPF
此选项允许使用 ethtool 加载固件命令来加载 BPF 代码
无论哪种情况，BPF 代码都会加载到主机内核中。虽然目前仅限于传统的 BPF 语法（不是 eBPF），但这仍然是一个安全风险。除非认为 User Mode Linux 实例是可信的，否则不建议启用此功能。
所需权限：原始套接字运输方式需要 `CAP_NET_RAW` 权限。
### GRE Socket 传输

示例：

```plaintext
vecX:transport=gre,src=$src_host,dst=$dst_host
```

这将配置一个通过 `GRE`（又名 `GRETAP` 或 `GREIRB`）隧道的以太网连接，该隧道将 UML 实例连接到目标主机 `dst_host` 上的 `GRE` 终端。`GRE` 支持以下附加选项：

* `rx_key=int` - 接收数据包的 `GRE` 32 位整数密钥，如果设置，则 `tx_key` 也必须设置。
* `tx_key=int` - 发送数据包的 `GRE` 32 位整数密钥，如果设置，则 `rx_key` 也必须设置。
* `sequence=[0,1]` - 启用 `GRE` 序列号。
* `pin_sequence=[0,1]` - 假装每个数据包的序列号总是重置（与某些有缺陷的实现兼容所需）。
* `v6=[0,1]` - 分别强制使用 IPv4 或 IPv6 套接字。
* 目前不支持 `GRE` 校验和。

`GRE` 存在一些注意事项：
- 每个 IP 地址只能使用一个 `GRE` 连接。无法复用连接，因为每个 `GRE` 隧道直接终止于 UML 实例上。
- 密钥并不是真正的安全特性。虽然最初设计时是作为安全措施，但其“安全性”非常可笑。然而，它是一个有用的特性，可以确保隧道没有被错误配置。

例如，对于本地地址为 192.168.128.1 的 Linux 主机，连接到位于 192.168.129.1 的 UML 实例：

**/etc/network/interfaces**:

```plaintext
auto gt0
iface gt0 inet static
 address 10.0.0.1
 netmask 255.255.255.0
 broadcast 10.0.0.255
 mtu 1500
 pre-up ip link add gt0 type gretap local 192.168.128.1 \
        remote 192.168.129.1 || true
 down ip link del gt0 || true
```

此外，`GRE` 已经在各种网络设备上进行了测试。
所需权限：`GRE` 需要 `CAP_NET_RAW` 权限。

### L2TPv3 Socket 传输

**警告**。L2TPv3 有一个“bug”。这个“bug”被称为“比 GNU ls 更多的选项”。尽管它有一些优点，但通常有更简单（且不那么冗长）的方法来连接 UML 实例。例如，大多数支持 L2TPv3 的设备也支持 GRE。

示例：

```plaintext
vec0:transport=l2tpv3,udp=1,src=$src_host,dst=$dst_host,srcport=$src_port,dstport=$dst_port,depth=128,rx_session=0xffffffff,tx_session=0xffff
```

这将配置一个通过 L2TPv3 固定隧道的以太网连接，该隧道将 UML 实例连接到目标主机 `$dst_host` 上的 L2TPv3 终端，使用 L2TPv3 UDP 方式和 UDP 目标端口 `$dst_port`。

L2TPv3 总是需要以下附加选项：
- `rx_session=int` - 接收数据包的 L2TPv3 32 位整数会话。
- `tx_session=int` - 发送数据包的 L2TPv3 32 位整数会话。

由于隧道是固定的，这些值不是协商的，而是在两端预先配置好的。

此外，L2TPv3 支持以下可选参数：
- `rx_cookie=int` - 接收数据包的 L2TPv3 32 位整数 Cookie —— 功能类似于 `GRE` 密钥，更多是为了防止错误配置而不是提供实际的安全性。
- `tx_cookie=int` - 发送数据包的 L2TPv3 32 位整数 Cookie。
- `cookie64=[0,1]` - 使用 64 位 Cookie 而不是 32 位。
- `counter=[0,1]` - 启用 L2TPv3 计数器。
- `pin_counter=[0,1]` - 假装计数器在每个数据包上总是重置（与某些有缺陷的实现兼容所需）。
- `v6=[0,1]` - 强制使用 IPv6 套接字。
- `udp=[0,1]` - 使用原始套接字（0）或 UDP 版本的协议（1）。

L2TPv3 存在一些注意事项：
- 在原始模式下，每个 IP 地址只能使用一个连接。无法复用连接，因为每个 L2TPv3 隧道直接终止于 UML 实例上。UDP 模式可以使用不同的端口来达到此目的。
以下是配置Linux主机以通过L2TPv3连接到UML的一个示例：

**/etc/network/interfaces**::

   auto l2tp1
   iface l2tp1 inet static
    address 192.168.126.1
    netmask 255.255.255.0
    broadcast 192.168.126.255
    mtu 1500
    pre-up ip l2tp add tunnel remote 127.0.0.1 \
           local 127.0.0.1 encap udp tunnel_id 2 \
           peer_tunnel_id 2 udp_sport 1706 udp_dport 1707 && \
           ip l2tp add session name l2tp1 tunnel_id 2 \
           session_id 0xffffffff peer_session_id 0xffffffff
    down ip l2tp del session tunnel_id 2 session_id 0xffffffff && \
           ip l2tp del tunnel tunnel_id 2

所需权限：L2TPv3在原始IP模式下需要`CAP_NET_RAW`权限，在UDP模式下不需要特殊权限。

### BESS套接字传输

BESS是一个高性能的模块化网络交换机，详情见：https://github.com/NetSys/bess

它支持一种简单的顺序数据包套接字模式，最近版本中使用向量I/O来提高性能。示例如下：

   vecX:transport=bess,src=$unix_src,dst=$unix_dst

这将配置一个使用`$unix_src`作为源地址和`$unix_dst`作为目的地址的BESS传输。有关BESS配置及如何分配一个BESS Unix域套接字端口，请参阅BESS文档：https://github.com/NetSys/bess/wiki/Built-In-Modules-and-Ports

BESS传输不需要任何特殊权限。

### 配置传统传输方式

传统传输方式现在被认为是过时的。请使用向量版本。

### 运行UML

本节假设已在主机上安装了来自发行版的用户模式Linux（User Mode Linux）软件包或自定义构建的内核。这些会向系统添加一个名为`linux`的可执行文件。这是UML内核，可以像其他任何可执行文件一样运行。

它可以接受大多数正常的Linux内核参数作为命令行参数。此外，为了执行一些有用的操作，还需要一些特定于UML的参数。
### 参数
#### 必需参数：
* ``mem=int[K,M,G]`` - 内存大小。默认以字节为单位，也接受 K、M 或 G 的后缀。
* ``ubdX[s,d,c,t]=`` 虚拟磁盘规范。虽然这不是严格意义上的必需项，但在几乎所有情况下都需要它来指定根文件系统。
  - 最简单的镜像规范是文件系统的镜像文件名称（使用 `Creating an image`_ 中描述的方法之一创建）。
  - UBD 设备支持写时复制（COW）。更改会保存在一个单独的文件中，该文件可以被丢弃，从而回滚到原始的干净镜像。如果需要 COW，则 UBD 镜像指定为：``cow_file,master_image``。
  - 示例：``ubd0=Filesystem.cow,Filesystem.img``
  - UBD 设备可以设置为使用同步 I/O。任何写操作都会立即刷新到磁盘。这通过在 ``ubdX`` 规格后面加上 ``s`` 来实现。
  - UBD 对指定为单个文件名的设备执行一些启发式检查，以确保未将 COW 文件指定为镜像。要关闭这些检查，使用 ``d`` 标志放在 ``ubdX`` 后面。
  - UBD 支持 TRIM —— 请求宿主操作系统回收镜像中的任何未使用的块。要关闭此功能，在 ``ubdX`` 后面指定 ``t`` 标志。
  - ``root=`` 根设备 —— 大多数情况下可能是 ``/dev/ubd0``（这是一个 Linux 文件系统镜像）。

#### 重要的可选参数：
如果 UML 作为 "linux" 运行且没有额外参数，它会尝试为镜像中配置的每个控制台启动一个 xterm（大多数 Linux 发行版最多有 6 个控制台）。每个控制台都在一个 xterm 中启动。这对于具有图形界面的宿主机来说非常方便。然而，如果将 UML 用作测试框架或在纯文本环境中运行，这种做法是错误的。
为了改变这种行为，我们需要指定一个替代的控制台，并将其连接到一个支持的“线路”通道。为此，我们需要映射一个控制台以使用不同于默认 xterm 的东西。
示例：将控制台 1 重定向到标准输入/输出：

   con1=fd:0,fd:1

UML 支持多种串行线路通道，其语法如下：

   conX=channel_type:options[,channel_type:options]

如果通道规范包含两个部分并由逗号分隔，第一个部分是输入，第二个部分是输出。
* 空通道 - 丢弃所有输入或输出。例如：``con=null`` 将默认将所有控制台设置为 null。
* 文件描述符（fd）通道 - 使用文件描述符编号进行输入/输出。例如：``con1=fd:0,fd:1``。
* 端口（port）通道 - 在 TCP 端口号上启动一个 Telnet 服务器。例如：``con1=port:4321``。主机必须有 `/usr/sbin/in.telnetd`（通常是 Telnetd 软件包的一部分），以及来自 UML 工具的端口助手（参见下面的 xterm 通道信息）。UML 在客户端连接之前不会启动。
* pty 和 pts 通道 - 使用系统 pty/pts。
* tty 通道 - 绑定到现有的系统 tty。例如：``con1=/dev/tty8`` 将使 UML 使用主机上的第 8 个控制台（通常未使用）。
* xterm 通道 - 这是默认设置 - 在此通道上启动一个 xterm 并将输入/输出定向到它。请注意，为了让 xterm 正常工作，主机必须安装 UML 发行版软件包。这个软件包通常包含端口助手和其他 UML 与 xterm 通信所需的工具。或者，这些工具需要从源代码编译和安装。适用于控制台的所有选项也适用于 UML 的串行线路，它们在 UML 内部表现为 ttyS。

启动 UML
========

现在我们可以运行 UML：
```
# linux mem=2048M umid=TEST \
ubd0=Filesystem.img \
vec0:transport=tap,ifname=tap0,depth=128,gro=1 \
root=/dev/ubda con=null con0=null,fd:2 con1=fd:0,fd:1
```

这将启动一个具有 `2048M RAM` 的实例，并尝试使用名为 `Filesystem.img` 的镜像文件作为根文件系统。它将通过 tap0 连接到主机。除了 `con1` 外，所有控制台都将被禁用，而 `con1` 将使用标准输入/输出，使其出现在启动时的同一终端中。

登录
======

如果你在生成镜像时没有设置密码，则需要关闭 UML 实例，挂载镜像，进入该镜像并设置密码，具体方法请参见“生成镜像”部分。如果密码已经设置，你可以直接登录。
UML 管理控制台
============================

除了使用常规系统管理工具从“内部”管理镜像之外，还可以通过 UML 管理控制台执行一些低级别的操作。UML 管理控制台是运行中的 UML 实例内核的一个低级接口，有点类似于 i386 的 SysRq 接口。由于 UML 下面有一个完整的操作系统，因此相比 SysRq 机制具有更大的灵活性。您可以通过 mconsole 接口执行以下操作：

* 获取内核版本
* 添加和移除设备
* 关机或重启机器
* 发送 SysRq 命令
* 暂停和恢复 UML
* 查看在 UML 内部运行的进程
* 查看 UML 内部的 `/proc` 状态

您需要 mconsole 客户端（uml_mconsole），这是 UML 工具包的一部分，在大多数 Linux 发行版中都有提供。您还需要在 UML 内核的“常规设置”下启用 `CONFIG_MCONSOLE`。当您启动 UML 时，您会看到类似以下的一行信息：

```
mconsole 初始化于 /home/jdike/.uml/umlNJ32yL/mconsole
```

如果您在 UML 命令行上指定了一个唯一的机器 ID，例如 `umid=debian`，那么您会看到：

```
mconsole 初始化于 /home/jdike/.uml/debian/mconsole
```

该文件是 uml_mconsole 用来与 UML 通信的套接字。您可以使用 umid 或完整路径作为参数来运行它：

```
# uml_mconsole debian
```

或者

```
# uml_mconsole /home/jdike/.uml/debian/mconsole
```

您将得到一个提示符，在该提示符下可以运行以下命令之一：

* version
* help
* halt
* reboot
* config
* remove
* sysrq
* help
* cad
* stop
* go
* proc
* stack

### version

此命令不需要任何参数。它打印 UML 版本：

```
(mconsole) version
OK Linux OpenWrt 4.14.106 #0 Tue Mar 19 08:19:41 2019 x86_64
```

这个命令有一些实际用途。它是一个简单的无操作命令，可用于检查 UML 是否正在运行。这也是向 UML 发送设备中断的一种方式。UML mconsole 在内部被视为一个 UML 设备。

### help

此命令不需要任何参数。它打印一个包含支持的 mconsole 命令的简短帮助屏幕。

### halt 和 reboot

这些命令不需要任何参数。它们立即关闭机器，不进行磁盘同步和用户空间的干净关机。因此，它们几乎相当于使机器崩溃：

```
(mconsole) halt
OK
```

### config

`config` 向虚拟机添加一个新的设备。大多数 UML 设备驱动程序都支持这一点。它需要一个参数，即要添加的设备，语法与内核命令行相同：

```
(mconsole) config ubd3=/home/jdike/incoming/roots/root_fs_debian22
```

### remove

`remove` 从系统中删除一个设备。其参数只是要删除的设备名称。该设备必须处于驱动程序认为必要的空闲状态。对于 ubd 驱动程序，被移除的块设备不能被挂载、交换或以其他方式打开；对于网络驱动程序，设备必须处于关闭状态：

```
(mconsole) remove ubd3
```

### sysrq

此命令需要一个参数，即单个字母。它调用通用内核的 SysRq 驱动程序，根据该参数执行相应的操作。请参阅您最喜欢的内核树中的 `Documentation/admin-guide/sysrq.rst` 来了解哪些字母有效以及它们的作用。

### cad

这会在运行的镜像中触发 `Ctrl-Alt-Del` 操作。具体会发生什么取决于 `init`, `systemd` 等。通常情况下，它会重启机器。

### stop

这会使 UML 进入一个循环读取 mconsole 请求，直到收到 `go` mconsole 命令。这是一个非常有用的调试/快照工具。

### go

此命令在 UML 被 `stop` 命令暂停后恢复。请注意，当 UML 恢复后，TCP 连接可能会超时，并且如果 UML 被暂停了很长时间，`crond` 可能会变得有点疯狂，运行所有之前未完成的任务。

### proc

此命令需要一个参数 —— `/proc` 中的一个文件名，该文件的内容将被打印到 mconsole 标准输出。

### stack

此命令需要一个参数 —— 一个进程的 PID。该进程的堆栈将被打印到标准输出。
高级UML主题
*******************

在虚拟机之间共享文件系统
============================================

不要尝试通过从同一个文件启动两个UML来共享文件系统。这相当于从共享磁盘启动两台物理机器，会导致文件系统损坏。
使用分层块设备
---------------------------

在两个虚拟机之间共享文件系统的方法是使用ubd块驱动程序的写时复制（COW）分层功能。任何更改过的块将存储在私有的COW文件中，而读取则来自任一设备——如果请求的块在私有设备中有效，则从私有设备读取；否则从共享设备读取。使用此方案，大部分未更改的数据可以在任意数量的虚拟机之间共享，每台虚拟机都有一个较小的文件，包含其所做的更改。当大量UML从较大的根文件系统启动时，这将大大节省磁盘空间。
共享文件系统数据还将有助于性能提升，因为主机能够使用更少的内存缓存共享数据，因此UML的磁盘请求将从主机的内存而不是磁盘中服务。在多插槽NUMA机器上执行此操作有一个重要警告。在这种硬件上，运行许多具有共享主镜像和COW更改的UML实例可能会导致由于过多的插槽间通信而导致的NMI问题。
如果你在高端硬件上运行UML，请确保使用`taskset`命令将UML绑定到同一插槽上的逻辑CPU集，或者参阅“调整”部分。
要向现有的块设备文件添加写时复制层，只需将COW文件名添加到相应的ubd开关中：

   `ubd0=root_fs_cow,root_fs_debian_22`

其中`root_fs_cow`是私有的COW文件，而`root_fs_debian_22`是现有的共享文件系统。COW文件不一定需要存在。如果不存在，驱动程序会创建并初始化它。
磁盘使用情况
----------

UML支持TRIM功能，可以将其磁盘映像文件中的任何未使用空间释放给底层操作系统。重要的是使用`ls -ls`或`du`来验证实际文件大小。
COW有效性
-------------

对主镜像的任何更改都会使所有COW文件无效。如果发生这种情况，UML不会自动删除任何COW文件，并且拒绝启动。在这种情况下，唯一的解决方法是恢复旧镜像（包括其最后修改时间戳），或者删除所有COW文件，这将导致它们被重新创建。COW文件中的任何更改都将丢失。
COW可以合并 —— `uml_moo`：将COW文件与其基础文件合并
-----------------------------------------------------------------

根据你如何使用UML和COW设备，可能建议偶尔将COW文件中的更改合并到基础文件中。
执行此操作的工具是`uml_moo`。其用法如下：

```
uml_moo COW_file new_backing_file
```

无需指定后端文件，因为这些信息已经包含在COW文件的头部中。如果你非常谨慎，可以启动新的合并文件，并且如果你满意的话，将其替换旧的后端文件。
`uml_moo`默认情况下会创建一个新的后端文件作为安全措施。
它还有一个破坏性合并选项，可以直接将COW文件合并到当前的后端文件中。这实际上只在后端文件仅关联一个COW文件时有用。如果有多个COW文件与后端文件相关联，则其中一个的-d合并会使得其他所有COW文件失效。然而，在磁盘空间不足的情况下这是很方便的，并且通常比非破坏性合并更快。

`uml_moo`随UML发行包一起安装，并作为UML工具的一部分提供。

主机文件访问
===============

如果你想从UML内部访问主机上的文件，你可以将其视为另一台机器，并通过NFS挂载主机目录或将文件通过scp复制到虚拟机中。
然而，由于UML运行在主机上，它可以像其他任何进程一样访问这些文件，并使其在虚拟机内可用而无需使用网络。
这是通过`hostfs`虚拟文件系统实现的。通过它，你可以将主机目录挂载到UML文件系统中，并像在主机上那样访问其中的文件。

**安全警告**

没有任何参数的`hostfs`将允许镜像挂载主机文件系统的任何部分并对其进行写入。如果运行UML，请始终将`hostfs`限制在一个特定的“无害”目录（例如`/var/tmp`）中。如果UML以root身份运行，这一点尤为重要。

使用`hostfs`
-------------

首先，确保虚拟机内有`hostfs`可用，方法是：

```
# cat /proc/filesystems
```

`hostfs`应该被列出。如果没有，请重新编译内核并配置`hostfs`，或者确保`hostfs`作为一个模块被构建并在虚拟机内可用，并使用`insmod`加载它。

现在你只需要运行`mount`命令：

```
# mount none /mnt/host -t hostfs
```

这将会把主机的`/`挂载到虚拟机的`/mnt/host`目录下。
如果你不想挂载主机的根目录，你可以使用 `-o` 开关指定一个子目录来挂载：

   # mount none /mnt/home -t hostfs -o /home

这将会把主机上的 `/home` 挂载到虚拟机的 `/mnt/home`。

将 `hostfs` 作为根文件系统
-----------------------------

可以使用 `hostfs` 从主机上的目录层次结构启动，而不是使用文件中的标准文件系统。首先，你需要这个目录层次结构。最简单的方法是循环挂载现有的 `root_fs` 文件：

   # mount root_fs uml_root_dir -o loop

你需要在 `etc/fstab` 中将 `"/"` 的文件系统类型更改为 `hostfs`，因此该行应如下所示：

   /dev/ubd/0       /        hostfs      defaults          1   1

然后需要将该目录中所有属于 root 的文件的所有者更改为你自己。对我来说这样做有效：

   # find . -uid 0 -exec chown jdike {} \;

接下来，确保你的 UML 内核已经编译了 `hostfs`，而不是作为一个模块。然后运行 UML，并让引导设备指向那个目录：

   ubd0=/path/to/uml/root/directory

UML 应该像平常一样启动。
`hostfs` 的注意事项
--------------------

`hostfs` 不支持跟踪主机文件系统（在 UML 外部）的变化。因此，如果一个文件在 UML 不知情的情况下被更改，UML 将不会知道这一点，并且它自己的内存缓存可能会损坏。虽然可以修复这个问题，但目前还没有人在这方面进行工作。

调整 UML
===========

目前 UML 严格来说是单处理器的。然而，它会生成多个线程来处理各种功能。UBD 驱动、SIGIO 和 MMU 模拟都会这样做。如果系统处于空闲状态，这些线程会被迁移到 SMP 主机上的其他处理器上。不幸的是，这通常会导致性能降低，因为核心之间的缓存/内存同步通信。因此，UML 通常受益于被绑定在一个单一的 CPU 上，特别是在大型系统上。这可以在某些基准测试中导致高达五倍的性能差异。

同样，在大型多节点 NUMA 系统上，如果 UML 的所有内存都从其运行的同一个 NUMA 节点分配，那么 UML 将会受益。操作系统默认情况下不会这样做。为了做到这一点，系统管理员需要创建一个适合的绑定到特定节点的 tmpfs 内存盘，并通过在 TMP 或 TEMP 环境变量中指定它来用作 UML RAM 分配的来源。UML 会查看 `TMPDIR`、`TMP` 或 `TEMP` 的值。如果这些失败，它将查找挂载在 `/dev/shm` 下的 shmfs。如果一切方法都失败，则使用 `/tmp/`，无论其使用的文件系统类型是什么：

   mount -t tmpfs -ompol=bind:X none /mnt/tmpfs-nodeX
   TEMP=/mnt/tmpfs-nodeX taskset -cX linux options options options.

为 UML 做贡献和使用 UML 进行开发
*******************************************

UML 是一个极好的平台，用于开发新的 Linux 内核概念——文件系统、设备、虚拟化等。它提供了无与伦比的机会来创建和测试它们，而无需局限于模拟特定硬件。

例如，想尝试 Linux 如何与 4096 个“真正的”网络设备一起工作？

对于 UML 来说这不是问题。同时，这在其他虚拟化软件包中很难实现——它们受到试图模拟的硬件总线上允许设备数量的限制（例如，在 qemu 中 PCI 总线上的设备数量为 16）。
如果你有贡献，例如补丁、错误修复或新功能，请发送到 ``linux-um@lists.infradead.org``。
请遵循所有标准的Linux补丁指南，如抄送相关的维护者，并在你的补丁上运行 ``./scripts/checkpatch.pl``。
更多详情请参阅 ``Documentation/process/submitting-patches.rst``。

注意 —— 邮件列表不接受HTML格式或附件，所有邮件必须以纯文本格式发送。

开发总是伴随着调试。首先，你可以一直将UML运行在gdb下，并且稍后会有一整节介绍如何做到这一点。然而，这并不是调试Linux内核的唯一方法。通常情况下，添加追踪语句和/或使用UML特定的方法（如ptrace UML内核进程）会显著提供更多有用的信息。
追踪UML
==============

当运行时，UML由一个主内核线程和若干个辅助线程组成。对于追踪来说，感兴趣的线程不是已经被UML作为MMU模拟的一部分ptrace的那些线程。
这些通常是ps显示中前三个线程。
PID最低且占用CPU最多的通常是内核线程。其他线程是磁盘（ubd）设备辅助线程和SIGIO辅助线程。
对这个线程进行ptrace通常会产生如下画面：

```
host$ strace -p 16566
--- SIGIO {si_signo=SIGIO, si_code=POLL_IN, si_band=65} ---
epoll_wait(4, [{EPOLLIN, {u32=3721159424, u64=3721159424}}], 64, 0) = 1
epoll_wait(4, [], 64, 0)                = 0
rt_sigreturn({mask=[PIPE]})             = 16967
ptrace(PTRACE_GETREGS, 16967, NULL, 0xd5f34f38) = 0
ptrace(PTRACE_GETREGSET, 16967, NT_X86_XSTATE, [{iov_base=0xd5f35010, iov_len=832}]) = 0
ptrace(PTRACE_GETSIGINFO, 16967, NULL, {si_signo=SIGTRAP, si_code=0x85, si_pid=16967, si_uid=0}) = 0
ptrace(PTRACE_SETREGS, 16967, NULL, 0xd5f34f38) = 0
ptrace(PTRACE_SETREGSET, 16967, NT_X86_XSTATE, [{iov_base=0xd5f35010, iov_len=2696}]) = 0
ptrace(PTRACE_SYSEMU, 16967, NULL, 0)   = 0
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_TRAPPED, si_pid=16967, si_uid=0, si_status=SIGTRAP, si_utime=65, si_stime=89} ---
wait4(16967, [{WIFSTOPPED(s) && WSTOPSIG(s) == SIGTRAP | 0x80}], WSTOPPED|__WALL, NULL) = 16967
ptrace(PTRACE_GETREGS, 16967, NULL, 0xd5f34f38) = 0
ptrace(PTRACE_GETREGSET, 16967, NT_X86_XSTATE, [{iov_base=0xd5f35010, iov_len=832}]) = 0
ptrace(PTRACE_GETSIGINFO, 16967, NULL, {si_signo=SIGTRAP, si_code=0x85, si_pid=16967, si_uid=0}) = 0
timer_settime(0, 0, {it_interval={tv_sec=0, tv_nsec=0}, it_value={tv_sec=0, tv_nsec=2830912}}, NULL) = 0
getpid()                                = 16566
clock_nanosleep(CLOCK_MONOTONIC, 0, {tv_sec=1, tv_nsec=0}, NULL) = ? ERESTART_RESTARTBLOCK (被信号中断)
--- SIGALRM {si_signo=SIGALRM, si_code=SI_TIMER, si_timerid=0, si_overrun=0, si_value={int=1631716592, ptr=0x614204f0}} ---
rt_sigreturn({mask=[PIPE]})             = -1 EINTR (被中断的系统调用)
```

这是大多数空闲状态下的UML实例的典型画面：
* UML中断控制器使用epoll——这是UML等待IO中断的情况：

  ```
  epoll_wait(4, [{EPOLLIN, {u32=3721159424, u64=3721159424}}], 64, 0) = 1
  ```

* ptrace调用序列是MMU模拟和运行UML用户空间的一部分。
* ``timer_settime`` 是UML高分辨率定时子系统的一部分，它将UML内部的定时请求映射到主机的高分辨率定时器上。
``clock_nanosleep`` 表示 UML 进入空闲状态（类似于 PC 执行 ACPI 空闲的方式）。
如你所见，即使在空闲状态下，UML 也会生成大量的输出。这些输出在观察 I/O 操作时非常有用，它显示了实际的 I/O 调用、参数和返回值。

### 内核调试

现在你可以将 UML 在 gdb 下运行，尽管它不一定会同意在 gdb 下启动。如果你试图追踪一个运行时错误，最好是将 gdb 附加到一个正在运行的 UML 实例上，并让 UML 继续运行。假设 PID 与前一个例子相同，可以这样做：

```sh
# gdb -p 16566
```

这会停止 UML 实例，因此你需要在 gdb 命令行中输入 `cont` 来请求继续运行。将此操作编写成一个 gdb 脚本并作为参数传递给 gdb 可能是个好主意。

### 开发设备驱动程序

几乎所有的 UML 驱动程序都是单体式的。虽然可以将 UML 驱动程序构建为内核模块，但这限制了其功能仅限于内核内部且不特定于 UML。原因是，为了充分利用 UML，需要编写一段用户空间代码，将驱动程序的概念映射到实际的用户空间主机调用上。

这部分被称为驱动程序的“用户”部分。虽然它可以重用很多内核概念，但通常只是一段普通的用户空间代码。这一部分需要一些匹配的“内核”代码，这些代码驻留在 UML 图像内部并实现 Linux 内核的部分功能。

*注意：在“内核”和“用户”之间交互方面几乎没有限制。*

UML 并没有严格定义的内核到主机的 API。它并不尝试模拟特定的架构或总线。UML 的“内核”和“用户”部分可以共享内存、代码，并根据需要进行交互以实现软件开发人员设想的设计。唯一的限制是技术上的。由于许多函数和变量具有相同的名称，开发人员应该小心选择要引用的头文件和库。

因此，许多用户空间代码由简单的包装器组成。例如，``os_close_file()`` 就是一个围绕 ``close()`` 的包装器，确保用户空间中的 ``close`` 函数不会与内核部分中的同名函数冲突。
使用UML作为测试平台
============================

UML是设备驱动开发的优秀测试平台。与大多数UML功能一样，“可能需要用户自行组装”。用户需要自己构建其仿真环境。目前，UML仅提供内核基础设施。这部分基础设施包括加载和解析在Arm或Open Firmware平台上使用的fdt设备树blob的能力。这些设备树blob可以通过向内核命令行添加一个可选参数来提供：

    dtb=filename

设备树在启动时被加载和解析，并且可以被查询它的驱动访问。目前，此功能仅用于开发目的。UML自身的设备不会查询设备树。

安全考虑
-----------------------

驱动程序或任何新功能默认不应接受来自UML实例内部可能影响主机的任意文件名、BPF代码或其他参数。
例如，在UML命令行上指定用于驱动程序与主机之间IPC通信的套接字在安全上是可以接受的。将其作为可加载模块的参数则不可接受。
如果特定应用需要此类功能（例如为原始套接字网络传输加载BPF“固件”），该功能应默认关闭，并且应在启动时通过命令行参数显式开启。
即使考虑到这一点，UML与主机之间的隔离级别相对较低。如果允许UML用户空间加载任意内核驱动，攻击者可以利用这一点突破UML的限制。因此，如果在生产环境中使用UML，建议所有模块在启动时加载，并在之后禁用内核模块加载。
