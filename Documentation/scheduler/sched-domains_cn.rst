调度域
===============

每个CPU都有一个“基础”调度域（struct sched_domain）。通过->parent指针，这些基础域构建了域的层次结构。->parent 必须以NULL终止，并且域结构应该按CPU分配，因为它们是无锁更新的。
每个调度域跨越多个CPU（存储在->span字段中）。
一个域的范围必须是其子域范围的超集（如果有必要，这一限制可以放宽），并且对于CPU i 的基础域必须至少包含 i。每个CPU的顶级域通常会覆盖系统中的所有CPU，尽管严格来说并不一定需要这样，但如果不这样做可能会导致某些CPU永远无法获得任务执行，除非明确设置了允许的CPU掩码。调度域的范围意味着“在这几个CPU之间平衡进程负载”。
每个调度域必须有一个或多个CPU组（struct sched_group），这些组通过->groups指针组织成一个单向循环链表。这些组的cpumask的并集必须与该域的范围相同。由->groups指针指向的组必须包含该域所属的CPU。组可以在多个CPU之间共享，因为设置完毕后它们包含只读数据。任意两个组的cpumask交集可能是非空的。如果出现这种情况，则相应的调度域将设置SD_OVERLAP标志，并且其组不能在CPU之间共享。
在一个调度域内的平衡发生在组之间。也就是说，每个组被视为一个实体。一个组的负载定义为其成员CPU负载的总和，只有当某个组的负载不平衡时，任务才会在组之间移动。
在kernel/sched/core.c中，通过sched_tick()周期性地在每个CPU上运行sched_balance_trigger()。在当前runqueue下一次定期重新平衡事件到达后，它会引发一个软中断。然后在软中断上下文（SCHED_SOFTIRQ）中运行实际的负载平衡函数sched_balance_softirq()->sched_balance_domains()。
此函数有两个参数：当前CPU的runqueue以及CPU在发生sched_tick()时是否处于空闲状态。它遍历我们的CPU所在的全部调度域，从其基础域开始，向上遍历->parent链。在这个过程中，它检查当前域是否已耗尽其重新平衡间隔。如果是，则在此域上调用sched_balance_rq()。然后继续检查父级调度域（如果存在），以及父级的父级等等。
最初，sched_balance_rq()会在当前调度域中找到最忙的组。
如果成功，它会查找该组中所有CPU的runqueue中最忙的那个。如果能够找到这样的runqueue，它将锁定我们初始CPU的runqueue和新找到的最忙的runqueue，并开始将任务从它移动到我们的runqueue。具体任务数量取决于在遍历此调度域的组时预先计算出的不平衡量。

实现调度域
==========================

“基础”域将“覆盖”层次结构的第一级。在SMT的情况下，你将覆盖物理CPU的所有兄弟节点，每个组是一个虚拟CPU。
在SMP（对称多处理）中，基础域的父域将覆盖节点中的所有物理CPU，每个组对应一个物理CPU。而在NUMA（非统一内存访问）架构中，SMP域的父域将覆盖整台机器，每个组包含一个节点的CPU掩码。或者，你可以实现多级NUMA或Opteron架构，例如，可能只有一个域覆盖其单一的NUMA级别。

开发者应该阅读`include/linux/sched/sd_flags.h`中的注释，特别是`SD_*`部分，以了解具体的细节和如何调整调度域（sched_domain）的SD标志。

不同的架构可以通过创建`sched_domain_topology_level`数组并调用`set_sched_topology()`函数来覆盖通用的域构建器和默认的SD标志，从而针对特定的拓扑层级进行自定义。

启用调度域调试基础设施的方法是开启`CONFIG_SCHED_DEBUG`配置，并在启动参数（cmdline）中添加`sched_verbose`。如果你忘记了调整启动参数，也可以通过修改`/sys/kernel/debug/sched/verbose`文件来开启调试功能。这会启用错误检查解析调度域的功能，能够捕捉大多数可能的错误（如上所述）。同时，它还会以可视化格式打印出域结构。
