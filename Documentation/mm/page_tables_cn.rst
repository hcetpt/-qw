SPDX 许可证标识符: GPL-2.0

===========
页表
===========

分页虚拟内存的概念最早出现在 1962 年的 Ferranti Atlas 计算机上，这是第一台具有分页虚拟内存的计算机。随着时间的推移，这一特性逐渐迁移到更新的计算机上，并成为所有类 Unix 系统的标准特性。1985 年，该特性被纳入 Intel 80386 中，而 Linux 1.0 就是在这颗 CPU 上开发的。

页表将 CPU 看到的虚拟地址映射为外部内存总线上看到的物理地址。Linux 定义了五级层次结构的页表。每个支持的架构的体系结构代码会根据硬件限制进行映射。

与虚拟地址对应的物理地址通常由底层物理页框引用。**页框号**（**pfn**）是物理地址（在外部内存总线上看到的）除以 `PAGE_SIZE` 的结果。

物理内存地址 0 对应的是 *pfn 0*，最高的 pfn 是 CPU 外部地址总线所能寻址的最后一个物理页。

以 4KB 的页粒度和 32 位地址范围为例，pfn 0 在地址 0x00000000，pfn 1 在地址 0x00001000，pfn 2 在 0x00002000，依此类推，直到 pfn 0xfffff 在 0xfffff000。如果使用 16KB 的页，则 pfn 分别位于 0x00004000、0x00008000 … 0xffffc000，pfn 范围从 0 到 0x3fffff。

如你所见，在 4KB 的页大小下，页基地址使用地址的第 12 至 31 位，因此这里的 `PAGE_SHIFT` 定义为 12，`PAGE_SIZE` 通常定义为 `PAGE_SHIFT` 的函数 `(1 << PAGE_SHIFT)`。

随着时间的推移，为了应对不断增长的内存大小，更深层的页表层次结构得到了发展。当 Linux 创建时，使用的是 4KB 的页以及一个名为 `swapper_pg_dir` 的单个页表，包含 1024 个条目，覆盖 4MB 的空间，这恰好与 Linus Torvalds 第一台计算机拥有 4MB 物理内存的事实相符。这个单个表中的条目被称为 *PTE*（页表项）。

软件页表层次结构反映了硬件页表已经变得层次化，这样做是为了节省页表内存并加快映射速度。

当然可以想象一个带有大量条目的单一线性页表，将整个内存分解为单个页。这样的页表会非常稀疏，因为虚拟内存的大部分通常是未使用的。通过使用层次化的页表，虚拟地址空间中的大空洞不会浪费宝贵的页表内存，因为在页表层次结构的较高层标记大块区域为未映射就足够了。

此外，在现代 CPU 上，高层页表项可以直接指向物理内存范围，从而允许在一个高层页表项中映射连续的几兆字节甚至吉字节的范围，简化虚拟内存到物理内存的映射：找到这样的大映射范围时，无需深入到层次结构的更深处。
页表层次结构现已发展为如下所示：

  +-----+
  | PGD |
  +-----+
     |
     |   +-----+
     +-->| P4D |
         +-----+
            |
            |   +-----+
            +-->| PUD |
                +-----+
                   |
                   |   +-----+
                   +-->| PMD |
                       +-----+
                          |
                          |   +-----+
                          +-->| PTE |
                              +-----+

页表层次结构中不同层级的符号具有以下含义，从底层开始解释：

- **pte**，`pte_t`，`pteval_t` = **页表项** —— 之前已经提到过
  *pte* 是一个由 `PTRS_PER_PTE` 个 `pteval_t` 类型元素组成的数组，每个元素映射虚拟内存中的一页到物理内存中的一页。
  架构定义了 `pteval_t` 的大小和内容。一个典型的例子是 `pteval_t` 是一个 32 位或 64 位值，其中高几位是一个 **pfn**（页框号），低几位是一些架构特定的位，例如内存保护。
  名字中的 **entry** 部分有点令人困惑，因为在 Linux 1.0 中这确实是指顶级页表中的单个页表项，但当引入两层页表时，它被改造成一个映射元素数组，因此 *pte* 实际上是最低级别的页 *表*，而不是页表 *项*。
- **pmd**，`pmd_t`，`pmdval_t` = **页中间目录**，位于 *pte* 之上的层级，包含 `PTRS_PER_PMD` 个指向 *pte* 的引用。
- **pud**，`pud_t`，`pudval_t` = **页上级目录** 在其他层级之后引入以处理四层页表。它可能是未使用的，或者如我们稍后讨论的那样被“折叠”。
- **p4d**，`p4d_t`，`p4dval_t` = **页第四级目录** 在引入 *pud* 之后为了处理五层页表而引入。这时很明显我们需要用数字来表示目录级别，并且不能再继续使用随意的名字了。这仅在实际有五层页表的系统中使用，否则会被“折叠”。
- **pgd**，`pgd_t`，`pgdval_t` = **页全局目录** —— 处理内核内存的 Linux 内核主页表仍然可以在 `swapper_pg_dir` 中找到，但系统中的每个用户空间进程也有自己的内存上下文，因此有自己的 *pgd*，位于 `struct mm_struct` 中，而 `struct mm_struct` 又被每个 `struct task_struct` 引用。因此任务拥有形式为 `struct mm_struct` 的内存上下文，而这个结构又有一个 `struct pgt_t *pgd` 指针指向相应的页全局目录。

再次强调：页表层次结构中的每一层都是一个 *指针数组*，因此 **pgd** 包含 `PTRS_PER_PGD` 个指向下一层的指针，**p4d** 包含 `PTRS_PER_P4D` 个指向 **pud** 项的指针，以此类推。每一层的指针数量由架构定义。

```
        PMD
  --> +-----+           PTE
      | ptr |-------> +-----+
      | ptr |-        | ptr |-------> PAGE
      | ptr | \       | ptr |
      | ptr |  \        ..
```
```
| ... |   \
  | ptr |    \         PTE
  +-----+     +----> +-----+
                          | ptr |-------> PAGE
                          | ptr |
                            ..
Page Table Folding
==================

如果架构没有使用所有的页表层级，这些层级可以被“折叠”，即跳过，并且所有对页表的操作将在编译时增强，以便在访问下一层级时直接跳过一层。
希望保持架构中立的页表处理代码（如虚拟内存管理器）需要编写为遍历当前的五个层级。这种风格也应被特定架构的代码所偏好，以便在未来发生变化时保持稳健性。

MMU、TLB 和页面错误
=========================

`内存管理单元 (MMU)` 是一个硬件组件，负责处理虚拟地址到物理地址的转换。它可能使用相对较小的硬件缓存，称为 `转换后备缓冲存储器 (TLBs)` 和 `页面行走缓存` 来加速这些转换。
当 CPU 访问一个内存位置时，它向 MMU 提供一个虚拟地址，MMU 检查 TLB 或页面行走缓存（支持的架构）中是否有现有的转换。如果没有找到转换，MMU 使用页面行走来确定物理地址并创建映射。
页面的脏位会在该页面被写入时设置（即打开）。每个内存页面都有相关的权限位和脏位。后者表明自该页面加载到内存以来已被修改。
如果没有任何阻止因素，最终可以访问物理内存，并执行请求的操作。
MMU 无法找到某些转换的原因有多种。这可能是因为 CPU 正在尝试访问当前任务无权访问的内存，或者因为数据尚未进入物理内存。
当这些条件发生时，MMU 触发页面错误，这是一种异常类型，指示 CPU 暂停当前执行并运行一个特殊函数来处理这些异常。
```
存在一些常见且预期的页面错误原因。这些页面错误是由称为“懒惰分配”（Lazy Allocation）和“写时复制”（Copy-on-Write）的过程管理优化技术触发的。当页面帧被交换到持久存储（交换分区或文件）并从其物理位置驱逐时，也会发生页面错误。

这些技术提高了内存效率，减少了延迟，并最小化了空间占用。本文档不会深入探讨“懒惰分配”和“写时复制”的细节，因为这些主题超出了范围，属于进程地址管理的范畴。

交换与其他提到的技术不同，因为它是在内存压力较大时作为减少内存的一种手段，这是不理想的。
交换不能用于映射内核逻辑地址的内存。这些是内核虚拟空间的一个子集，直接映射了一段连续的物理内存。给定任何逻辑地址，其物理地址可以通过简单的偏移算术确定。访问逻辑地址的速度很快，因为它们避免了复杂的页表查找，但代价是这些帧无法被驱逐或交换出去。

如果内核无法为必须存在于物理帧中的数据腾出空间，内核会调用“内存不足”（Out-Of-Memory, OOM）杀手来通过终止优先级较低的进程来腾出空间，直到压力降至安全阈值以下。

此外，页面错误也可能由代码错误或恶意构造的地址引起，CPU被指示访问这些地址。一个进程的线程可能会使用指令访问不属于其地址空间的（非共享）内存，或者尝试执行一条试图写入只读位置的指令。

如果上述情况发生在用户空间中，内核会向当前线程发送一个“分段错误”（SIGSEGV）信号。这个信号通常会导致该线程及其所属进程的终止。

本文档将简化并展示 Linux 内核如何处理这些页面错误、创建表及其条目、检查内存是否存在以及如果不存在则请求从持久存储或其他设备加载数据，并更新 MMU 及其缓存的高层次视图。

最初的步骤依赖于架构。大多数架构跳转到 `do_page_fault()`，而 x86 中断处理器由 `DEFINE_IDTENTRY_RAW_ERRORCODE()` 宏定义，该宏调用 `handle_page_fault()`。

无论路径如何，所有架构最终都会调用 `handle_mm_fault()`，后者（很可能）最终调用 `__handle_mm_fault()` 来实际完成分配页表的工作。
无法调用 `__handle_mm_fault()` 的不幸情况意味着虚拟地址指向了不允许访问的物理内存区域（至少从当前上下文来看）。这种情况下，内核会向进程发送上述提到的 SIGSEGV 信号，导致之前已经解释过的后果。

`__handle_mm_fault()` 通过调用多个函数来完成其工作，这些函数用于查找分层页表中的条目偏移，并分配可能需要的表。

查找偏移的函数命名规则为 `*_offset()`，其中 "*" 可以是 pgd、p4d、pud、pmd 和 pte；而逐层分配相应表的函数则命名为 `*_alloc`，遵循上述命名规则。

页表遍历可能在中间层或上层（如 PMD 或 PUD）结束。Linux 支持比通常的 4KB 更大的页面大小（即所谓的“大页”）。使用这些较大的页面时，更高层的页面可以直接映射它们，无需使用较低层的页表项（PTE）。大页包含较大的连续物理区域，通常范围从 2MB 到 1GB，并分别由 PMD 和 PUD 页表项映射。

大页带来许多好处，如减少 TLB 压力、减少页表开销、提高内存分配效率以及在某些工作负载下提升性能。然而，这些好处也伴随着一些权衡，例如浪费内存和分配挑战。

在完成带有分配的页表遍历后（如果没有返回错误），`__handle_mm_fault()` 最终会调用 `handle_pte_fault()`，该函数通过 `do_fault()` 执行 `do_read_fault()`、`do_cow_fault()` 或 `do_shared_fault()` 中的一个。“read”、“cow” 和 “shared” 这些名称提供了关于处理故障原因及其类型的线索。

实际的工作流程实现非常复杂。其设计允许 Linux 根据每种架构的具体特性处理页故障，同时保持一个共同的整体结构。

最后，在概述 Linux 如何处理页故障时，还需补充一点：可以通过 `pagefault_disable()` 和 `pagefault_enable()` 分别禁用和启用页故障处理器。
几条代码路径使用了后两个函数，因为它们需要禁用陷阱进入页面故障处理器，主要是为了防止死锁。
