SPDX 许可声明标识符：GPL-2.0

================================================
多队列块 I/O 调度机制（blk-mq）
================================================

多队列块 I/O 调度机制是一个 API，它使快速存储设备能够通过同时向块设备排队和提交 I/O 请求来实现每秒大量的输入/输出操作（IOPS），从而充分利用现代存储设备提供的并行性。
介绍
============

背景
----------

从内核开发之初，磁性硬盘一直是事实上的标准。块 I/O 子系统旨在为那些随机访问代价很高的设备实现最佳性能，而瓶颈在于机械部件，这些部件比存储堆栈中的任何一层都要慢得多。例如，一种优化技术涉及根据磁盘头的当前位置对读写请求进行排序。
然而，随着固态驱动器和非易失性内存的发展，它们没有机械部件、没有随机访问的代价，并且能够执行高并行访问，存储堆栈的瓶颈已经从存储设备转移到了操作系统上。为了利用这些设备设计中的并行性，引入了多队列机制。
早期的设计有一个单个队列用于存储块 I/O 请求，以及一个单一锁。这在对称多处理（SMP）系统中扩展不佳，因为缓存中的脏数据以及多个处理器只有一个锁的瓶颈。这种设置在不同的进程（或同一进程，在不同 CPU 上移动）想要执行块 I/O 时也会遇到拥堵问题。相反，blk-mq API 启动了多个队列，每个 CPU 都有自己的入口点，消除了对锁的需求。关于它是如何工作的更深入解释将在下面的操作部分中阐述。
操作
---------

当用户空间对块设备执行 I/O 操作（例如，读取或写入文件）时，blk-mq 将采取行动：它将存储和管理到块设备的 I/O 请求，作为用户空间（如果存在的话，还包括文件系统）与块设备驱动程序之间的中间件。
blk-mq 包含两种类型的队列：软件暂存队列和硬件分发队列。当请求到达块层时，它会尝试最短路径：直接发送到硬件队列。但是，有两种情况可能不会这样做：如果有 I/O 调度器连接在该层，或者我们想要尝试合并请求。在这两种情况下，请求将被发送到软件队列。
然后，在请求由软件队列处理后，它们将被放置在硬件队列中，这是一个第二阶段队列，硬件可以直接访问以处理这些请求。但是，如果硬件没有足够的资源来接受更多的请求，blk-mq 将把请求放在一个临时队列中，以便在未来硬件能够处理时再发送。
软件暂存队列
~~~~~~~~~~~~~~~~~~~~~~~

块 I/O 子系统将请求添加到软件暂存队列（由 struct blk_mq_ctx 表示）中，除非它们被直接发送给驱动程序。一个请求可以是一个或多个 BIO。它们通过数据结构 struct bio 到达块层。然后，块层将构建一个新的结构，即 struct request，用于与设备驱动程序通信。每个队列都有自己的锁，并且队列的数量由每个 CPU 或每个节点定义。
暂存队列可用于合并相邻扇区的请求。例如，对于扇区 3-6、6-7 和 7-9 的请求可以合并为一个 3-9 的请求。
即使对 SSD 和 NVM 的随机访问与顺序访问具有相同的响应时间，但分组顺序访问的请求可以减少单个请求的数量。这种合并请求的技术称为插桩。
与此相伴，请求可以被重新排序以确保系统资源的公平性（例如，确保没有应用程序因饥饿而受到影响）和/或通过I/O调度程序提高I/O性能。
**I/O 调度程序**
^^^^^^^^^^^^^^^^

块层实现了几种调度程序，每一种都遵循一定的启发式方法来改善I/O性能。它们是“可插拔”的（类似即插即用），也就是说可以在运行时使用sysfs进行选择。你可以在这里阅读更多关于Linux的I/O调度器的信息：`链接 <https://www.kernel.org/doc/html/latest/block/index.html>`_。调度只发生在同一队列中的请求之间，因此不可能合并不同队列中的请求，否则会导致缓存碎片以及每个队列都需要一个锁的问题。在调度之后，请求就有资格被发送到硬件上。可以选择的一种可能的调度程序是NONE调度程序，这是最直接的方法。它只是将请求放置在进程正在运行的软件队列上，不进行任何重新排序。当设备开始处理硬件队列（即运行硬件队列）中的请求时，映射到该硬件队列的软件队列将根据它们的映射顺序被清空。
**硬件分发队列**
~~~~~~~~~~~~~~~~~~~~

硬件队列（由struct blk_mq_hw_ctx表示）是由设备驱动程序用来映射设备提交队列（或设备DMA环形缓冲区）的结构体，并且是在低级别设备驱动程序接管请求之前块层提交代码的最后一步。要运行这个队列，块层从相关的软件队列中移除请求并尝试将其分发到硬件。如果无法直接将请求发送到硬件，它们将被添加到一个链表(``hctx->dispatch``)中。然后，在下一次块层运行队列时，它会首先发送位于``dispatch``列表中的请求，以确保与那些最先准备好的请求进行公平的分发。硬件队列的数量取决于硬件及其设备驱动程序支持的硬件上下文数量，但不会超过系统的内核数量。在这个阶段没有重新排序，并且每个软件队列都有一组硬件队列来发送请求。
.. note::
   块层和设备协议都不保证请求完成的顺序。这必须由更高级别的组件如文件系统来处理。
**基于标签的完成**
~~~~~~~~~~~~~~~~~~~~

为了指示哪些请求已完成，每个请求都被一个整数标识，范围从0到分发队列的大小。这个标签由块层生成，稍后被设备驱动程序重用，从而消除了创建冗余标识符的需要。当请求在驱动程序中完成时，其标签会被送回给块层以通知其完成情况。这样就无需进行线性搜索来找出哪些I/O操作已完成。
**进一步阅读**
------------------

- `Linux Block I/O: Introducing Multi-queue SSD Access on Multi-core Systems <http://kernel.dk/blk-mq.pdf>`_
- `NOOP调度程序 <https://en.wikipedia.org/wiki/Noop_scheduler>`_
- `空块设备驱动程序 <https://www.kernel.org/doc/html/latest/block/null_blk.html>`_

源代码文档
==================

.. kernel-doc:: include/linux/blk-mq.h

.. kernel-doc:: block/blk-mq.c
