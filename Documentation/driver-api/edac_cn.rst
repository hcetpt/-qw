错误检测与校正 (EDAC) 设备
=============================================

EDAC 子系统中的主要概念
----------------------------------------------

有一些术语并不直观，例如 *插槽*、*插槽组*、*存储库*、*行*、*芯片选择行*、*通道* 等等。这些是许多被广泛使用的术语，并不总是具有人们所认为的含义（不可思议！）。为了建立共同的讨论基础，下面将定义一些术语：
* 内存设备

内存条上的单个 DRAM 芯片。这些设备通常输出 4 位和 8 位数据（x4, x8）。通过并行组合多个这样的设备可以提供内存控制器所需的位数：通常是 72 位，以便提供 64 位数据加上 8 位 ECC 数据。
* 内存条

一个印刷电路板，它并行地集成多个内存设备。一般来说，这是在出现过多错误时需要更换的现场可更换单元 (FRU)。最常见的是被称为 DIMM（双列直插式内存模块）。
* 内存插槽

主板上的物理连接器，用于接受单个内存条。在一些数据表中也称为“插槽”。
* 通道

负责与一组 DIMM 进行通信的内存控制器通道。每个通道都有独立的控制（命令）和数据总线，可以独立使用或与其他通道组合使用。
* 分支

对于完全缓冲的 DIMM 内存控制器而言，这通常是最高层级的概念。通常包含两个通道。同一分支内的两个通道可以在单模式下或锁步模式下使用。当启用锁步模式时，缓存行会加倍，但通常会带来一定的性能损失。此外，在发生错误时通常无法只指向一个内存条，因为错误校正码是基于两个 DIMM 计算得出的，而不是一个。因此，它能够纠正比单模式更多的错误。
* 单通道

内存控制器访问的数据仅位于一个 DIMM 中。例如，如果数据宽度为 64 位，则数据以 64 位的并行方式流向 CPU。通常用于 SDR、DDR、DDR2 和 DDR3 内存。FB-DIMM 和 RAMBUS 使用不同的通道概念，因此这个概念不适用于它们。
* 双通道

内存控制器访问的数据交错分布在两个 DIMM 上，同时被访问。例如，如果 DIMM 的宽度为 64 位（含 ECC 为 72 位），则数据以 128 位的并行方式流向 CPU。
* 芯片选择行

这是 DRAM 信号名称，用于选择要访问的 DRAM 排列。单通道的常用芯片选择行宽度为 64 位，双通道为 128 位。内存控制器可能无法直接看到该信号，因为某些类型的 DIMM 具有内存缓冲器，它可以隐藏来自内存控制器的直接访问。
* 单排内存条

单排内存条具有1个芯片选择行的内存。主板通常会驱动两个芯片选择引脚到一个内存条上。对于单排内存条，它只会占用其中一个行，另一个则不会被使用。
* 双排内存条

双排内存条有两个芯片选择行，可以访问不同的内存设备组。这两个行不能同时被访问。
* 双面内存条

**已废弃术语**，请参见：双排内存条
双面内存条有两个芯片选择行，可以访问不同的内存设备组。这两个行不能同时被访问。“双面”与内存设备是否安装在内存条的两面无关。
* 插槽集

为了进行一次内存访问所必需的所有内存条，或者由一个芯片选择行覆盖的所有内存条。一个插槽集包含两个芯片选择行，如果使用的是双面内存条，则这些内存条将占据这两个芯片选择行。
* 银行

这个术语尽量避免使用，因为它在需要区分芯片选择行和插槽集时会产生混淆。
* 高带宽内存（HBM）

HBM是一种新型内存类型，功耗低且通信通道极宽。它使用垂直堆叠的内存芯片（DRAM芯片）通过称为“硅通孔”或TSV的微观导线互联。
多个HBM芯片堆栈通过一种名为“中介层”的超高速互联连接到CPU或GPU上。因此，HBM的特点几乎与片上集成RAM无法区分。
## 内存控制器

EDAC核心的大部分工作集中在内存控制器错误检测上。
`:c:func:`edac_mc_alloc`。它内部使用 `struct mem_ctl_info` 来描述内存控制器，对于 EDAC 驱动程序来说这是一个不透明的结构体。只有 EDAC 核心模块可以访问它。

.. kernel-doc:: include/linux/edac.h

.. kernel-doc:: drivers/edac/edac_mc.h

PCI 控制器
-----------

EDAC 子系统提供了一种处理 PCI 控制器的机制，通过调用 `:c:func:`edac_pci_alloc_ctl_info` 实现。它将使用 `:c:type:`edac_pci_ctl_info` 结构体来描述 PCI 控制器。

.. kernel-doc:: drivers/edac/edac_pci.h

EDAC 设备块
--------------

EDAC 子系统还提供了一个通用机制，用于通过 `:c:func:`edac_device_alloc_ctl_info` 函数报告硬件其他部分的错误。结构体 `:c:type:`edac_dev_sysfs_block_attribute`、`:c:type:`edac_device_block`、`:c:type:`edac_device_instance` 和 `:c:type:`edac_device_ctl_info` 在 sysfs 中提供了通用或抽象的“edac_device”表示。

这一组结构体以及实现相同 API 的代码，允许注册非标准内存或 PCI 类型的 EDAC 设备，例如：

- CPU 缓存（L1 和 L2）
- DMA 引擎
- 核心 CPU 开关
- 架构交换单元
- PCIe 接口控制器
- 其他可以监控错误的 EDAC/ECC 类型设备等

它允许具有两层层次结构。
例如，缓存可能由 L1、L2 和 L3 级别的缓存组成。
每个 CPU 内核都有自己的 L1 缓存，而共享 L2 和可能的 L3 缓存。在这种情况下，这些可以通过以下 sysfs 节点表示：

```
/sys/devices/system/edac/.
pci/		<现有 pci 目录（如果可用）>
mc/		<现有内存设备目录>
cpu/cpu0/..	<L1 和 L2 块目录>
		/L1-cache/ce_count
			 /ue_count
		/L2-cache/ce_count
			 /ue_count
cpu/cpu1/..	<L1 和 L2 块目录>
		/L1-cache/ce_count
			 /ue_count
		/L2-cache/ce_count
			 /ue_count
```

L1 和 L2 目录将是 “edac_device_block”的实例。

.. kernel-doc:: drivers/edac/edac_device.h

异构系统支持
----------------

AMD 异构系统是通过自定义 xGMI 链路将 CPU 和 GPU 的数据结构连接起来构建的。因此，GPU 节点上的数据结构可以像 CPU 节点上的数据结构一样被访问。
MI200加速器是数据中心GPU。它们拥有2种数据结构（fabric），每种GPU数据结构包含四个统一内存控制器(UMC)。
每个UMC包含八个通道。每个UMC通道控制一个128位的HBM2e（2GB）通道（相当于8个2GB的等级）。这形成了总共4096位的DRAM数据总线。
虽然UMC连接的是16GB（8高x 2GB DRAM）的HBM堆栈，但每个UMC通道连接的是2GB的DRAM（表示为等级）。
AMD GPU节点上的内存控制器可以用EDAC表示如下：

- GPU数据结构 / GPU节点 -> EDAC内存控制器(MC)
- GPU UMC -> EDAC芯片选择行(CSROW)
- GPU UMC通道 -> EDAC通道(CHANNEL)

例如：一个异构系统中，1个AMD CPU通过xGMI连接了4个MI200（Aldebaran）GPU。
一些额外的异构硬件细节如下：

- CPU的UMC（统一内存控制器）与GPU的UMC大致相同。
它们都有芯片选择（csrows）和通道。但是，为了性能、物理布局或其他原因，它们的布局不同。
- CPU UMC使用1个通道，在这种情况下，UMC=EDAC通道。这符合市场术语。CPU有X个内存通道等。
- CPU UMC最多使用4个芯片选择，因此UMC芯片选择=EDAC CSROW。
- GPU UMC使用1个芯片选择，因此UMC=EDAC CSROW。
- GPU UMC使用8个通道，因此UMC通道=EDAC通道。
EDAC 子系统提供了一种机制来处理 AMD 的异构系统，通过为 CPU 和 GPU 调用特定于系统的操作。AMD GPU 节点根据 PCI 层次结构顺序枚举，并假设第一个 GPU 节点的节点 ID 值在所有 CPU 节点完全枚举后紧接着 CPU 节点的值：

    $ ls /sys/devices/system/edac/mc/
        mc0   - CPU MC 节点 0
        mc1  |
        mc2  |- GPU 卡[0] => 节点 0(mc1)，节点 1(mc2)
        mc3  |
        mc4  |- GPU 卡[1] => 节点 0(mc3)，节点 1(mc4)
        mc5  |
        mc6  |- GPU 卡[2] => 节点 0(mc5)，节点 1(mc6)
        mc7  |
        mc8  |- GPU 卡[3] => 节点 0(mc7)，节点 1(mc8)

例如，在一个具有一个 AMD CPU 的异构系统中，四个 MI200 (Aldebaran) GPU 通过 xGMI 连接到该 CPU。此拓扑可以通过以下 sysfs 条目表示：

    /sys/devices/system/edac/mc/.
    CPU			# CPU 节点
        ├── mc 0

    GPU 节点在 CPU 节点完全枚举之后按顺序枚举
    GPU 卡 1		# 每个 MI200 GPU 有 2 个节点/mcs
        ├── mc 1		# GPU 节点 0 == mc1，每个 MC 节点有 4 个 UMC/CSROW
            │   ├── csrow 0		# UMC 0
            │   │   ├── channel 0	# 每个 UMC 有 8 个通道
            │   │   ├── channel 1   # 每个通道大小为 2 GB，因此每个 UMC 为 16 GB
            │   │   ├── channel 2
            │   │   ├── channel 3
            │   │   ├── channel 4
            │   │   ├── channel 5
            │   │   ├── channel 6
            │   │   ├── channel 7
            │   ├── csrow 1		# UMC 1
            │   │   ├── channel 0
            │   │   ├── .
            │   │   ├── channel 7
            │   ├── ..		.
            │   ├── csrow 3		# UMC 3
            │   │   ├── channel 0
            │   │   ├── .
            │   │   ├── channel 7
            │   ├── rank 0
            │   ├── ..		.
            │   ├── rank 31		# 总共 32 个 rank/dimm 来自 4 个 UMC
        ├──
        ├── mc 2		# GPU 节点 1 == mc2
            │   ├── ..		# 每个 GPU 总共有 64 GB

    GPU 卡 2
        ├── mc 3
            │   ├── .
    ├── mc 4
        │   ├── .
    GPU 卡 3
        ├── mc 5
            │   ├── .
    ├── mc 6
        │   ├── .
这段文字似乎是试图以一种非标准的方式描述一个文件夹结构或者是一个具有特定层级的列表，并不是一句通顺的英文句子。如果我们尝试将其解释为描述某个系统或文件夹结构的一部分，可以这样理解：

- GPU卡4
  - 分区/组件 7
    - ...
  - 分区/组件 8
    - ...

这里，“mc”可能是某种缩写或简称，在没有具体上下文的情况下很难准确判断其含义，所以暂且将其翻译为“分区/组件”。如果您有更具体的上下文信息，请提供给我以便给出更准确的翻译。
